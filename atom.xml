<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Frank]]></title>
  <subtitle><![CDATA[Li Jingpeng's site]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://www.notehub.cn/"/>
  <updated>2015-10-21T11:52:37.000Z</updated>
  <id>http://www.notehub.cn/</id>
  
  <author>
    <name><![CDATA[Li Jingpeng]]></name>
    <email><![CDATA[me@lijingpeng.org]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[C++ 编程环境]]></title>
    <link href="http://www.notehub.cn/2015/10/21/dev/cpp_dev/"/>
    <id>http://www.notehub.cn/2015/10/21/dev/cpp_dev/</id>
    <published>2015-10-21T12:19:56.000Z</published>
    <updated>2015-10-21T11:52:37.000Z</updated>
    <content type="html"><![CDATA[<h3 id="C++_code_with_Google_style">C++ code with Google style</h3><p><a href="http://google.github.io/styleguide/cppguide.html" target="_blank" rel="external">http://google.github.io/styleguide/cppguide.html</a></p>
<h3 id="Use_cpplint_to_check_your_style">Use cpplint to check your style</h3><h3 id="Protocol_Buffers">Protocol Buffers</h3><p><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="external">https://developers.google.com/protocol-buffers/</a><br>(proto2): <a href="https://developers.google.com/protocol-buffers/docs/proto" target="_blank" rel="external">https://developers.google.com/protocol-buffers/docs/proto</a><br>C++ related: <a href="https://developers.google.com/protocol-buffers/docs/cpptutorial" target="_blank" rel="external">https://developers.google.com/protocol-buffers/docs/cpptutorial</a>,<br>Style guide: <a href="https://developers.google.com/protocol-buffers/docs/style" target="_blank" rel="external">https://developers.google.com/protocol-buffers/docs/style</a></p>
<h3 id="Compile_code:_Blade">Compile code: Blade</h3><p><a href="https://github.com/chen3feng/typhoon-blade" target="_blank" rel="external">https://github.com/chen3feng/typhoon-blade</a></p>
<h3 id="Unit_test_your_code:_gtest">Unit test your code: gtest</h3><p><a href="https://github.com/google/googletest/blob/master/googletest/docs/Documentation.md" target="_blank" rel="external">https://github.com/google/googletest/blob/master/googletest/docs/Documentation.md</a><br>Run unit tests with BLADE<br>Every public method should be covered</p>
<h3 id="Post_your_code_review:_ReviewBoard">Post your code review: ReviewBoard</h3>]]></content>
    <summary type="html">
    <![CDATA[<h3 id="C++_code_with_Google_style">C++ code with Google style</h3><p><a href="http://google.github.io/styleguide/cppguide.html" target="_bl]]>
    </summary>
    
      <category term="c++" scheme="http://www.notehub.cn/categories/c/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Maven 依赖包打包]]></title>
    <link href="http://www.notehub.cn/2015/10/12/dev/maven_assembly/"/>
    <id>http://www.notehub.cn/2015/10/12/dev/maven_assembly/</id>
    <published>2015-10-12T12:19:56.000Z</published>
    <updated>2015-10-12T12:25:43.000Z</updated>
    <content type="html"><![CDATA[<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">version</span>&gt;</span>2.4<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>com.travelsky.tdp.pkgstock<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>stock-assembly-descriptor<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.0.0<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">execution</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 绑定到maven的package命令 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="title">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="title">phase</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="title">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="title">goal</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="title">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="title">execution</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">executions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">ignoreMissingDescriptor</span>&gt;</span>true<span class="tag">&lt;/<span class="title">ignoreMissingDescriptor</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">descriptorRefs</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">descriptorRef</span>&gt;</span>zipAll<span class="tag">&lt;/<span class="title">descriptorRef</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">descriptorRef</span>&gt;</span>zipFilterConf<span class="tag">&lt;/<span class="title">descriptorRef</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">descriptorRef</span>&gt;</span>zipJsCssOnly<span class="tag">&lt;/<span class="title">descriptorRef</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">descriptorRef</span>&gt;</span>zipPicOnly<span class="tag">&lt;/<span class="title">descriptorRef</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="title">descriptorRefs</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="]]>
    </summary>
    
      <category term="java" scheme="http://www.notehub.cn/categories/java/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Java Math StatExample]]></title>
    <link href="http://www.notehub.cn/2015/10/12/dev/java_math_stat/"/>
    <id>http://www.notehub.cn/2015/10/12/dev/java_math_stat/</id>
    <published>2015-10-12T04:57:56.000Z</published>
    <updated>2015-10-12T11:27:09.000Z</updated>
    <content type="html"><![CDATA[<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.StatUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.moment.GeometricMean;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.moment.Kurtosis;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.moment.Mean;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.moment.Skewness;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.moment.StandardDeviation;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.moment.Variance;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.rank.Max;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.rank.Min;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.rank.Percentile;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.summary.Product;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math.stat.descriptive.summary.Sum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StatExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span>[] values = <span class="keyword">new</span> <span class="keyword">double</span>[] &#123; <span class="number">2.3</span>, <span class="number">5.4</span>, <span class="number">6.2</span>, <span class="number">7.3</span>, <span class="number">23.3</span> &#125;;</span><br><span class="line"></span><br><span class="line">        System.out.println( <span class="string">"min: "</span> + StatUtils.min( values ) );</span><br><span class="line">        System.out.println( <span class="string">"max: "</span> + StatUtils.max( values ) );</span><br><span class="line">        System.out.println( <span class="string">"mean: "</span> + StatUtils.mean( values ) );</span><br><span class="line">        System.out.println( <span class="string">"product: "</span> + StatUtils.product( values ) );</span><br><span class="line">        System.out.println( <span class="string">"sum: "</span> + StatUtils.sum( values ) );</span><br><span class="line">        System.out.println( <span class="string">"variance: "</span> + StatUtils.variance( values ) );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Measures from previous example</span></span><br><span class="line">        Min min = <span class="keyword">new</span> Min();</span><br><span class="line">        System.out.println( <span class="string">"min: "</span> + min.evaluate( values ) );</span><br><span class="line">        Max max = <span class="keyword">new</span> Max();</span><br><span class="line">        System.out.println( <span class="string">"max: "</span> + max.evaluate( values ) );</span><br><span class="line">        Mean mean = <span class="keyword">new</span> Mean();</span><br><span class="line">        System.out.println( <span class="string">"mean: "</span> + mean.evaluate( values ) );</span><br><span class="line">        Product product = <span class="keyword">new</span> Product();</span><br><span class="line">        System.out.println( <span class="string">"product: "</span> + product.evaluate( values ) );</span><br><span class="line">        Sum sum = <span class="keyword">new</span> Sum();</span><br><span class="line">        System.out.println( <span class="string">"sum: "</span> + sum.evaluate( values ) );</span><br><span class="line">        Variance variance = <span class="keyword">new</span> Variance();</span><br><span class="line">        System.out.println( <span class="string">"variance: "</span> + variance.evaluate( values ) );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// New measures</span></span><br><span class="line">        Percentile percentile = <span class="keyword">new</span> Percentile();</span><br><span class="line">        System.out.println( <span class="string">"80 percentile value: "</span> + percentile.evaluate( values, <span class="number">80.0</span> ) );</span><br><span class="line">        GeometricMean geoMean = <span class="keyword">new</span> GeometricMean();</span><br><span class="line">        System.out.println( <span class="string">"geometric mean: "</span> + geoMean.evaluate( values ) );</span><br><span class="line">        StandardDeviation stdDev = <span class="keyword">new</span> StandardDeviation();</span><br><span class="line">        System.out.println( <span class="string">"standard dev: "</span> + stdDev.evaluate( values ) );</span><br><span class="line">        Skewness skewness = <span class="keyword">new</span> Skewness();</span><br><span class="line">        System.out.println( <span class="string">"skewness: "</span> + skewness.evaluate( values ) );</span><br><span class="line">        Kurtosis kurtosis = <span class="keyword">new</span> Kurtosis();</span><br><span class="line">        System.out.println( <span class="string">"kurtosis: "</span> + kurtosis.evaluate( values ) );</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class=]]>
    </summary>
    
      <category term="java" scheme="http://www.notehub.cn/categories/java/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在线广告作弊手段一览]]></title>
    <link href="http://www.notehub.cn/2015/10/10/internet/ad/ad_cheating/"/>
    <id>http://www.notehub.cn/2015/10/10/internet/ad/ad_cheating/</id>
    <published>2015-10-09T16:00:00.000Z</published>
    <updated>2015-10-10T06:21:42.000Z</updated>
    <content type="html"><![CDATA[<p>这里提到的在线广告作弊是指媒体为了刷广告流量而进行的作弊。他们的作弊手段很多， 这里介绍常见的几种。</p>
<p>iframe是广告作弊最常用的技巧，就是在自己的网页上嵌入iframe, 大小为0x0或1×1，也就是用户不可见。通过iframe打开其他页面，在用户看不见的情况下刷流量。别看iframe简单，里面花样很多。</p>
<h3 id="页面内嵌入本站页面的iframe">页面内嵌入本站页面的iframe</h3><p>iframe打开和当前页一样的页面地址，或本站的其他页面。 这样用户的一个浏览行为，很轻松就从1个pv翻倍变成2个pv。如果嵌入iframe多点， 就能翻3倍，4倍…。但使用这个方法很容易被发现，广告投放方，通过分析UV，独立IP等很容易就发现异常。 这是很老的方法，不过还是有些网站乐此不疲。</p>
<h3 id="两个站点间互相嵌入对方站点页面的iframe">两个站点间互相嵌入对方站点页面的iframe</h3><p>这是比较巧妙的作弊技巧，UV，独立IP等分析方法是不能发现异常的。</p>
<h3 id="双层iframe">双层iframe</h3><p>作弊的iframe为了不让人看见，大小只有0x0或1×1，但有些在线广告在显示时会判断浏览窗口大小，如果太小可能就不能显示。这时有些网站就采用了双层iframe技术来刷广告流量。 第一层1×1大小的iframe中又嵌入一个iframe，这个第二层iframe是正常浏览窗口大小，广告代码很难发现异常。</p>
<p>这种作弊方式使用巧妙的，会让主页面和两个iframe使用三个不同的域名，这样因为跨域的问题， 里面的js不可能得到最外层真正的页面地址， 想抓证据都抓不到。</p>
<h3 id="IP屏蔽">IP屏蔽</h3><p>有些站点在进行作弊时，会屏蔽北京，上海等大城市的访问，你从这些地区访问时，看不到他们的作弊代码，一切正常。等换用其他地方的代理访问时，你在他们页面里就能看到作弊用iframe代码。 这是因为很多IT，在线广告公司都在这些大城市，这种屏蔽让他们的作弊手段很难被同业发现。</p>
<h3 id="购买垃圾流量">购买垃圾流量</h3><p>现在来自iframe，木马的垃圾流量都是明码标价在卖的，可以用这些流量来刷页面，刷广告。这种也比较难以发现。网站去刷流量目的往往比较复杂，一是刷广告流量，赚广告商和广告主的钱，二是为了alexa之类的排名，也有是为了给投资人看所谓的“业绩”。 </p>
<p>上面谈的基本都是CPM广告方式的作弊，下面说说其他的。 </p>
<h3 id="CPC作弊">CPC作弊</h3><p>CPC作弊其实是很简单的，只要用iframe打开点击链接即可。</p>
<h3 id="CPA作弊">CPA作弊</h3><p>有些网站广告按CPA结算，比如注册人数等。 这种情况下，有的公司会做专门的自动注册机，保证你的注册人数疯狂上涨。</p>
<h3 id="CPS作弊">CPS作弊</h3><p>很多人感觉CPS方式是不可能作弊的，其实这也是可以的。 </p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这里提到的在线广告作弊是指媒体为了刷广告流量而进行的作弊。他们的作弊手段很多， 这里介绍常见的几种。</p>
<p>iframe是广告作弊最常用的技巧，就是在自己的网页上嵌入iframe, 大小为0x0或1×1，也就是用户不可见。通过iframe打开其他页面，在用户看不见的]]>
    </summary>
    
      <category term="广告" scheme="http://www.notehub.cn/tags/%E5%B9%BF%E5%91%8A/"/>
    
      <category term="internet" scheme="http://www.notehub.cn/categories/internet/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[关于Cookie]]></title>
    <link href="http://www.notehub.cn/2015/10/10/internet/ad/cookie/"/>
    <id>http://www.notehub.cn/2015/10/10/internet/ad/cookie/</id>
    <published>2015-10-09T16:00:00.000Z</published>
    <updated>2015-10-10T06:35:19.000Z</updated>
    <content type="html"><![CDATA[<h2 id="关于Cookie">关于Cookie</h2><hr>
<p><img src="/images/other/cookie.jpg" alt=""></p>
<h3 id="Cookie的传递流程">Cookie的传递流程</h3><p>Cookie利用网页代码中癿HTTP头信息，伴随着用户请求和页面在 Web 服务器和浏览器之间传递。例如：当你在浏览器地址栏中键入了Amazon的URL，浏览器会向Amazon发送一个读取网页请求，并将结果在显示器上显示。在发送前，该网页在你的电脑上寻找Amazon网站设置的Cookie文件，如果找到，浏览器会把Cookie文件中的数据连同前面输入的URL一同发送到Amazon服务器。服务器收到Cookie数据，就会在他的数据库中检索你的ID，你的购物记彔、个人喜好等信息，并记录下新的内容，增加到数据库和Cookie文件中去。如果没有检测到Cookie或者你的Cookie信息不数据库中的信息不符合，则说明你是第一次浏览该网站，服务器的CGI程序将为你创建新的ID信息，幵保存到数据库中。</p>
<h3 id="关于Cookie的一些知识点">关于Cookie的一些知识点</h3><ol>
<li>Cookie是基二浏览器的，因此当电脑上安装多个浏览器时，服务器会生成多个Cookie。虽然是同一个人，但服务器是识删为多个用户。 </li>
<li>Cookie是基二浏览器的，因此当同一台电脑有多个人使用时，服务器也叧会生成一个Cookie。虽然是多个人，但服务器会讣为是一个用户。补充：在多个人均登彔账户时，服务器可以以账户为匙分，为每个账户生成单独癿cookie，比如多人用同一台电脑登彔新浪微博。（感谢数据挖掘_PHP癿指正） </li>
<li>Cookie是无法跨设备设置的。比如我们在单位和家里分别使用两台电脑，即使我们使用同一种同一版本的浏览器，我们迓是生成了两个Cookie，服务器会认为是两个用户。（PS：现在有些浏览器可以同步数据，比如Chrome、Friefox，可以避免这种问题） </li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="关于Cookie">关于Cookie</h2><hr>
<p><img src="/images/other/cookie.jpg" alt=""></p>
<h3 id="Cookie的传递流程">Cookie的传递流程</h3><p>Cookie利用网页代码中]]>
    </summary>
    
      <category term="广告" scheme="http://www.notehub.cn/tags/%E5%B9%BF%E5%91%8A/"/>
    
      <category term="internet" scheme="http://www.notehub.cn/categories/internet/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[合福高铁-国庆游]]></title>
    <link href="http://www.notehub.cn/2015/10/07/travel/hefu_travel/"/>
    <id>http://www.notehub.cn/2015/10/07/travel/hefu_travel/</id>
    <published>2015-10-06T16:00:00.000Z</published>
    <updated>2015-10-10T06:11:10.000Z</updated>
    <content type="html"><![CDATA[<p>国庆本来自己没什么计划，后来同学一起计划沿着合福高铁沿线的景点游一圈，合福高铁将黄山、三清山、武夷山、福州、厦门等联系在了一起，横跨三个省份，当真是中国最美的高铁线路。由于人在杭州，因此打算从杭州出发，六天的行程计划去三清山、武夷山、福州和厦门。正所谓计划赶不上变化，再加上国庆人比较多导致早已经买好的票都改签了，预约的酒店很多也没有住成。</p>
<h3 id="首站：杭州-武夷山东">首站：杭州-武夷山东</h3><hr>
<p>晚上6:30发车，9:00就到武夷山东站了，武夷山东站是刚刚开通的车站，周围的交通配套设施都很不完善，另外武夷山东站虽然名字中带着『武夷山』，但是离武夷山景区的距离实在是太长了，坐大巴车要两个小时。</p>
<p>到了景区后住了一个青年旅店，六人间，遇到了两个福州来的漂亮妹子，住的地方很潮湿，可能是因为刚刚来台风的原因，一晚上没有怎么睡好，青年旅店的环境还是挺好的，老板非常文艺，微信发的状态都是繁体字的。</p>
<hr>
<p><img src="/images/hefu_train/IMG_4006.jpg" alt=""><br><img src="/images/hefu_train/IMG_4010.jpg" alt=""></p>
<p>第二天吃了点早饭，为了逃票，直接找了个当地人把我们带到景区去爬大王峰了，大王峰不算是最知名的武夷山景点，不过丹霞地貌的还是挺美的。</p>
<hr>
<p><img src="/images/hefu_train/IMG_4021.jpg" alt=""><br>我觉得逃票这个决定可能是这次旅行最坏得决定了，大王峰倒是没什么特色，但是下午打算去其他景点的时候就发现再买票有点不划算了，本来定的是10月2号离开武夷山的，结果最后只能提前走了。再附几张武夷山的图。</p>
<hr>
<p><img src="/images/hefu_train/IMG_4048.jpg" alt=""><br><img src="/images/hefu_train/IMG_4115.jpg" alt=""></p>
<h3 id="第二站：三清山">第二站：三清山</h3><hr>
<p>『三清山又名少华山、丫山，位于中国江西省上饶市玉山县与德兴市交界处。因玉京、玉虚、玉华三峰宛如道教玉清、上清、太清三位尊神列坐山巅而得名。其中玉京峰为最高，海拔1819.9米，是江西第五高峰和怀玉山脉的最高峰，也是信江的源头。三清山是道教名山，世界自然遗产地、世界地质公园、国家自然遗产、国家地质公园。』</p>
<p>三清山比较热门的路线是南线索道和东线索道，要想徒步上山的话只能从南部走。我们是从东部的金沙索道上山的，国庆假期索道还要叫号按序上山，上去之后已经是海拔1000米以上了，之后所有的景点都在1000米之上。</p>
<hr>
<p><img src="/images/hefu_train/IMG_4192.jpg" alt=""><br><img src="/images/hefu_train/IMG_4213.jpg" alt=""><br><img src="/images/hefu_train/IMG_4257.jpg" alt=""></p>
<center>云雾缭绕的三清山</center><br><img src="/images/hefu_train/IMG_4265.jpg" alt=""><br><img src="/images/hefu_train/IMG_4269.jpg" alt=""><br><img src="/images/hefu_train/IMG_4276.jpg" alt=""><br><center>猴王观宝</center><br><img src="/images/hefu_train/IMG_4287.jpg" alt=""><br><center>如诗如画</center><br><img src="/images/hefu_train/IMG_4296.jpg" alt=""><br><img src="/images/hefu_train/IMG_4299.jpg" alt=""><br><center>三清山主峰</center>

<h3 id="第三站：福州">第三站：福州</h3><hr>
<p>福州整体没有很深得印象，就去了三坊七巷，还买了原价120一人的票，逛的过程中发现票价非常不值啊，收费的小景点都是一些古宅什么的，作为一个北方人，看过了也就那样了，都是类似的。另外三坊七巷和厦门的曾厝垵和鼓浪屿比也没有什么特色，被完爆的节奏。</p>
<hr>
<p><img src="/images/hefu_train/IMG_4346.jpg" alt=""><br><img src="/images/hefu_train/IMG_4355.jpg" alt=""><br><img src="/images/hefu_train/IMG_4523.jpg" alt=""></p>
<center>非常喜欢林则徐纪念馆的牌子的设计</center>

<h3 id="第四站：厦门">第四站：厦门</h3><hr>
<p>上次去厦门是元旦的时候，那个时候是十几个人一起去的，离现在还不到半年的时间。每次去厦门都是不同的感受，总的来说厦门是一个让人放松的城市，非常的文艺。</p>
<hr>
<p><img src="/images/hefu_train/IMG_4364.jpg" alt=""></p>
<center>『烤酸奶』其实是冷冻的，第一次吃，味道还不错</center><br><img src="/images/hefu_train/IMG_4428.jpg" alt=""><br><br><img src="/images/hefu_train/IMG_4497.jpg" alt=""><br><img src="/images/hefu_train/IMG_4518.jpg" alt=""><br><img src="/images/hefu_train/IMG_4519.jpg" alt=""><br><img src="/images/hefu_train/IMG_4520.jpg" alt=""><br><center>鼓浪屿</center><br>鼓浪屿上面的欧式风格的建筑，文艺的小店，小吃等非常多，龙头路非常热闹。<br><img src="/images/hefu_train/IMG_4541.jpg" alt=""><br><center>最后附上行程的所有火车票</center>
]]></content>
    <summary type="html">
    <![CDATA[<p>国庆本来自己没什么计划，后来同学一起计划沿着合福高铁沿线的景点游一圈，合福高铁将黄山、三清山、武夷山、福州、厦门等联系在了一起，横跨三个省份，当真是中国最美的高铁线路。由于人在杭州，因此打算从杭州出发，六天的行程计划去三清山、武夷山、福州和厦门。正所谓计划赶不上变化，再加上]]>
    </summary>
    
      <category term="合福高铁,三清山,武夷山,福州,三坊七巷,厦门,鼓浪屿" scheme="http://www.notehub.cn/tags/%E5%90%88%E7%A6%8F%E9%AB%98%E9%93%81-%E4%B8%89%E6%B8%85%E5%B1%B1-%E6%AD%A6%E5%A4%B7%E5%B1%B1-%E7%A6%8F%E5%B7%9E-%E4%B8%89%E5%9D%8A%E4%B8%83%E5%B7%B7-%E5%8E%A6%E9%97%A8-%E9%BC%93%E6%B5%AA%E5%B1%BF/"/>
    
      <category term="travel" scheme="http://www.notehub.cn/categories/travel/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Feature hashing]]></title>
    <link href="http://www.notehub.cn/2015/09/25/algo/ml/feature_hashing/"/>
    <id>http://www.notehub.cn/2015/09/25/algo/ml/feature_hashing/</id>
    <published>2015-09-24T16:00:00.000Z</published>
    <updated>2015-09-25T14:43:22.000Z</updated>
    <content type="html"><![CDATA[<p>In machine learning, feature hashing, also known as the hashing trick(by analogy to the kernel trick), is a fast and space-efficient way of vectorizing features, i.e. turning arbitrary features into indices in a vector or matrix. It works by applying a hash function to the features and using their hash values as indices directly, rather than looking the indices up in an associative array.</p>
<h3 id="Motivating_example">Motivating example</h3><p>In a typical document classification task, the input to the machine learning algorithm (both during learning and classification) is free text. From this, a bag of words (BOW) representation is constructed: the individual tokens are extracted and counted, and each distinct token in the training set defines a feature (independent variable) of each of the documents in both the training and test sets.</p>
<p>Machine learning algorithms, however, are typically defined in terms of numerical vectors. Therefore, the bags of words for a set of documents is regarded as a term-document matrix where each row is a single document, and each column is a single feature/word; the entry i, j in such a matrix captures the frequency (or weight) of the j’th term of the vocabulary in document i. (An alternative convention swaps the rows and columns of the matrix, but this difference is immaterial.) Typically, these vectors are extremely sparse.</p>
<p>The common approach is to construct, at learning time or prior to that, a dictionary representation of the vocabulary of the training set, and use that to map words to indices. Hash tables and tries are common candidates for dictionary implementation. E.g., the three documents</p>
<p>John likes to watch movies.<br>Mary likes movies too.<br>John also likes football.<br>can be converted, using the dictionary<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Term    Index</span><br><span class="line">John    <span class="number">1</span></span><br><span class="line">likes   <span class="number">2</span></span><br><span class="line">to      <span class="number">3</span></span><br><span class="line">watch   <span class="number">4</span></span><br><span class="line">movies  <span class="number">5</span></span><br><span class="line">Mary    <span class="number">6</span></span><br><span class="line">too     <span class="number">7</span></span><br><span class="line">also    <span class="number">8</span></span><br><span class="line">football9</span><br></pre></td></tr></table></figure></p>
<p>to the term-document matrix</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> </span><br><span class="line"><span class="number">0</span> &amp; <span class="number">1</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> </span><br><span class="line"><span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>(Punctuation was removed, as is usual in document classification and clustering.)</p>
<p>The problem with this process is that such dictionaries take up a large amount of storage space and grow in size as the training set grows. On the contrary, if the vocabulary is kept fixed and not increased with a growing training set, an adversary may try to invent new words or misspellings that are not in the stored vocabulary so as to circumvent a machine learned filter. This difficulty is why feature hashing has been tried for spam filtering at Yahoo! Research.</p>
<p>Note that the hashing trick isn’t limited to text classification and similar tasks at the document level, but can be applied to any problem that involves large (perhaps unbounded) numbers of features.</p>
<h3 id="Feature_vectorization_using_the_hashing_trick">Feature vectorization using the hashing trick</h3><p>Instead of maintaining a dictionary, a feature vectorizer that uses the hashing trick can build a vector of a pre-defined length by applying a hash function h to the features (e.g., words) in the items under consideration, then using the hash values directly as feature indices and updating the resulting vector at those indices:</p>
<p> function hashing_vectorizer(features : array of string, N : integer):<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">x :</span>= <span class="keyword">new</span> vector[N]</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> <span class="string">features:</span></span><br><span class="line">    <span class="string">h :</span>= hash(f)</span><br><span class="line">    x[h mod N] += <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p>
<p>It has been suggested that a second, single-bit output hash function ξ be used to determine the sign of the update value, to counter the effect of hash collisions. If such a hash function is used, the algorithm becomes</p>
<p> function hashing_vectorizer(features : array of string, N : integer):<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x := <span class="keyword">new</span> <span class="built_in">vector</span>[N]</span><br><span class="line"><span class="keyword">for</span> f in features:</span><br><span class="line">    h := hash(f)</span><br><span class="line">    idx := h mod N</span><br><span class="line">    <span class="keyword">if</span> ξ(f) == <span class="number">1</span>:</span><br><span class="line">        x[idx] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x[idx] -= <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p>
<p>The above pseudocode actually converts each sample into a vector. An optimized version would instead only generate a stream of (h,ξ) pairs and let the learning and prediction algorithms consume such streams; a linear model can then be implemented as a single hash table representing the coefficient vector.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>In machine learning, feature hashing, also known as the hashing trick(by analogy to the kernel trick), is a fast and space-efficient way ]]>
    </summary>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[特征处理]]></title>
    <link href="http://www.notehub.cn/2015/09/25/algo/ml/Feature%20Processing/"/>
    <id>http://www.notehub.cn/2015/09/25/algo/ml/Feature Processing/</id>
    <published>2015-09-24T16:00:00.000Z</published>
    <updated>2015-09-25T14:37:04.000Z</updated>
    <content type="html"><![CDATA[<p>特征工程（Feature Engineering）经常被说为机器学习中的black art，这里面包含了很多不可言说的方面。怎么处理好特征，最重要的当然还是对要解决问题的了解。但是，它其实也有很多科学的地方。这篇文章我之所以命名为特征处理（Feature Processing），是因为这里面要介绍的东西只是特征工程中的一小部分。这部分比较基础，比较容易说，所以由此开始。单个原始特征（或称为变量）通常属于以下几类之一：</p>
<ul>
<li>连续（continuous）特征；</li>
<li>无序类别（categorical）特征；</li>
<li>有序类别（ordinal）特征。</li>
</ul>
<p>本文中我主要介绍针对单个特征的处理方法，虽然也会附带介绍基础的特征组合方法。同时处理多个特征，以及更复杂的特征处理方法介绍，以后我再另外细说。下面我由浅入深地逐渐说明针对这三类特征的常用处理方法。</p>
<h2 id="初级篇">初级篇</h2><hr>
<h3 id="连续特征">连续特征</h3><p>除了归一化（去中心，方差归一），不用做太多特殊处理，可以直接把连续特征扔到模型里使用。</p>
<h3 id="无序特征">无序特征</h3><p>可以使用One-hot（也叫One-of-k）的方法把每个无序特征转化为一个数值向量。比如一个无序特征color有三种取值：red，green，blue。那么可以用一个长度为3的向量来表示它，向量中的各个值分别对应于red，green，blue。如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">color取值 向量表示</span><br><span class="line">red     (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">green   (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">blue    (<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>这种方法在NLP里用的很多，就是所谓的词向量模型。变换后的向量长度对于词典长度，每个词对应于向量中的一个元素。</p>
<p>机器学习书籍里在讲这个的时候介绍的处理方法可能跟我上面说的有点差别。上面说的表达方式里有一个维度是可以省略的。既然我们知道color一定是取3个值中的一个，那么我们知道向量的前两个元素值，就能推断第3个值是多少。所以，其实用下面的方式就可以表达到底是哪种颜色：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">color取值 向量表示</span><br><span class="line">red     (<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">green   (<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">blue    (<span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>这样表达的好处是少用了一个维度，降低了转化后特征之间的相关性。但在实际问题中特征基本都或多或少会有些缺失。使用第一种表达方式就可以用全0的向量来表示值缺失，而第二种表达方式是没法表达缺失的。</p>
<h3 id="有序特征">有序特征</h3><p>有些特征虽然也像无序特征那样只取限定的几个值，但是这些值之间有顺序的含义。例如一个人的状态status有三种取值：bad, normal, good，显然bad &lt; normal &lt; good。</p>
<p>当然，对有序特征最简单的处理方式是忽略其中的顺序关系，把它看成无序的，这样我们就可以使用处理无序特征的方式来处理它。在实际问题中，这种处理方式其实用的很多。</p>
<p>当然有些问题里有序可能会很重要，这时候就不应该把其中的顺序关系丢掉。一般的表达方式如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">status取值    向量表示</span><br><span class="line">bad     (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">normal  (<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">good    (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>上面这种表达方式很巧妙地利用递进表达了值之间的顺序关系。</p>
<h2 id="中级篇">中级篇</h2><hr>
<p>最容易让人掉以轻心的，往往就是大家觉得最简单的事。在特征处理中，最容易让刚入门同学忽略的，是对连续特征的处理方式。</p>
<p>以线性分类器Linear Regression (LinearReg)为例，它是通过特征的线性加权来预测因变量y：<br><figure class="highlight fix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">y</span>=<span class="string">wTx</span></span><br></pre></td></tr></table></figure></p>
<p>但大部分实际情况下，y与x都不会是这么简单的线性关系，甚至连单调关系都不会有。举个只有一个特征的例子，如果y与x的实际关系如下图：</p>
<p><img src="/images/algo/nonlinear_function1.png" alt=""></p>
<p>那么直接把x扔进LinearReg模型是怎么也得不到好结果的。很多人会想着既然线性分类器搞不定，那就直接找个非线性的好了，比如高斯核的SVM。我们确实可以通过这种简单换算法的方式解决这个简单的问题。但对于很多实际问题（如广告点击率预测），往往特征非常多，这时候时间约束通常不允许我们使用很复杂的非线性分类器。这也是为什么算法发展这么多年，广告点击率预测最常用的方法还是Logistic Regression (LogisticReg)。</p>
<p>对于上面这个问题，有没有什么办法使得LinearReg也能处理得不错？当然是有，就是对原始特征x做转化，把原来的非线性关系转化为线性关系。</p>
<h3 id="方法一：离散化">方法一：离散化</h3><p>最常用的转化方式是对x做离散化(discretization)，也就是把原来的值分段，转化成一个取值为0或1的向量。原始值落在某个段里，向量中此段对应的元素就为1，否则为0。</p>
<p>离散化的目标是y与转化后向量里的每个元素都保持比较好的线性关系。<br>比如取离散点{0.5,1.5,2.5}，通过判断x属于(−∞,0.5)，[0.5,1.5)，[1.5,2.5)，[2.5,+∞)中哪段来把它离散化为4维的向量。下面是一些例子的离散结果：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">原始值x    离散化后的值</span><br><span class="line"><span class="number">0.1</span>     (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">1.3</span>     (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">3.2</span>     (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="number">5.8</span>     (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>离散化方法的关键是怎么确定分段中的离散点。下面是常用的选取离散点的方法：</p>
<p>a. 等距离离散：顾名思义，就是离散点选取等距点。我们上面对x取离散点{0.5,1.5,2.5}就是一种等距离散，见下图。图中垂直的灰线代表离散点。</p>
<p><img src="/images/algo/nonlinear_function2.png" alt=""></p>
<p>b. 等样本点离散：选取的离散点保证落在每段里的样本点数量大致相同，见下图。</p>
<p><img src="/images/algo/nonlinear_function3.png" alt=""></p>
<p>c. 画图观察趋势：以x为横坐标，y为纵坐标，画图，看曲线的趋势和拐点。通过观察下面的图我们发现可以利用3条直线（红色直线）来逐段近似原来的曲线。把离散点设为两条直线相交的各个点，我们就可以把x离散化为长度为3的向量。</p>
<p><img src="/images/algo/nonlinear_function4.png" alt=""></p>
<p>上面介绍的这种离散化为0/1向量的方法有个问题，它在离散时不会考虑到具体的x到离散边界的距离。比如等距离散中取离散点为{0.5,1.5,2.5}，那么1.499，1.501和2.49分别会离散为(0, 1, 0, 0)，(0, 0, 1, 0)和(0, 0, 1, 0)。1.499和1.501很接近，可是就因为这种强制分段的离散导致它们离散的结果差距很大。</p>
<p>针对上面这种硬离散的一种改进就是使用软离散，也就是在离散时考虑到x与附近离散点的距离，离散出来的向量元素值可以是0/1之外的其他值。有兴趣的同学可以去ESL1这本书中找点感觉。</p>
<h3 id="方法二：函数变换">方法二：函数变换</h3><p>函数变换直接把原来的特征通过非线性函数做变换，然后把原来的特征，以及变换后的特征一起加入模型进行训练。常用的变换函数见下表，不过其实你可以尝试任何函数。<br><figure class="highlight openscad"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">常用非线性函数f<span class="params">(x)</span> x的取值范围</span><br><span class="line">xα; α∈<span class="params">(−∞,+∞)</span>   <span class="params">(−∞,+∞)</span></span><br><span class="line"><span class="built_in">log</span><span class="params">(x)</span>          <span class="params">(<span class="number">0</span>,+∞)</span></span><br><span class="line"><span class="built_in">log</span><span class="params">(x1−x)</span>       <span class="params">(<span class="number">0</span>,<span class="number">1</span>)</span></span><br></pre></td></tr></table></figure></p>
<p>这个方法操作起来很简单，但记得对新加入的特征做归一化。</p>
<p>对于我们前面的问题，只要把x2，x3也作为特征加入即可，因为实际上y就是x的一个三次多项式。</p>
<h2 id="高级篇">高级篇</h2><hr>
<h3 id="笛卡尔乘积">笛卡尔乘积</h3><p>我们可以使用笛卡尔乘积的方式来组合2个或更多个特征。比如有两个类别特征color和light，它们分别可以取值为red，green，blue和on, off。这两个特征各自可以离散化为3维和2维的向量。对它们做笛卡尔乘积转化，就可以组合出长度为6的特征，它们分别对应着原始值对(red, on)，(red, off)，(green, on)，(green, off)，(blue, on)，(blue, off)。下面的矩阵表达方式更清楚地说明了这种组合。<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">X</span>       <span class="built_in">on</span>  <span class="built_in">off</span></span><br><span class="line">red      </span><br><span class="line">green        </span><br><span class="line">blue</span><br></pre></td></tr></table></figure></p>
<p>对于3个特征的笛卡尔乘积组合，可以表达为立方的形式。更多特征的组合依次类推。 这个方法也可以直接用于连续特征与类别特征之间的组合，只要把连续特征看成是1维的类别特征就好了，这时候组合后特征对应的值就不是0/1了，而是连续特征的取值。</p>
<h3 id="离散化续篇">离散化续篇</h3><p>在上节中我已经介绍了一些常用的离散化单个连续特征的方法，其中一个是画图观察趋势。画图观察趋势的好处是直观、可解释性强，坏处是很麻烦。当要离散化的特征很多时，这种方法可操作性较差。</p>
<p>机器学习中有个很好解释，速度也不错的模型——决策树模型。大白话说决策树模型就是一大堆的if else。它天生就可以对连续特征分段，所以把它用于离散化连续特征合情合理。我称这种方法为决策树离散化方法。例如Gmail在对信件做重要性排序时就使用了决策树离散化方法2。</p>
<p>决策树离散化方法通常也是每次离散化一个连续特征，做法如下：</p>
<p>单独用此特征和目标值y训练一个决策树模型，然后把训练获得的模型内的特征分割点作为离散化的离散点。<br>这种方法当然也可以同时离散化多个连续特征，但是操作起来就更复杂了，实际用的不多。</p>
<h3 id="核方法">核方法</h3><p>核方法经常作为线性模型的一种推广出现。以线性回归模型为例，它对应的核方法如下：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fθ(x)=∑θ<span class="function"><span class="title">iK</span><span class="params">(x,xi)</span></span></span><br></pre></td></tr></table></figure></p>
<p>其中{xi}=1为训练样本点，K(xi,xj)为核函数，比如常用的高斯核函数为：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">K</span><span class="params">(xi,xj)</span></span>=<span class="function"><span class="title">exp</span><span class="params">(−exp(∥xi−xj∥, <span class="number">2</span>)</span></span>/<span class="number">2</span>*<span class="function"><span class="title">exp</span><span class="params">(h,<span class="number">2</span>)</span></span>)</span><br></pre></td></tr></table></figure></p>
<p>如果我们把上面模型里的{K(x,xi)}=1看成特征，而θ看成模型参数的话，上面的模型仍旧是个线性模型。所以可以认为核方法只是特征函数变换的一种方式。</p>
<p>当然，如果把核函数K(xi,xj)看成一种相似度的话，那上面的模型就是kNN模型了，或者叫做加权平均模型也可以。因为核方法在预测时也要用到训练样本点，耗内存且计算量大，所以在数据量较大的实际问题中用的并不多。到此，我已经介绍了不少针对单个特征的处理方法。这些处理方法很难说哪个好哪个不好。有些问题这个好，有些问题那个好，也没什么绝招能直接判断出哪种方法能适合哪些问题。唯一的招就是：</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>特征工程（Feature Engineering）经常被说为机器学习中的black art，这里面包含了很多不可言说的方面。怎么处理好特征，最重要的当然还是对要解决问题的了解。但是，它其实也有很多科学的地方。这篇文章我之所以命名为特征处理（Feature Processin]]>
    </summary>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[机器学习资料大汇总]]></title>
    <link href="http://www.notehub.cn/2015/09/23/algo/ml/"/>
    <id>http://www.notehub.cn/2015/09/23/algo/ml/</id>
    <published>2015-09-22T16:00:00.000Z</published>
    <updated>2015-09-23T05:09:18.000Z</updated>
    <content type="html"><![CDATA[<p><img src="/images/other/ml.jpg" alt=""></p>
<p>注：本页面主要针对想快速上手机器学习而又不想深入研究的同学，对于专门的researcher，建议直接啃PRML，ESL，MLAPP以及你相应方向的书（比如Numerical Optimization，Graphic Model等），另外就是Follow牛会牛paper，如果谁有兴趣也可以一起来整理个专业的汇总页。本页面将持续更新，敬请关注，如有推荐的文章请留言，谢谢！</p>
<h3 id="开源工具">开源工具</h3><hr>
<p><a href="http://www.52ml.net/12043.html" target="_blank" rel="external">机器学习的开源工具</a><br><a href="http://www.52ml.net/13547.html" target="_blank" rel="external">Python机器学习库</a><br><a href="http://www.52ml.net/13002.html" target="_blank" rel="external">C++矩阵运算库推荐</a></p>
<h3 id="公开课">公开课</h3><hr>
<ul>
<li>Machine Learning | Coursera Andrew NG在coursera上的课，难度比公开课略低，适合入门</li>
<li>斯坦福大学公开课 ：机器学习课程 Andrew NG在学校里面的课程，网易公开课有中英文字幕，可以配合笔记来看</li>
<li>CMU机器学习系主任Tom Mitchell院士机器学习课程视频及课件（英文）</li>
<li>机器学习|加州理工，老师是Yaser Abu-Mostafa，会从最基本的理论开始，为你构建机器学习的基础。</li>
<li>机器学习基石 如果想听中文课程，台湾大学的这门就很合适，友情提示，台大的课程基本上都可以加快语速来听，原因你懂的</li>
<li>神经网络|多伦多大学 鼎鼎大名的Geoffrey Hinton ，这门课着实不容错过</li>
<li>凸优化课程|斯坦福 授课老师是凸优化经典教材的作者Stephen Boyd！有难度有挑战！</li>
<li>概率图模型  coursera的另外一个创始人，Daphne Koller的课程，值得一提的是，Koller因提出了Probabilistic Relational Models拿到了2001年的IJCAI Computers and Thought Award</li>
<li>统计学习|斯坦福 授课老师是ESL作者 ，还有同学把视频放在了百度网盘上～ 这个更快一些</li>
</ul>
<h3 id="1-_机器学习入门篇">1. 机器学习入门篇</h3><h4 id="1-1_机器学习介绍">1.1 机器学习介绍</h4><ul>
<li>机器学习-维基百科  Machine Learning-Wikipedia</li>
<li>机器学习简史</li>
<li>规则与机器学习 不建议为了机器学习而机器学习，对于初学者应该是先规则再机器学习，规则直观，可以深入理解领域知识和特征，要记住一个机器学习的专家必须首先是该领域知识的专家。</li>
<li>贝叶斯思想 MLAPP 第5章 Bayesian statistics 第6章 Frequentist statistics 机器学习第6章 贝叶斯学习</li>
<li>监督学习 ESL 第2章 Overview of Supervised Learning</li>
</ul>
<h4 id="1-2_书籍">1.2 书籍</h4><ul>
<li>《统计学习方法》 第1章 统计学习方法概论</li>
<li>《机器学习》（Mitchell） 第1章 引言</li>
<li>PRML 第1章 Introduction</li>
<li>MLAPP 第1章 Introduction 第2章 Probability</li>
<li>ESL 第1章 Introduction</li>
<li>Some Notes on Applied Mathematics for Machine (选修)</li>
<li>Machine Learning Textbook minireviews</li>
<li>List of Cool Machine Learning Books</li>
</ul>
<h4 id="1-3_数学基础">1.3 数学基础</h4><ul>
<li>线性代数：公开课： 线性代数；推荐文章 ： 线性代数的本质，</li>
<li>概率论：公开课： 概率课|台大 叶老师为人风趣幽默，课程也比较简单，容易听进去</li>
<li>书籍：MLAPP第二章</li>
<li>微积分：公开课：单变量微积分|MIT 多变量微积分|MIT</li>
</ul>
<p>——————————————-</p>
<h4 id="1-4_LDA">1.4 LDA</h4><ul>
<li>LDA最佳学习资料汇总</li>
</ul>
<h4 id="1-4_Spectral_Clustering">1.4 Spectral Clustering</h4><ul>
<li>Spectral Clustering最佳学习资料汇总</li>
</ul>
<h4 id="1-5_图像处理">1.5 图像处理</h4><ul>
<li>图像处理和计算机视觉中的经典论文</li>
</ul>
<h4 id="2_线性回归模型">2 线性回归模型</h4><ul>
<li>PRML 第3章 Linear Models for Regression</li>
<li>MLAPP 第7章 Linear Regression 第13章 Sparse Linear Models</li>
<li>ESL 第3章 Linear Method for Regression</li>
</ul>
<h4 id="3_线性分类模型">3 线性分类模型</h4><ul>
<li>PRML 第4章 Linear Models for Classification</li>
<li>MLAPP 第8章 Logistic Regression 第9章 Generalized Linear Models and the exponential family</li>
<li>ESL 第4章 Linear Method for Classification</li>
<li>统计机器学习 第6章 逻辑斯谛回归与最大熵模型</li>
</ul>
<h4 id="4_神经网络">4 神经网络</h4><ul>
<li>PRML 第5章 Neural Networks</li>
<li>ESL 第11章 Neural Networks</li>
<li>统计学习方法 第2章 感知机</li>
<li>机器学习 第4章 人工神经网络</li>
</ul>
<h4 id="5_支持向量机">5 支持向量机</h4><ul>
<li>统计学习方法 第7章 支持向量机 (强烈推荐)</li>
<li>PRML 第6章 Kernel Methods 第7章 Sparse Kernel Machine</li>
<li>ESL 第12章 Support Vector Machines and Flexible Discriminants</li>
<li>MLAPP 第14章 Kernels</li>
</ul>
<h4 id="6_图模型">6 图模型</h4><ul>
<li>PRML 第8章 Graphical Models</li>
<li>MLAPP 第10章 Directed graphical models（Bayes nets） 第19章 Undirected Graphical Models（Marcov random fields）第20章 Exact inference for graphical models 第26章 Graphical model structure learning</li>
<li>统计学习方法 第10章 隐马尔可夫模型 第11章 条件随机场</li>
<li>机器学习 6.11 贝叶斯信念网</li>
<li>ESL 第17章 Undirected Graphical Models</li>
<li>Koller 的书</li>
<li>Jordan 的书</li>
</ul>
<h4 id="7_混合模型和EM">7 混合模型和EM</h4><ul>
<li>PRML 第9章 Mixture Models and EM</li>
<li>MLAPP 第11章 Mixture models and the EM algorithm</li>
<li>ESL 8.5 The EM Algorithm</li>
<li>统计学习方法 第9章 EM算法及其推广</li>
</ul>
<h4 id="8_近似推理">8 近似推理</h4><ul>
<li>PRML 第10章 Approximate Inference</li>
<li>MLAPP 第21章 Variational Inference 第22章 More Variational Inference</li>
</ul>
<h4 id="9_采样方法">9 采样方法</h4><ul>
<li>PRML 第11章 Sampling Methods</li>
<li>MLAPP 第23章 Monte Carlo inference 第24章 Markov Chain Monte Carlo (MCMC) inference</li>
<li>ESL 8.6 MCMC for Sampling from Posterior</li>
</ul>
<h4 id="10_PCA">10 PCA</h4><ul>
<li>PRML 第12章 Continuous Latent Variables</li>
<li>MLAPP 第12章 Latent Linear Models</li>
<li>ESL 14.5 Principal Componens， Curves and Surfaces</li>
</ul>
<h4 id="11_HMM">11 HMM</h4><ul>
<li>PRML 13.1 13.2 Hidden Marcov Models</li>
<li>MLAPP 第17章 Marcov and Hidden Marcov Models</li>
</ul>
<h4 id="12_组合模型">12 组合模型</h4><ul>
<li>(投票，boosting，bagging，树模型，model averaging)</li>
<li>PRML 第14章 Combining Models</li>
<li>统计学习方法 第5章 决策树 第8章 提升方法</li>
<li>MLAPP 第16章 Adaptive basis function models</li>
<li>ESL 第15章 Random Forests 第16章 Ensemble Learning 8.7 Bagging 第9章 Additive Models, Trees, and Related Methods 第10章 Boosting and Additive Trees</li>
<li>机器学习 第3章 决策树学习</li>
</ul>
<h4 id="14_聚类">14 聚类</h4><ul>
<li>ESL 14.3 Cluster Analysis</li>
<li>MLAPP 25章 Clustering</li>
<li>PRML 9.1 K-means Clustering</li>
</ul>
<h4 id="15_近邻">15 近邻</h4><ul>
<li>ELS 第13章 Protype Methods and Nearest-Neighbors</li>
</ul>
<h4 id="16_Deep_Learning">16 Deep Learning</h4><ul>
<li><a href="http://deeplearning.net/" target="_blank" rel="external">http://deeplearning.net/</a></li>
<li>Deep Learning Tutorial</li>
<li>MLAPP 第28章 Deep Learning</li>
</ul>
<h4 id="2-2_Deep_Learning教程">2.2 Deep Learning教程</h4><ul>
<li>UFLDL-斯坦福大学Andrew Ng教授“Deep Learning”教程</li>
</ul>
<h3 id="3-_自然语言处理入门篇">3. 自然语言处理入门篇</h3><h4 id="3-1_斯坦福大学自然语言处理公开课">3.1 斯坦福大学自然语言处理公开课</h4><ul>
<li>NLP | 斯坦福  授课教师是 Dan Jurafsky 以及 Christopher Manning，英文不是很有信心的可以参考《斯坦福大学自然语言处理公开课中文解读》</li>
<li>NLP | 哥伦比亚 授课老师是Michael Collins大神</li>
</ul>
<h4 id="3-2_统计机器翻译">3.2 统计机器翻译</h4><ul>
<li>Statistical Machine Translation</li>
<li>统计机器翻译开源软件汇总</li>
</ul>
<p>转自：<a href="http://www.52ml.net/star?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="external">http://www.52ml.net/star?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><img src="/images/other/ml.jpg" alt=""></p>
<p>注：本页面主要针对想快速上手机器学习而又不想深入研究的同学，对于专门的researcher，建议直接啃PRML，ESL，MLAPP以及你相应方向的书（比如Numerical Opt]]>
    </summary>
    
      <category term="PPTP, vpn" scheme="http://www.notehub.cn/tags/PPTP-vpn/"/>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to customize Writable class in Hadoop]]></title>
    <link href="http://www.notehub.cn/2015/09/21/dev/How%20to%20customize%20Writable%20class%20in%20Hadoop/"/>
    <id>http://www.notehub.cn/2015/09/21/dev/How to customize Writable class in Hadoop/</id>
    <published>2015-09-21T04:49:45.000Z</published>
    <updated>2015-09-21T06:13:25.000Z</updated>
    <content type="html"><![CDATA[<p>I’m trying to implement Writable class, but i have no idea on how to implement a writable class if in my class there is nested object, such as list, etc.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StorageClass</span> <span class="keyword">implements</span> <span class="title">Writable</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> String xStr;</span><br><span class="line"><span class="keyword">public</span> String yStr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> List&lt;Field&gt; sStor</span><br><span class="line"></span><br><span class="line"><span class="comment">//omitted ctors</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="annotation">@override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    out.writeChars(xStr);</span><br><span class="line">    out.WriteChars(yStr);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//WHAT SHOULD I DO FOR List&lt;Field&gt;</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="annotation">@override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    xStr = in.readLine();</span><br><span class="line">    yStr = in.readLine();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//WHAT SHOULD I DO FOR List&lt;Field&gt;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SubStorage</span></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> String x;</span><br><span class="line">    <span class="keyword">public</span> String y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Following is the Field class:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Field</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Field</span>&gt;, <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> DataType dataType;</span><br><span class="line">    <span class="keyword">private</span> Object value;</span><br><span class="line">    <span class="keyword">private</span> FieldType fieldType;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Field</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  <span class="title">Field</span><span class="params">(String name, DataType dataType, FieldType fieldType)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(name, dataType, <span class="keyword">null</span>, fieldType);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  <span class="title">Field</span><span class="params">(String name, DataType type, Object value, FieldType fieldType)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.dataType = type;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.fieldType = fieldType;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> FieldType &#123;</span><br><span class="line">    PRI, LOOKUP, SCD, VERSION, OTHER</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> DataType &#123;</span><br><span class="line"></span><br><span class="line">    UNDEFINED(<span class="number">4</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSizeInBytes</span><span class="params">(Object value)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> STRING.getSizeInBytes(value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    STRING(<span class="number">4</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSizeInBytes</span><span class="params">(Object value)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">super</span>.getSizeInBytes(value) + (value.toString().length() * <span class="number">2</span>); <span class="comment">// length + chars</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    INT(<span class="number">4</span>),</span><br><span class="line">    LONG(<span class="number">8</span>),</span><br><span class="line">    DOUBLE(<span class="number">8</span>),</span><br><span class="line">    DATETIME(<span class="number">8</span>),</span><br><span class="line">    BOOLEAN(<span class="number">1</span>),</span><br><span class="line">    BYTE(<span class="number">1</span>),</span><br><span class="line">    FLOAT(<span class="number">4</span>),</span><br><span class="line">    SHORT(<span class="number">2</span>),</span><br><span class="line">    CHAR(<span class="number">2</span>),</span><br><span class="line">    DATE(<span class="number">8</span>),</span><br><span class="line">    TIME(<span class="number">8</span>),</span><br><span class="line"></span><br><span class="line">    BLOB(<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSizeInBytes</span><span class="params">(Object value)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> ((<span class="keyword">byte</span>[])value).length;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sizeInBytes;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">DataType</span><span class="params">(<span class="keyword">int</span> sizeInBytes)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sizeInBytes = sizeInBytes;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSizeInBytes</span><span class="params">(Object value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> sizeInBytes;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Serializing collections is quite simple.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> size = in.readInt();</span><br><span class="line">    list= <span class="keyword">new</span> ArrayList&lt;Field&gt;(size);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)&#123;</span><br><span class="line">        Field f = <span class="keyword">new</span> Field();</span><br><span class="line">        f.readFields(in);</span><br><span class="line">        list.add(f);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    out.writeInt(list.size());</span><br><span class="line">    <span class="keyword">for</span> (Field l : list) &#123;</span><br><span class="line">        l.write(out);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>I’m trying to implement Writable class, but i have no idea on how to implement a writable class if in my class there is nested object, su]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[MurmurHash]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/murmurhash-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/murmurhash-md/</id>
    <published>2015-09-03T06:55:54.000Z</published>
    <updated>2015-09-03T06:58:03.000Z</updated>
    <content type="html"><![CDATA[<p>　　MurmurHash 是一种非加密型哈希函数，适用于一般的哈希检索操作。由Austin Appleby在2008年发明，并出现了多个变种，都已经发布到了公有领域(public domain)。与其它流行的哈希函数相比，对于规律性较强的key，MurmurHash的随机分布特征表现更良好。</p>
<h3 id="变种">变种</h3><p>　　当前的版本是MurmurHash3， 能够产生出32-bit或128-bit哈希值。较早的MurmurHash2能产生32-bit或64-bit哈希值。对于大端存储和强制对齐的硬件环境有一个较慢的MurmurHash2可以用。MurmurHash2A 变种增加了Merkle–Damgård 构造，所以能够以增量方式调用。 有两个变种产生64-bit哈希值：MurmurHash64A，为64位处理器做了优化；MurmurHash64B，为32位处理器做了优化。MurmurHash2-160用于产生160-bit 哈希值，而MurmurHash1已经不再使用。</p>
<h3 id="实现">实现</h3><p>　　最初的实现是C++的，但是被移植到了其他的流行语言上，包括 Python, C,C#, Perl, Ruby, PHP,Haskell,、Scala、Java和JavaScript等。这个算法已经被若干开源计划所采纳，最重要的有libstdc++ (4.6版)、Perl、nginx (不早于1.0.1版)、Rubinius、 libmemcached (Memcached的C语言客户端驱动)、maatkit、Hadoop、Kyoto Cabinet以及RaptorDB。</p>
<p>A sample C implementation follows:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">uint32_t</span> murmur3_32(<span class="keyword">const</span> <span class="keyword">char</span> *key, <span class="keyword">uint32_t</span> len, <span class="keyword">uint32_t</span> seed) &#123;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> c1 = <span class="number">0xcc9e2d51</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> c2 = <span class="number">0x1b873593</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> r1 = <span class="number">15</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> r2 = <span class="number">13</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> m = <span class="number">5</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> n = <span class="number">0xe6546b64</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">uint32_t</span> hash = seed;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">int</span> nblocks = len / <span class="number">4</span>;</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">uint32_t</span> *blocks = (<span class="keyword">const</span> <span class="keyword">uint32_t</span> *) key;</span><br><span class="line">	<span class="keyword">int</span> i;</span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; nblocks; i++) &#123;</span><br><span class="line">		<span class="keyword">uint32_t</span> k = blocks[i];</span><br><span class="line">		k *= c1;</span><br><span class="line">		k = (k &lt;&lt; r1) | (k &gt;&gt; (<span class="number">32</span> - r1));</span><br><span class="line">		k *= c2;</span><br><span class="line"> </span><br><span class="line">		hash ^= k;</span><br><span class="line">		hash = ((hash &lt;&lt; r2) | (hash &gt;&gt; (<span class="number">32</span> - r2))) * m + n;</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">uint8_t</span> *tail = (<span class="keyword">const</span> <span class="keyword">uint8_t</span> *) (key + nblocks * <span class="number">4</span>);</span><br><span class="line">	<span class="keyword">uint32_t</span> k1 = <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">switch</span> (len &amp; <span class="number">3</span>) &#123;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">		k1 ^= tail[<span class="number">2</span>] &lt;&lt; <span class="number">16</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">		k1 ^= tail[<span class="number">1</span>] &lt;&lt; <span class="number">8</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">		k1 ^= tail[<span class="number">0</span>];</span><br><span class="line"> </span><br><span class="line">		k1 *= c1;</span><br><span class="line">		k1 = (k1 &lt;&lt; r1) | (k1 &gt;&gt; (<span class="number">32</span> - r1));</span><br><span class="line">		k1 *= c2;</span><br><span class="line">		hash ^= k1;</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">	hash ^= len;</span><br><span class="line">	hash ^= (hash &gt;&gt; <span class="number">16</span>);</span><br><span class="line">	hash *= <span class="number">0x85ebca6b</span>;</span><br><span class="line">	hash ^= (hash &gt;&gt; <span class="number">13</span>);</span><br><span class="line">	hash *= <span class="number">0xc2b2ae35</span>;</span><br><span class="line">	hash ^= (hash &gt;&gt; <span class="number">16</span>);</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">return</span> hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="相关资源：">相关资源：</h3><ol>
<li><a href="http://blog.csdn.net/yfkiss/article/details/7337382" target="_blank" rel="external">http://blog.csdn.net/yfkiss/article/details/7337382</a></li>
<li><a href="https://zh.wikipedia.org/wiki/Murmur%E5%93%88%E5%B8%8C" target="_blank" rel="external">https://zh.wikipedia.org/wiki/Murmur%E5%93%88%E5%B8%8C</a></li>
<li><a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="external">https://en.wikipedia.org/wiki/MurmurHash</a></li>
<li><a href="https://github.com/lijingpeng/java_util/tree/master/src/util/hash" target="_blank" rel="external">https://github.com/lijingpeng/java_util/tree/master/src/util/hash</a></li>
<li><a href="https://github.com/huichen/murmur/blob/master/murmur.go" target="_blank" rel="external">https://github.com/huichen/murmur/blob/master/murmur.go</a></li>
<li><a href="https://pypi.python.org/pypi/mmh3/2.0" target="_blank" rel="external">https://pypi.python.org/pypi/mmh3/2.0</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　MurmurHash 是一种非加密型哈希函数，适用于一般的哈希检索操作。由Austin Appleby在2008年发明，并出现了多个变种，都已经发布到了公有领域(public domain)。与其它流行的哈希函数相比，对于规律性较强的key，MurmurHash的随机分]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Java beta distribution]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/java-beta-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/java-beta-md/</id>
    <published>2015-09-03T06:51:59.000Z</published>
    <updated>2015-09-03T06:54:33.000Z</updated>
    <content type="html"><![CDATA[<p>维基百科介绍：<a href="https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83" target="_blank" rel="external">https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83</a><br><a href="https://en.wikipedia.org/wiki/Beta_distribution" target="_blank" rel="external">https://en.wikipedia.org/wiki/Beta_distribution</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.commons.math3.distribution.BetaDistribution;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">test</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span><br><span class="line">     * <span class="doctag">@param</span> args</span><br><span class="line">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span> x;</span><br><span class="line">        <span class="keyword">double</span> b;</span><br><span class="line">        BetaDistribution beta = <span class="keyword">new</span> BetaDistribution(<span class="number">40.0</span>, <span class="number">40.0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">            x = Math.random();</span><br><span class="line">            b = beta.inverseCumulativeProbability(x);</span><br><span class="line">            System.out.println(b);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实现：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BetaDistributionE</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getBetaDistribution</span><span class="params">(<span class="keyword">double</span> alpha, <span class="keyword">double</span> beta)</span></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> a = alpha + beta;</span><br><span class="line">	<span class="keyword">double</span> b;</span><br><span class="line">	<span class="keyword">if</span>(Math.min(alpha, beta) &lt;= <span class="number">1</span>)&#123;</span><br><span class="line">		b = Math.max(<span class="number">1</span>/alpha, <span class="number">1</span>/beta);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span>&#123;</span><br><span class="line">	b = Math.sqrt((a - <span class="number">2</span>) / (<span class="number">2</span>*alpha*beta - a));</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">double</span> c = alpha + <span class="number">1</span>/b;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">double</span> W = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">boolean</span> reject = <span class="keyword">true</span>;</span><br><span class="line">	<span class="keyword">for</span> (reject = <span class="keyword">true</span>; reject; ) &#123;</span><br><span class="line"> 		<span class="keyword">double</span> U1 = Math.random();</span><br><span class="line"> 		<span class="keyword">double</span> U2 = Math.random();</span><br><span class="line"> 		<span class="keyword">double</span> V = b * Math.log(U1/(<span class="number">1</span>-U1));</span><br><span class="line"> 		W = alpha * Math.exp(V);</span><br><span class="line"> 		reject = (a*Math.log(a/(beta+W)) + c*V - Math.log(<span class="number">4</span>)) &lt; Math.log(U1*U1*U2);</span><br><span class="line"> 	&#125;</span><br><span class="line"> 	<span class="keyword">return</span> (W / (beta + W));</span><br><span class="line"> 	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>相关资源：</p>
<ol>
<li><a href="http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math3/distribution/BetaDistribution.html" target="_blank" rel="external">http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math3/distribution/BetaDistribution.html</a></li>
<li><a href="http://stackoverflow.com/questions/13634170/java-using-beta-distribution-to-generate-a-random-number-from-0-to-1" target="_blank" rel="external">http://stackoverflow.com/questions/13634170/java-using-beta-distribution-to-generate-a-random-number-from-0-to-1</a></li>
<li>go语言实现：<a href="https://github.com/purzelrakete/bandit/blob/4fca67f963006845de83860fcd849625251fce57/math/rand.go#L21" target="_blank" rel="external">https://github.com/purzelrakete/bandit/blob/4fca67f963006845de83860fcd849625251fce57/math/rand.go#L21</a></li>
<li>非均衡抽样，在一个概率区间内抽样：Paper：Generating Beta Variates with Nonintegral Shape Parameters</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>维基百科介绍：<a href="https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83" target="_blank" rel="external">https://zh.wikipedia.org/wiki/%CE%]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[二项分布和Beta分布]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/beta-a-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/beta-a-md/</id>
    <published>2015-09-03T06:33:26.000Z</published>
    <updated>2015-09-03T06:49:32.000Z</updated>
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br></pre></td></tr></table></figure>
<h2 id="二项分布">二项分布</h2><hr>
<p>　　在概率论和统计学中，二项分布是n个独立的[是/非]试验中成功的次数的离散概率分布，其中每次试验的成功概率为$p$。举两个例子就很容易理解二项分布的含义了：</p>
<ul>
<li>抛一次硬币出现正面的概率是0.5($p$)，抛10(n)次硬币，出现k次正面的概率。</li>
<li>掷一次骰子出现六点的概率是1/6，投掷6次骰子出现k次六点的概率。</li>
</ul>
<p>　　在上面的两个例子中，每次抛硬币或者掷骰子都和上次的结果无关，所以每次实验都是独立的。二项分布是一个离散分布，k的取值范围为从0到n，只有n+1种可能的结果。scipy.stats.binom为二项分布，下面用它计算抛十次硬币，出现k次正面的概率分布。</p>
<h4 id="In_[16]:">In [16]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = np.arange(n+<span class="number">1</span>)</span><br><span class="line">pcoin = stats.binom.pmf(k, n, <span class="number">0.5</span>)</span><br><span class="line">pcoin</span><br></pre></td></tr></table></figure>
<h4 id="Out[16]:">Out[16]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([ <span class="number">0.00097656</span>,  <span class="number">0.00976563</span>,  <span class="number">0.04394531</span>,  <span class="number">0.1171875</span> ,  <span class="number">0.20507813</span>,</span><br><span class="line">        <span class="number">0.24609375</span>,  <span class="number">0.20507813</span>,  <span class="number">0.1171875</span> ,  <span class="number">0.04394531</span>,  <span class="number">0.00976563</span>,</span><br><span class="line">        <span class="number">0.00097656</span>])</span><br></pre></td></tr></table></figure>
<h4 id="In_[17]:">In [17]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pl.stem(k, pcoin, basefmt=<span class="string">"k-"</span>)</span><br><span class="line">pl.margins(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss.png" alt=""><br>下面是投掷6次骰子，出现6点的概率分布。</p>
<h4 id="In_[18]:">In [18]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">6</span></span><br><span class="line">k = np.arange(n+<span class="number">1</span>)</span><br><span class="line">pdice = stats.binom.pmf(k, n, <span class="number">1.0</span>/<span class="number">6</span>)</span><br><span class="line">pdice</span><br></pre></td></tr></table></figure>
<h4 id="Out[18]:">Out[18]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([  <span class="number">3.34897977e-01</span>,   <span class="number">4.01877572e-01</span>,   <span class="number">2.00938786e-01</span>,</span><br><span class="line">         <span class="number">5.35836763e-02</span>,   <span class="number">8.03755144e-03</span>,   <span class="number">6.43004115e-04</span>,</span><br><span class="line">         <span class="number">2.14334705e-05</span>])</span><br></pre></td></tr></table></figure>
<h4 id="In_[19]:">In [19]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pl.stem(k, pdice, basefmt=<span class="string">"k-"</span>)</span><br><span class="line">pl.margins(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss1.png" alt=""></p>
<h2 id="Beta分布">Beta分布</h2><hr>
<p>　　对于硬币或者骰子这样的简单实验，我们事先能很准确地掌握系统成功的概率。然而通常情况下，系统成功的概率是未知的。为了测试系统的成功概率$p$，我们做n次试验，统计成功的次数k，于是很直观地就可以计算出$p = k/n$。然而由于系统成功的概率是未知的，这个公式计算出的$p$只是系统成功概率的最佳估计。也就是说实际上$p$也可能为其它的值，只是为其它的值的概率较小。</p>
<p>　　例如有某种特殊的硬币，我们事先完全无法确定它出现正面的概率。然后抛10次硬币，出现5次正面，于是我们认为硬币出现正面的概率最可能是0.5。但是即使硬币出现正面的概率为0.4，也会出现抛10次出现5次正面的情况。因此我们并不能完全确定硬币出现正面的概率就是0.5，所以$p$也是一个随机变量，它符合Beta分布。</p>
<p>　　Beta分布是一个连续分布，由于它描述概率$p$的分布，因此其取值范围为0到1。 Beta分布有$\alpha$和$\beta$两个参数，其中$\alpha$为成功次数加1，$\beta$为失败次数加1。连续分布用概率密度函数描述，下面绘制实验10次，成功4次和5次时，系统成功概率$p$的分布情况。可以看出$k=5$时，曲线的峰值在$p=0.5$处，而$k=4$时，曲线的峰值在$p=0.4$处。</p>
<h4 id="In_[20]:">In [20]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = <span class="number">5</span></span><br><span class="line">p = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"k=5"</span>, lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"k=4"</span>, lw=<span class="number">2</span>)</span><br><span class="line">xlabel(<span class="string">"$p$"</span>)</span><br><span class="line">legend(loc=<span class="string">"best"</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss3.png" alt=""><br>　　下面绘制$n=10, k=4$和$n=20, k=8$的概率分布。可以看出峰值都在$p=0.4$处，但是$n=20$的山峰更陡峭。也就是说随着实验次数的增加，$p$取其它值的可能就越小，对$p$的估计就更有信心，因此山峰也就更陡峭了。</p>
<h4 id="In_[30]:">In [30]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">p = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"n=10"</span>, lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">20</span></span><br><span class="line">k = <span class="number">8</span></span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"n=20"</span>, lw=<span class="number">2</span>)</span><br><span class="line">xlabel(<span class="string">"$p$"</span>)</span><br><span class="line">legend(loc=<span class="string">"best"</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss4.png" alt=""></p>
<h2 id="用pymc模拟">用pymc模拟</h2><hr>
<p>　　假设我们的知识库中没有Beta分布，如何通过模拟实验找出$p$的概率分布呢？pymc是一个用于统计估计的库，它可以通过 先验概率和 观测值 模拟出 后验概率 的分布。下面先解释一下这两个概率：</p>
<ul>
<li>先验概率：在贝叶斯统计中，某一不确定量p的先验概率分布是在考虑”观测数据”前，能表达p不确定性的概率分布。</li>
<li>后验概率：在考虑相关证据或数据后所得到的不确定量p的概率分布。</li>
</ul>
<p>　　拿前面抛硬币的实验来说，如果在做实验之前能确信硬币出现正面的概率大概在0.5附近的话，那么它的先验概率就是一个以0.5为中心的山峰波形。而如果是某种特殊的硬币，我们对其出现正面的概率完全不了解，那么它的先验概率就是一个从0到1的平均分布。为了估计这个特殊硬币出现正面的概率，我们做了20次实验，其中出现了8次正面。通过这个实验，硬币出现正面的可能性的后验概率就如上图中的绿色曲线所示。</p>
<p>　　pymc库可以通过先验概率和观测值模拟出后验概率的分布，这对于一些复杂的系统的估计是很有用的。下面我们看看如何用pymc来对这个特殊硬币出现正面的可能性进行估计：首先pcoin是这个特殊硬币出现正面的概率，由于我们没有任何先验知识，因此它的先验概率是一个从0到1的平均分布(Uniform)。假设我们做了20次实验，其中8次为正面。根据前面的介绍可知，出现正面的次数符合二项分布(Binomial)，并且这个二项分布的概率$p$为pcoin。这个通过value参数指定了实验的结果。因此experiment虽然是一个二项分布，但是它已经不能取其它值了。</p>
<h4 id="In_[32]:">In [32]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymc</span><br><span class="line">pcoin = pymc.Uniform(<span class="string">"pcoin"</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">experiment = pymc.Binomial(<span class="string">"experiment"</span>, <span class="number">20</span>, pcoin, value=<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<p>　　接下来通过MCMC对象模拟pcoin的后验概率。MCMC是Markov chain Monte Carlo(马尔科夫蒙特卡洛)的缩写，它是一种用马尔可夫链从随机分布取样的算法。通过调用MCMC对象的sample()，可以对pcoin的后验概率分布进行取样。这里30000为取样次数，5000表示不保存头5000次取样值。这时因为MCMC算法通常有一个收敛过程，我们希望只保留收敛之后的取样值。</p>
<h4 id="In_[33]:">In [33]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mc = pymc.MCMC([pcoin])</span><br><span class="line">mc.sample(<span class="number">30000</span>, <span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<p>[<strong><strong><strong><em>**</em></strong></strong></strong>100%<strong><strong><strong><strong>**</strong></strong></strong></strong>]  30000 of 30000 complete<br>　　通过MCMC对象trace()可以获得某个不确定量的取样值。下面的程序获得pcoin的25000次取样值，并用hist()显示其分布情况。由结果可知pcoin的分布与前面介绍的Beta分布一致。</p>
<h4 id="In_[31]:">In [31]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pcoin_trace = mc.trace(<span class="string">"pcoin"</span>)[:]</span><br><span class="line">hist(pcoin_trace, normed=<span class="keyword">True</span>, bins=<span class="number">30</span>);</span><br><span class="line">plot(p, pbeta, <span class="string">"r"</span>, label=<span class="string">"n=20"</span>, lw=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Out[31]:">Out[31]:</h4><p><img src="/images/algo/ssss5.png" alt=""></p>
<h4 id="In_[34]:">In [34]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcoin_trace.shape</span><br></pre></td></tr></table></figure>
<h4 id="Out[34]:">Out[34]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">25000</span>,)</span><br></pre></td></tr></table></figure>
<p>链接：<a href="http://hyry.dip.jp/tech/slice/slice.html/42" target="_blank" rel="external">http://hyry.dip.jp/tech/slice/slice.html/42</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span clas]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[理解Beta分布和Dirichlet分布]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/beta-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/beta-md/</id>
    <published>2015-09-03T06:18:04.000Z</published>
    <updated>2015-09-03T06:31:39.000Z</updated>
    <content type="html"><![CDATA[<p><br><br>在Machine Learning中，有一个很常见的概率分布叫做Beta Distribution：<br><img src="/images/algo/j8b261e3942f702b2a36d5221f9a006bf.png" alt=""><br>同时，Dirichelet Distribution：</p>
<p><img src="/images/algo/j24fc194e3126c49d315032f55d0a52e2.png" alt=""></p>
<h3 id="解释">解释</h3><hr>
<p>　　如果给你一个硬币，投这个硬币有\theta的概率抛出Head，有(1-\theta)的概率抛出Tail。如果在未来抛了五次这个硬币，有三次是Head，有两次是Tail，这个\theta最有可能是多少呢？如果你必须给出一个确定的值，并且你完全根据目前观测的结果来估计\theta，那么\theta = 3/5。</p>
<p><img src="/images/algo/a.png" alt=""></p>
<p>　　如果未来抛出五次硬币，全部都是Head。那么按照1中的逻辑，你将估计\theta为1。也就是说，你估计这枚硬币不管怎么投，都朝上！可是，你想这或许是巧合：世界上没有这么屌的硬币，硬币还是有一定可能抛出Tail的。就算观测到再多次的Head，抛出Tail的概率还是不可能为0。这时候，Bayesian公式横空出世（如下图所示）。我们在估计\theta时，心中先有一个估计，即先验概率。这个估计，表现在Probability中，就是一个概率分布。通俗得来讲，我们不再认为\theta是个固定的值了。</p>
<p><img src="/images/algo/j8b6e228eaeb570260d0f8c12a18add50.png" alt=""></p>
<p>　　在上面的Bayesian公式中，p(\theta)就是个概率分布。这个概率分布可以是任何概率分布，比如高斯分布，比如我们想要说的Beta Distribution。下图是Beta(5,2)的概率分布图。如果我们将这个概率分布作为p(\theta)，那么我们在还未抛硬币前，便认为\theta很可能接近于0.8，而不大可能是个很小的值或是一个很大的值。即，我们在抛硬币前，便估计这枚硬币更可能有0.8的概率抛出正面。</p>
<p><img src="/images/algo/j9f3ba3610336773ac92573a548621b3e.png" alt=""></p>
<p>　　虽然p(\theta)可以是任何种类的概率分布，但是如果使用Beta Distribution，会让之后的计算更加方便。我们接着继续看便知道这是为什么了。况且，通过调节Beta Distribution中的a和b，你可以让这个概率分布变成各种你想要的形状！Beta Distribution已经很足够表达你事先对\theta的估计了。现在我们已经估计好了p(\theta)为一个Beta Distribution，那么p(X|\theta)是多少呢？其实就是个二项分布。继续以1中抛5次硬币抛出3次Head为例，X=抛5次硬币抛出3个Head的事件。</p>
<p><img src="/images/algo/ja3a99d005b464c5164166547afc9e13b.png" alt=""><br>　　Bayesian公式下的p(X)是个Normalizer，或者叫做marginal probability。在\theta离散的情况下，p(X)就是\theta为不同值的时候，p(X|\theta)的求和。比如，如果我们事先估计硬币抛出正面的概率只可能是0.5或者0.8，那么p(X) = p(X|\theta=0.5)+p(X|\theta=0.8)，计算时分别将\theta=0.5和\theta=0.8代入到7中的公式中。而如果我们用Beta Distribution，\theta的概率分布在[0,1]之间是连续的，所以要用积分。</p>
<p><img src="/images/algo/j48e8020e87f818d9414e03ffb9fcf248.png" alt=""></p>
<p>　　p(\theta)是个Beta Distribution，那么在观测到X=抛5次硬币中有3个head的事件后，p(\theta|X)依旧是个Beta Distribution！只是这个概率分布的形状因为观测的事件而发生了变化。<br><img src="/images/algo/j0eca37b51f989944703ffbabadb40086.png" alt=""></p>
<p>　　因为观测前后，对\theta估计的概率分布均为Beta Distribution，这就是为什么使用Beta Distribution方便我们计算的原因了。当我们得知p(\theta|X)=Beta(\theta|a+3, b+2)后，我们就只要根据Beta Distribution的特性，得出\theta最有可能等于多少了。（即\theta等于多少时，观测后得到的Beta distribution有最大的概率密度）。例如下图，仔细观察新得到的Beta Distribution，和（5）中的概率分布对比，发现峰值从0.8左右的位置移向了0.7左右的位置。这是因为新观测到的数据中，5次有3次是head（60%），这让我们觉得，\theta没有0.8那么高。但由于我们之前觉得\theta有0.8那么高，我们觉得抛出head的概率肯定又要比60%高一些！这就是Bayesian方法和普通的统计方法不同的地方。我们结合自己的先验概率和观测结果来给出预测。</p>
<p><img src="/images/algo/j01a0b8b112291e2355890ac32572b01b.png" alt=""></p>
<p>　　如果我们投的不是硬币，而是一个多面体（比如筛子），那么我们就要使用Dirichlet Distribution了。使用Dirichlet Distributio的目的，也是为了让观测后得到的posterior probability依旧是Dirichlet Distribution。比如，我们抛掷一个三面体。抛出这三个面的概率分别为\theta_1, \theta_2和\theta_3。不论\theta_1, \theta_2和\theta_3如何分布，它们相加必须等于1。那它们的概率分布，是在一个立体的空间里的一个面。这个面由\theta_1+\theta_2+\theta_3=1表示。这个面上的任意一点，表示某种\theta_1, \theta_2和\theta_3组合的概率密度。下三图分别由不同的\alpha vector初始化得到不同的Dirichlet Distribution，红颜色代表概率密度较大，蓝颜色的区域概率密度较小。</p>
<p><img src="/images/algo/j3f8307ef170c6664eea5996932322a29.png" alt=""><br>　　Dirichlet Distribution和Beta Distribution都叫做Conjugate Prior。根据你的likelihood function，你可以选择对应的conjugate prior作为你对p(\theta)事先的估计。<br><img src="/images/algo/j3481aac389b57152d20380150d0abd4a.png" alt=""><br>转自：<a href="http://maider.blog.sohu.com/306392863.html" target="_blank" rel="external">http://maider.blog.sohu.com/306392863.html</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><br><br>在Machine Learning中，有一个很常见的概率分布叫做Beta Distribution：<br><img src="/images/algo/j8b261e3942f702b2a36d5221f9a006bf.png" alt=""><br>同时]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[忠诚度越高买东西越贵]]></title>
    <link href="http://www.notehub.cn/2015/09/03/other/nitian-md/"/>
    <id>http://www.notehub.cn/2015/09/03/other/nitian-md/</id>
    <published>2015-09-03T06:01:28.000Z</published>
    <updated>2015-09-03T06:07:50.000Z</updated>
    <content type="html"><![CDATA[<p>　　引言：马云曾说，阿里巴巴本质上就是一家数据公司，做淘宝的目的也不是为了卖货，而是获得所有零售的数据和制造业的数据；做物流也不仅仅为了送包裹，而是要把这些数据合在一起。而亚马逊公司作为美国最大的一家网络电子商务公司，是网络上最早开始经营电子商务的公司之一，20年的持续发展关键也离不开对数据的分析。如今，我们正从IT时代走向DT时代，即从information technology转向data technology。</p>
<p>　　先问大家一个问题，AB两个顾客同时想买某个品牌的东西，其中A顾客对这个品牌非常喜欢，B是新顾客。如果你是这个品牌的经营者的话，你会卖给谁更贵（假设不是标准定价）？</p>
<p>　　答案是A，我们很多人的观点是我们一定要对老顾客好一些，给他们最优的待遇。这其实是从消费者的角度出发思考，其实从经营的角度来说，忠诚度越高我们反而应该卖得更贵，因为企业经营是追求利润最大化（互联网思维的企业除外哈），另外忠诚度高的顾客不用太担心流失。</p>
<p>　　欺负老顾客，这是一个人艰不拆的真理，会让很多人眼泪忍不住的流下来。其实现在不就是这样的吗？首次打车的顾客免单，第一次购买电影票补贴，第一次消费打折等等。只是这些我们能接受，我们认为合理，接下来讲一个真实的差异化定价的案例。</p>
<h3 id="亚马逊差异化定价测试">亚马逊差异化定价测试</h3><p>　　为提高在主营产品上的赢利，亚马逊在2000年9月中旬开始了著名的差别定价实验。他们选择了68种DVD碟片进行动态定价试验。试验当中，亚马逊根据潜在客户的人口统计资料、在亚马逊的购物历史、上网行为以及上网使用的软件系统确定对这68种碟片的报价水平。</p>
<p>　　例如，名为《泰特斯》（Titus）的碟片对新顾客的报价为22.74美元，而对那些对该碟片表现出兴趣的老顾客的报价则为26.24美元。通过这一定价策略，部分顾客付出了比其他顾客更高的价格，亚马逊因此提高了销售的毛利率。（网络购物可以做到千人千面，每个人看到的页面不一样，价格也可以不一样）</p>
<p>　　但是好景不长，这一差别定价策略实施不到一个月，就有细心的消费者发现了这一秘密，通过在名为DVDTalk 的音乐爱好者社区的交流，成百上千的DVD消费者知道了此事，那些付出高价的顾客当然怨声载道，纷纷在网上以激烈的言辞对亚马逊的做法进行口诛笔伐，有人甚至公开表示以后绝不会在亚马逊购买任何东西。更不巧的是，由于亚马逊前不久才公布了它对消费者在网站上的购物习惯和行为进行了跟踪和记录，因此，这次事件曝光后，消费者和媒体开始怀疑亚马逊是否利用其收集的消费者资料作为其价格调整的依据，这样的猜测让亚马逊的价格事件与敏感的网络隐私问题联系在了一起。最后的结局是亚马逊道歉，然后将差价退给了那些买贵了的顾客。这件事虽然以失败告终，但是这种差异化定价的思路却是可以借鉴的。</p>
<p>　　放眼望去，我们身边到处都是差异化定价的案例：菜市场的小贩看人下菜单，不同顾客买到的机票价格都不同，会员和非会员的价格也不一样，买的多和买得少价格也不一样。唯一不一样的是，这些差异化定价是按照我们常人的逻辑在运行，如买的多就应该便宜。亚马逊的案例恰恰和常规相反，但确实是经营的需要。那么如何做到根据需求差异定价呢？这种需求差异主要体现在时间、地点、消费对象之间三个方面。“时间就是金钱”在这点上彻底体现出来了，新手机上市，如果你是品牌忠实的追随者，那你必须付高价才能得到它，反之，你可以慢慢等待，等到价格降到你的目标价位的时候出手，有些地方高峰电价和平峰电价不一样，机票的价格和距起飞时间成反比，旅游景区的淡旺季门票差异等，这都是需求中利用时间差异的定价方法。</p>
<p>　　新开一个超市如果附近没有竞争对手和有竞争对手时的定价策略是不一样的，一瓶同样品牌的啤酒在超市和酒吧的价格大相径庭，演唱会前排的价格高于后排的价格，海景房的价格比山景房的价格贵等等，这都是需求中地点差异的定价方法。消费对象的定价差异更多体现在会员顾客和非会员顾客的价格差异上，以及女性相对于男性对价格敏感的差异上。未来随着科技的进步会逐渐发展到个体的定价差异上，例如零售商根据你购买或维修冰箱的数据，发现你的冰箱到了更换的时候，就可以给你寄一张200元的冰箱代金券，这样你的价格就和其他人不一样了。需要注意的是差异定价不能引起顾客的反感，需要透彻分析其中的风险。针对亚马逊这个案例，错就错在互联网购物价格太透明了，一旦穿帮就是丑闻。那怎么让顾客不反感，同时企业又能贯彻忠诚度高的顾客价格越贵的原则呢？答案见下图。</p>
<p><img src="/images/bb/792c43ea9c648c61a22c1a50a6439b15.jpg" alt=""><br>看明白了吗？</p>
<p>没看明白的话我就给大家点破吧！</p>
<p>将抽奖结果关联用户数据！</p>
<p>　　怎么理解这句话？就是当买家在网站买东西的时候，旁边放一个抽奖链接，买家可以根据抽奖结果来付款，抽奖结果又减30，减50，一分不减等选项。当买家在按下抽奖按钮的同时，后台大数据就开始工作了，根据你以往的购买数据很快可以算出你对这个商品的忠诚度，喜好度，需要的紧迫性等。当发现你从来没有买过类似的商品的话，就会让你中“大奖”。当发现你是优质买家，那不好意思了，一分不减。这样是不是每个人都高高兴兴的了？你还以为抽奖结果是随机的呢。其实买的永远没有卖的精！你可以看看现在淘宝、京东等消费性电商培都用了这一招！</p>
<h3 id="比较有价值的评论：">比较有价值的评论：</h3><ol>
<li><p>就是利用信息不对称赚钱，不过互联网就是要消除信息不对称，所以这条路其实在互联网上是走不通的</p>
</li>
<li><p>互联网时代，价格是透明的，跨店比价购买的成本近乎为零，同一件商品如果亚马逊卖50，京东卖49，天猫卖45，你猜消 费者会怎么选择？</p>
</li>
<li><p>杀熟很危险，如果用户知道了，可能会对品牌造成致命的影响，而你得到的不过蝇头小利。</p>
</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　引言：马云曾说，阿里巴巴本质上就是一家数据公司，做淘宝的目的也不是为了卖货，而是获得所有零售的数据和制造业的数据；做物流也不仅仅为了送包裹，而是要把这些数据合在一起。而亚马逊公司作为美国最大的一家网络电子商务公司，是网络上最早开始经营电子商务的公司之一，20年的持续发展]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Bayesian Bandits原理及在互联网广告行业的应用]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/</id>
    <published>2015-09-03T05:48:13.000Z</published>
    <updated>2015-09-03T05:59:25.000Z</updated>
    <content type="html"><![CDATA[<h2 id="1-_The_Multi-Armed_Bandit_Problem">1. The Multi-Armed Bandit Problem</h2><p>Suppose you are faced with N slot machines (colourfully called multi-armed bandits). Each bandit has an unknown probability of distributing a prize (assume for now the prizes are the same for each bandit, only the probabilities differ). Some bandits are very generous, others not so much. Of course, you don’t know what these probabilities are. By only choosing one bandit per round, our task is devise a strategy to maximize our winnings.</p>
<p>Of course, if we knew the bandit with the largest probability, then always picking this bandit would yield the maximum winnings. So our task can be phrased as “Find the best bandit, and as quickly as possible”.</p>
<p>The task is complicated by the stochastic nature of the bandits. A suboptimal bandit can return many winnings, purely by chance, which would make us believe that it is a very profitable bandit. Similarly, the best bandit can return many duds. Should we keep trying losers then, or give up?</p>
<p>A more troublesome problem is, if we have a found a bandit that returns pretty good results, do we keep drawing from it to maintain our pretty good score, or do we try other bandits in hopes of finding an even-better bandit? This is the exploration vs. exploitation dilemma.</p>
<h2 id="2-_Applications">2. Applications</h2><p>The Multi-Armed Bandit problem at first seems very artificial, something only a mathematician would love, but that is only before we address some applications:</p>
<p>Internet display advertising: companies have a suite of potential ads they can display to visitors, but the company is not sure which ad strategy to follow to maximize sales. This is similar to A/B testing, but has the added advantage of naturally minimizing strategies that do not work (and generalizes to A/B/C/D… strategies)</p>
<ol>
<li>Ecology: animals have a finite amount of energy to expend, and following certain behaviours has uncertain rewards. How does the animal maximize its fitness?</li>
<li>Finance: which stock option gives the highest return, under time-varying return profiles.</li>
<li>Clinical trials: a researcher would like to find the best treatment, out of many possible treatments, while minimizing losses.</li>
</ol>
<p>Many of these questions above are fundamental to the application’s field. It turns out the optimal solution is incredibly difficult, and it took decades for an overall solution to develop. There are also many approximately-optimal solutions which are quite good. The one I wish to discuss is one of the few solutions that can scale incredibly well. The solution is known asBayesian Bandits.</p>
<h2 id="3-_A_Proposed_Solution">3. A Proposed Solution</h2><p>Any proposed strategy is called an online algorithm (not in the internet sense, but in the continuously-being-updated sense), and more specifically a reinforcement learning algorithm. The algorithm starts in an ignorant state, where it knows nothing, and begins to acquire data by testing the system. As it acquires data and results, it learns what the best and worst behaviours are (in this case, it learns which bandit is the best). With this in mind, perhaps we can add an additional application of the Multi-Armed Bandit problem:</p>
<p>Psychology: how does punishment and reward effect our behaviour? How do humans’ learn?<br>The Bayesian solution begins by assuming priors on the probability of winning for each bandit. In our vignette we assumed complete ignorance of the these probabilities. So a very natural prior is the flat prior over 0 to 1. The algorithm proceeds as follows:</p>
<p>For each round,</p>
<ol>
<li>Sample a random variable Xb from the prior of bandit b, for all b.</li>
<li>Select the bandit with largest sample, i.e. select bandit B=argmaxXb.</li>
<li>Observe the result of pulling bandit B, and update your prior on bandit B.</li>
<li>Return to 1.</li>
</ol>
<p>That’s it. Computationally, the algorithm involves sampling from N distributions. Since the initial priors are Beta(α=1,β=1) (a uniform distribution), and the observed result X (a win or loss, encoded 1 and 0 respectfully) is Binomial, the posterior is a Beta(α=1+X,β=1+1−X)(see here for why to is true). </p>
<p>To answer a question from before, this algorithm suggests that we should not discard losers, but we should pick them at a decreasing rate as we gather confidence that there exist better bandits. This follows because there is always a non-zero chance that a loser will achieve the status of B, but the probability of this event decreases as we play more rounds (see figure below). Below is an implementation of the Bayesian Bandits strategy (which can be skipped for the less Pythonic-ly interested).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pymc <span class="keyword">import</span> rbeta</span><br><span class="line"> </span><br><span class="line">rand = np.random.rand</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bandits</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    This class represents N bandits machines.</span><br><span class="line"> </span><br><span class="line">    parameters:</span><br><span class="line">        p_array: a (n,) Numpy array of probabilities &gt;0, &lt;1.</span><br><span class="line"> </span><br><span class="line">    methods:</span><br><span class="line">        pull( i ): return the results, 0 or 1, of pulling </span><br><span class="line">                   the ith bandit.</span><br><span class="line">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, p_array)</span>:</span></span><br><span class="line">        self.p = p_array</span><br><span class="line">        self.optimal = np.argmax(p_array)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pull</span><span class="params">( self, i )</span>:</span></span><br><span class="line">        <span class="comment">#i is which arm to pull</span></span><br><span class="line">        <span class="keyword">return</span> rand() &lt; self.p[i]</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.p)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BayesianStrategy</span><span class="params">( object )</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Implements a online, learning strategy to solve</span><br><span class="line">    the Multi-Armed Bandit problem.</span><br><span class="line"> </span><br><span class="line">    parameters:</span><br><span class="line">        bandits: a Bandit class with .pull method</span><br><span class="line"> </span><br><span class="line">    methods:</span><br><span class="line">        sample_bandits(n): sample and train on n pulls.</span><br><span class="line"> </span><br><span class="line">    attributes:</span><br><span class="line">        N: the cumulative number of samples</span><br><span class="line">        choices: the historical choices as a (N,) array</span><br><span class="line">        bb_score: the historical score as a (N,) array</span><br><span class="line"> </span><br><span class="line">    """</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, bandits)</span>:</span></span><br><span class="line"> </span><br><span class="line">        self.bandits = bandits</span><br><span class="line">        n_bandits = len( self.bandits )</span><br><span class="line">        self.wins = np.zeros( n_bandits )</span><br><span class="line">        self.trials = np.zeros(n_bandits )</span><br><span class="line">        self.N = <span class="number">0</span></span><br><span class="line">        self.choices = []</span><br><span class="line">        self.bb_score = []</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample_bandits</span><span class="params">( self, n=<span class="number">1</span> )</span>:</span></span><br><span class="line"> </span><br><span class="line">        bb_score = np.zeros( n )</span><br><span class="line">        choices = np.zeros( n )</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="comment">#sample from the bandits's priors, and select the largest sample</span></span><br><span class="line">            choice = np.argmax( rbeta( <span class="number">1</span> + self.wins, <span class="number">1</span> + self.trials - self.wins) )</span><br><span class="line"> </span><br><span class="line">            <span class="comment">#sample the chosen bandit</span></span><br><span class="line">            result = self.bandits.pull( choice )</span><br><span class="line"> </span><br><span class="line">            <span class="comment">#update priors and score</span></span><br><span class="line">            self.wins[ choice ] += result</span><br><span class="line">            self.trials[ choice ] += <span class="number">1</span></span><br><span class="line">            bb_score[ k ] = result </span><br><span class="line">            self.N += <span class="number">1</span></span><br><span class="line">            choices[ k ] = choice</span><br><span class="line"> </span><br><span class="line">        self.bb_score = np.r_[ self.bb_score, bb_score ]</span><br><span class="line">        self.choices = np.r_[ self.choices, choices ]</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>Below we present a visualization of the algorithm sequentially learning the solution. In the figure below, the dashed lines represent the true hidden probabilities, which are (0.85, 0.60, 0.75)(this can be extended to many more dimensions, but the figure suffers, so I kept it at 3).</p>
<p><img src="/images/bb/updating2.png" alt=""></p>
<p>Note that we don’t real care how accurate we become about inference of the hidden probabilities — for this problem we are more interested in choosing the best bandit (or more accurately, becoming more confident in choosing the best bandit). For this reason, the distribution of the red bandit is very wide (representing ignorance about what that hidden probability might be) but we are reasonably confident that it is not the best, so the algorithm chooses to ignore it.</p>
<h3 id="几篇介绍Bayesian_Bandits的原理的文章：">几篇介绍Bayesian Bandits的原理的文章：</h3><ol>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html</a></li>
<li>在线演示博弈过程： <a href="https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/" target="_blank" rel="external">https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/</a></li>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html</a></li>
<li><a href="http://camdp.com/blogs/multi-armed-bandits" target="_blank" rel="external">http://camdp.com/blogs/multi-armed-bandits</a></li>
<li>贝叶斯书籍：<a href="https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers" target="_blank" rel="external">https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="1-_The_Multi-Armed_Bandit_Problem">1. The Multi-Armed Bandit Problem</h2><p>Suppose you are faced with N slot machines (colourfully ]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Bayesian Bandits – optimizing click throughs with statistics]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/</id>
    <published>2015-09-03T05:36:48.000Z</published>
    <updated>2015-09-03T05:46:55.000Z</updated>
    <content type="html"><![CDATA[<p>Great news! A murder victim has been found. No slow news day today! The story is already written, now a title needs to be selected. The clever reporter who wrote the story has come up with two potential titles – “Murder victim found in adult entertainment venue” and “Headless Body found in Topless Bar”. (The latter title is one I’ve shamelessly stolen from the NY Daily News.) Once upon a time, deciding which title to run was a matter for a news editor to decide. Those days are now over – the geeks now rule the earth. Title selection is now primarily an algorithmic problem, not an editorial one.</p>
<p>One common approach is to display both potential versions of the title on the homepage or news feed, and measure the Click Through Rate (CTR) of each version of the title. At some point, when the measured CTR for one title exceeds that of the other title, you’ll switch to the one with the highest for all users. Algorithms for solving this problem are called bandit algorithms.</p>
<p>In this blog post I’ll describe one of my favorite bandit algorithms, the Bayesian Bandit, and show why it is an excellent method to use for problems which give us more information than typical bandit algorithms.</p>
<p>Unless you are already familiar with Bayesian statistics and beta distributions, I strongly recommend reading the previous blog post. That post provides much introductory material, and I’ll depend on it heavily.</p>
<h2 id="1-_The_problem_to_be_solved,_and_the_underlying_model">1. The problem to be solved, and the underlying model</h2><hr>
<p>Ultimately the problem we want to solve is the following. Consider an article being published on a website. The author or editor has come up with several possible titles – “Murder victim found in adult entertainment venue”, “Headless Body found in Topless Bar”, etc. We want to choose the title with the best click through rate (CTR). Let us represent each CTR by θi – i.e., θi is the true probability that an individual user will click on the i-th title. As a simplifying assumption, we assume that these rates θi do not change over time. It is important to note that we don’t actually know what θi is – if we did, we could simply choose i for which θi was largest and move on.</p>
<p>The goal of the bandit algorithm is to do the following. To begin with, it should display all possible titles to a random selection of users, and measure which titles are clicked on more frequently. Over time, it will use these observations to infer which articles have the higher CTR. Then, once the estimation of the CTR becomes more precise, it will preferentially display articles with the higher CTR.</p>
<h2 id="2-_The_Bayesian_Approach">2. The Bayesian Approach</h2><hr>
<p>In the model described above, we have N possible story titles, each of which has a click through rate θi. Unfortunately we do not know what θi is. As the astute reader can guess from the title, we are following a Bayesian approach, so we will construct a probability distribution which represents our belief about what the actual value of θi is.<br><img src="/images/bb/beliefs_about_theta.png" alt=""><br>In the figure above, we believe that θi is somewhere between 0.1 and 0.7, with values of 0.3-0.4 being considerably more likely than values of 0.1-0.2 or 0.6-0.7. For those who forgot STATS 101, the area under this curve between the points a and b is the probability thta θi lies between a and b. I.e.:<br><img src="/images/bb/11.png" alt=""><br>The basic idea behind Bayesian methods is to update our beliefs based on evidence. As we gather more data by showing different titles to other users and observing click throughs, we can incrementally narrow the width of the probability distribution.</p>
<p>As in all Bayesian inference, we need to choose a prior. The prior is something we believe to be true before we have any evidence – i.e., before we have shown the title to any visitors. This is just a starting point – after enough evidence is gathered, our prior will play a very minimal role in what we actually believe. Choosing a good prior is important both for mathematical simplicity, and because if your prior is accurate, you don’t need as much evidence to get the correct answer.</p>
<p>I’ll follow the approach I described in a previous blog post, and I’ll use a beta distribution as the prior:<br><img src="/images/bb/31.png" alt=""><br>The parameters αi,βi&gt;1 are the prior parameters. One reasonable choice is αi=βi=1, which amounts to the uniform distribution on [0,1]. What this means is that we are assuming that all possible values of θi are equally likely. Depending on the circumstances (which I’ll explain shortly), we might want to choose other possible values.</p>
<h2 id="3-_Updating_our_beliefs">3. Updating our beliefs</h2><p>Now we address the question of using evidence. After showing title i to ni visitors, we have observed that si of them have actually clicked on the title. We now want to compute theposterior distribution, which is to say the distribution that represents our beliefs after we have evidence.</p>
<p>I did a little bit of algebra previously, in which I showed that if the prior is fαi,βi(θi), then the posterior distribution is:<br><img src="/images/bb/21.png" alt=""><br>The key idea here is that to update our probability distribution describing θi, we need only update the parameters of our beta distribution.</p>
<p>So what does this mean in practice? As we run more experiments, our probability distribution on where θi lives becomes sharper:</p>
<p><img src="/images/bb/beta_distribution_evolution.png" alt=""><br>Before we run any experiments, θi could be anything (as represented by the blue line). Once we have run 700 experiments, yielding 175 click throughs, we are reasonably confident that θi lives roughly between 0.2 and 0.3.</p>
<p>What we’ve done so far is figured out how to estimate what our click through rates actually are based on empirical evidence. But that doesn’t actually give us a method of optimizing them yet.</p>
<h2 id="4-_Optimizing_click_throughs">4. Optimizing click throughs</h2><p>Now that we have a method of representing our beliefs about CTRs, it is useful to construct an algorithm to identify the best ones. There are many popular choices – I’ve written about the UCB Algorithm before, and I consider it a good choice.</p>
<p>But my new favorite method is a Monte Carlo method which I’ll describe now.</p>
<p>The ultimate goal of the bandit algorithm is to display to the user whichever title has the highest CTR. One method of estimating the CTRs of the articles is to sample the posterior distribution. I.e., suppose we have two possible titles, from which we have drawn n0=200,s0=64and n1=180,n2=40. Then one possible set of samples we might observe is this:</p>
<p><img src="/images/bb/beta_distribution_sampling1.png" alt=""></p>
<p>For title 0, our sample of θ0 has worked out to be 0.35, while our sample of θ1 is only 0.28. Since θ0=0.35&gt;θ1=0.28, we will display title 0 to the user.</p>
<p>However, there was no guarantee that things worked out this way. It was possible, although less likely, that θ1 could come out larger than θ0:<br><img src="/images/bb/beta_distribution_sampling2.png" alt=""><br>In this case, we would have displayed title 1 to the user rather than title 0.</p>
<p>The net result is that for overlapping probability distributions, we will display the title with the larger expected CTR the majority of the time. But occasionally, we will draw from the other distributions simply because it is within the realm of possibility that they are greater.</p>
<p>As we gather more data our probability distributions will become narrower and a clear winner will become apparent. When this occurs, we will almost surely choose the winner:<br><img src="/images/bb/beta_distribution_sampling3.png" alt=""><br>In python, the algorithm looks like this:</p>
<p>The results of this algorithm are exactly what any good bandit algorithm should do. I ran the following simulation, giving the beta bandit two titles – title 0 had a CTR of 0.25, title 1 had a CTR of 0.35. To start with, both titles were displayed to the user with roughly equal probability. Over time, evidence accumulated that title 1 was considerably better than title 0. At this point the algorithm switched to displaying primarily title 1, and the overall CTR of the experiment converged to 0.35 (the optimal CTR).</p>
<p><img src="/images/bb/beta_bandit_results.png" alt=""></p>
<p>Source code to generate this graph is available here. This method is called Thompson Sampling and is a a fairly popular method in Bayesian AI techniques. For the remainder of this post, I’ll call this method the Bayesian Bandit.</p>
<h2 id="5-Incorporating_common_sense">5.Incorporating common sense</h2><p>Anyone with common sense is now scoffing at the geekiness embodied in this post. Even before using statistics, it was fairly obvious that “Headless Body found in Topless Bar” was going to beat “Murder victim found in adult entertainment venue”. The former just sounds catchier and any good editor would run with it.</p>
<p>The wonderful thing about Bayesian methods is that we can modify them to take into account our prior knowledge. Suppose we believe editors intuition is a real thing – can we quantify it? Certainly. We can do this with a fairly simple experiment. We require editors to rate a collection of titles as “catchy” or “not catchy”, run them on the site, and then measure the CTR of the “catchy” and “not catchy” samples. Suppose we did such an experiment, and observed the following aggregate results:</p>
<p><img src="/images/bb/empirical_prior.png" alt=""></p>
<p>This isn’t a solid win for the editor – some catchy titles have low CTRs, and some boring titles have good CTRs. But nevertheless, it’s better for a story to have catchy title than not.</p>
<p>What we want to do is incorporate this information into our bandit algorithm. The beauty of a Bayesian method is that it gives you a clear and meaningful place to plug this information in, namely the prior. In contrast, for many other methods (e.g., UCB) it’s somewhat difficult to do this – there is no obvious parameter to tune as a result of our prior empirical data.</p>
<p>The first step is to fit a theoretical distribution to the empirical data. Due to the fact that I chose the “empirical” (i.e., made up) data to be very nice, a beta distribution fits well [1] – specifically beta distributions with (α0,β0)=(9,20) and (α1,β1)=(4,20).<br><img src="/images/bb/theoretical_prior.png" alt=""></p>
<p>Then the only modification needed to the algorithm is to plug these variables into the prior:<br><img src="/images/bb/41.png" alt=""><br>Everything else remains unchanged. In terms of modifications to source code, this is only a very small change to the previous code – an implementation can be found here.</p>
<h2 id="6-_Empirics_of_including_priors">6. Empirics of including priors</h2><p>To measure the benefits of incorporating priors into the Bayesian bandit, I ran some numerical experiments, the source code of which is available in this github gist. The methodology was the following.</p>
<p>To compare the Bayesian bandit with priors to that without, I drew a pair (θ0,θ1) from the prior distribution given above. For each pair, I then ran the Bayes Bandit with and without priors for this pair theta, for k trials. This is modelling the scenario that we have k page views on our homepage, and we can only leave a story on the homepage for 1 day.</p>
<p>I then repeated the experiment for 1000 different possible days, or equivalently for 1000 different pairs of (θ0,θ1). I then computed the average gain per page view over all trials and all days.</p>
<p>The result is the following. If we get 50 page views/day (i.e., the Bayes Bandit has very little data to use), the prior gives us a big gain. Without prior knowledge, the Bandit achieved a gain of 0.3749 on average, whereas the bandit with prior knowledge achieved a gain of 0.4274. If we run 150 experiments, the Bayes Bandit improves significantly – it achieves a gain of 0.40. If we run 300 experiments, the Bayes Bandit improves to 0.4146, while the bandit with priors improves to 0.4296. If we get 1000 page views/day, the Bayes Bandit improves to 0.4211, while the bandit with priors gains 0.4249.</p>
<p>The net result is the following – incorporating priors into the Bayes Bandit is an excellent way to improve your results when you don’t have a large number data points to use to train the bandit. If you have a lot of data points, you don’t need strong priors (but they still help a little).</p>
<h2 id="7-Conclusion">7.Conclusion</h2><p>Bandit algorithms are a great way of optimizing many factors of your website. There are many good options – I’ve written about UCB before and consider it a great choice. But if you have other information you want to include, consider using the Bayesian Bandit. It’s simple to implement, straightforward to use, and very importantly it’s also straightforward to extend.</p>
<p>It’s also important to note that the theoretical properties of the Bayesian Bandit (namely logarithmic regret) have been proven. So asymptotically, you lose nothing by using it. There are also attempts at constructing a Bayesian UCB algorithm – I don’t currently understand it well enough to comment.</p>
<p>I’ve written other articles related to this post. I have one post comparing bandit algorithms to a/b testing. I also I wrote about measuring a changing conversion rate, which provides an alternate algorithm for computing the posterior distribution if your conversion rate is not constant.</p>
<p>[1] If a single Beta distribution doesn’t fit, one can also use a convex combination of Beta distributions. The math works out just as nicely.</p>
<p>P.S. After I published this blog post, this related article was also pointed out to me, as was this online simulation of the Bayesian bandit.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Great news! A murder victim has been found. No slow news day today! The story is already written, now a title needs to be selected. The c]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hive UDF开发]]></title>
    <link href="http://www.notehub.cn/2015/09/03/dev/hive-udf-md/"/>
    <id>http://www.notehub.cn/2015/09/03/dev/hive-udf-md/</id>
    <published>2015-09-03T04:49:45.000Z</published>
    <updated>2015-09-03T04:53:26.000Z</updated>
    <content type="html"><![CDATA[<p>Hive进行UDAF开发，相对要比UDF复杂一些，不过也不是很难。请看一个例子:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.hrj.hive.udf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDAFEvaluator;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.io.DoubleWritable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UDAFSum_Sample</span> <span class="keyword">extends</span> <span class="title">NumericUDAF</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Evaluator</span> <span class="keyword">implements</span> <span class="title">UDAFEvaluator</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">boolean</span> mEmpty;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">double</span> mSum;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Evaluator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">super</span>();</span><br><span class="line">            init();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            mSum = <span class="number">0</span>;</span><br><span class="line">            mEmpty = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">iterate</span><span class="params">(DoubleWritable o)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</span><br><span class="line">                mSum += o.get();</span><br><span class="line">                mEmpty = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> DoubleWritable <span class="title">terminatePartial</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// This is SQL standard - sum of zero items should be null.</span></span><br><span class="line">            <span class="keyword">return</span> mEmpty ? <span class="keyword">null</span> : <span class="keyword">new</span> DoubleWritable(mSum);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">merge</span><span class="params">(DoubleWritable o)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</span><br><span class="line">                mSum += o.get();</span><br><span class="line">                mEmpty = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> DoubleWritable <span class="title">terminate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// This is SQL standard - sum of zero items should be null.</span></span><br><span class="line">            <span class="keyword">return</span> mEmpty ? <span class="keyword">null</span> : <span class="keyword">new</span> DoubleWritable(mSum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>1.将java文件编译成Sum_Sample.jar</p>
<p>2.进入hive<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">hive&gt; add jar Sum_sample.jar;</span><br><span class="line"></span><br><span class="line">hive&gt; create temporary <span class="keyword">function</span> sum_<span class="built_in">test</span> as <span class="string">'com.hrj.hive.udf.UDAFSum_Sample'</span>;</span><br><span class="line"></span><br><span class="line">hive&gt; select sum_<span class="built_in">test</span>(t.num) from t;</span><br><span class="line"></span><br><span class="line">hive&gt; drop temporary <span class="keyword">function</span> sum_<span class="built_in">test</span>;</span><br><span class="line"></span><br><span class="line">hive&gt; quit;</span><br></pre></td></tr></table></figure></p>
<p>关于UDAF开发注意点：</p>
<p>1.需要import org.apache.hadoop.hive.ql.exec.UDAF以及org.apache.hadoop.hive.ql.exec.UDAFEvaluator,这两个包都是必须的</p>
<p>2.函数类需要继承UDAF类，内部类Evaluator实现UDAFEvaluator接口</p>
<p>3.Evaluator需要实现 init、iterate、terminatePartial、merge、terminate这几个函数</p>
<pre><code><span class="number">1</span>）init函数类似于构造函数，用于UDAF的初始化

<span class="number">2</span>）iterate接收传入的参数，并进行内部的轮转。其返回类型为boolean

<span class="number">3</span>）terminatePartial无参数，其为iterate函数轮转结束后，返回乱转数据，iterate和terminatePartial类似于hadoop的Combiner

<span class="number">4</span>）merge接收terminatePartial的返回结果，进行数据merge操作，其返回类型为boolean

<span class="number">5</span>）terminate返回最终的聚集函数结果
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<p>Hive进行UDAF开发，相对要比UDF复杂一些，不过也不是很难。请看一个例子:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span>]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Flask microframework example]]></title>
    <link href="http://www.notehub.cn/2015/09/03/opensource/flask-example-md/"/>
    <id>http://www.notehub.cn/2015/09/03/opensource/flask-example-md/</id>
    <published>2015-09-03T03:25:14.000Z</published>
    <updated>2015-09-03T04:48:45.000Z</updated>
    <content type="html"><![CDATA[<p>NOTE: This article was revised in September 2014 to be in sync with current versions of Python and Flask.<br>If you followed the previous chapter you should have a fully working, yet very simple web application that has the following file structure:<br><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">microblog<span class="string">\</span></span><br><span class="line">  flask<span class="string">\</span></span><br><span class="line">    &lt;virtual environment files&gt;</span><br><span class="line">  app<span class="string">\</span></span><br><span class="line">    static<span class="string">\</span></span><br><span class="line">    templates<span class="string">\</span></span><br><span class="line">    __init__.py</span><br><span class="line">    views.py</span><br><span class="line">  tmp<span class="string">\</span></span><br><span class="line">  run.py</span><br></pre></td></tr></table></figure></p>
<p>To run the application you execute the run.py script and then open the<a href="http://localhost:5000" target="_blank" rel="external">http://localhost:5000</a> URL on your web browser.</p>
<p>We are picking up exactly from where we left off, so you may want to make sure you have the above application correctly installed and working.</p>
<h3 id="1-_Why_we_need_templates">1. Why we need templates</h3><p>Let’s consider how we can expand our little application.</p>
<p>We want the home page of our microblogging app to have a heading that welcomes the logged in user, that’s pretty standard for applications of this kind. Ignore for now the fact that we have no way to log a user in, I’ll present a workaround for this issue in a moment.</p>
<p>An easy option to output a nice and big heading would be to change our view function to output HTML, maybe something like this:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> app <span class="keyword">import</span> app</span><br><span class="line"></span><br><span class="line"><span class="decorator">@app.route('/')</span></span><br><span class="line"><span class="decorator">@app.route('/index')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    user = &#123;<span class="string">'nickname'</span>: <span class="string">'Miguel'</span>&#125;  <span class="comment"># fake user</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'''</span><br><span class="line">&lt;html&gt;</span><br><span class="line">  &lt;head&gt;</span><br><span class="line">    &lt;title&gt;Home Page&lt;/title&gt;</span><br><span class="line">  &lt;/head&gt;</span><br><span class="line">  &lt;body&gt;</span><br><span class="line">    &lt;h1&gt;Hello, '''</span> + user[<span class="string">'nickname'</span>] + <span class="string">'''&lt;/h1&gt;</span><br><span class="line">  &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">'''</span></span><br></pre></td></tr></table></figure></p>
<p>Give the application a try to see how this looks in your browser.</p>
<p>Since we don’t have support for users yet I have resorted to using a placeholder user object, sometimes called fake or mock object. This allows us to concentrate on certain aspects of our application that depend on parts of the system that haven’t been built yet.</p>
<p>I hope you agree with me that the solution used above to deliver HTML to the browser is very ugly. Consider how complex the code will become if you have to return a large and complex HTML page with lots of dynamic content. And what if you need to change the layout of your web site in a large app that has dozens of views, each returning HTML directly? This is clearly not a scalable option.</p>
<h3 id="2-_Templates_to_the_rescue">2. Templates to the rescue</h3><p>If you could keep the logic of your application separate from the layout or presentation of your web pages things would be much better organized, don’t you think? You could even hire a web designer to create a killer web site while you code the site’s behaviors in Python. Templates help implement this separation.</p>
<p>Let’s write our first template (file app/templates/index.html):<br><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>&#123;&#123; title &#125;&#125; - microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="title">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">body</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">h1</span>&gt;</span>Hello, &#123;&#123; user.nickname &#125;&#125;!<span class="tag">&lt;/<span class="title">h1</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="title">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>As you see above, we just wrote a mostly standard HTML page, with the only difference that there are some placeholders for the dynamic content enclosed in {{ ... }} sections.<br></p>
<p>Now let’s see how we use this template from our view function (file app/views.py):<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> render_template</span><br><span class="line"><span class="keyword">from</span> app <span class="keyword">import</span> app</span><br><span class="line"></span><br><span class="line"><span class="decorator">@app.route('/')</span></span><br><span class="line"><span class="decorator">@app.route('/index')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    user = &#123;<span class="string">'nickname'</span>: <span class="string">'Miguel'</span>&#125;  <span class="comment"># fake user</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">'index.html'</span>,</span><br><span class="line">                           title=<span class="string">'Home'</span>,</span><br><span class="line">                           user=user)</span><br></pre></td></tr></table></figure></p>
<p>Try the application at this point to see how the template works. Once you have the rendered page in your browser you may want to view the source HTML and compare it against the original template.</p>
<p>To render the template we had to import a new function from the Flask framework calledrender_template. This function takes a template filename and a variable list of template arguments and returns the rendered template, with all the arguments replaced.<br><br>Under the covers, the render_template function invokes the Jinja2 templating engine that is part of the Flask framework. Jinja2 substitutes {{...}} blocks with the corresponding values provided as template arguments.<br><br></p>
<h3 id="3-_Control_statements_in_templates">3. Control statements in templates</h3><p>The Jinja2 templates also support control statements, given inside {%...%} blocks. Let’s add an if statement to our template (file app/templates/index.html):<br><br><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">head</span>&gt;</span></span><br><span class="line">    &#123;% if title %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>&#123;&#123; title &#125;&#125; - microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">    &#123;% else %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>Welcome to microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="title">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">body</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">h1</span>&gt;</span>Hello, &#123;&#123; user.nickname &#125;&#125;!<span class="tag">&lt;/<span class="title">h1</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="title">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>Now our template is a bit smarter. If the view function forgets to define a page title then instead of showing an empty title the template will provide its own title. Feel free to remove the titleargument in the render_template call of our view function to see how the conditional statement works.</p>
<h3 id="4-_Loops_in_templates">4. Loops in templates</h3><p>The logged in user in our microblog application will probably want to see recent posts from followed users in the home page, so let’s see how we can do that.</p>
<p>To begin, we use our handy fake object trick to create some users and some posts to show (fileapp/views.py):<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    user = &#123;<span class="string">'nickname'</span>: <span class="string">'Miguel'</span>&#125;  <span class="comment"># fake user</span></span><br><span class="line">    posts = [  <span class="comment"># fake array of posts</span></span><br><span class="line">        &#123; </span><br><span class="line">            <span class="string">'author'</span>: &#123;<span class="string">'nickname'</span>: <span class="string">'John'</span>&#125;, </span><br><span class="line">            <span class="string">'body'</span>: <span class="string">'Beautiful day in Portland!'</span> </span><br><span class="line">        &#125;,</span><br><span class="line">        &#123; </span><br><span class="line">            <span class="string">'author'</span>: &#123;<span class="string">'nickname'</span>: <span class="string">'Susan'</span>&#125;, </span><br><span class="line">            <span class="string">'body'</span>: <span class="string">'The Avengers movie was so cool!'</span> </span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">"index.html"</span>,</span><br><span class="line">                           title=<span class="string">'Home'</span>,</span><br><span class="line">                           user=user,</span><br><span class="line">                           posts=posts)</span><br></pre></td></tr></table></figure></p>
<p>To represent user posts we are using a list, where each element has author and body fields. When we get to implement a real database we will preserve these field names, so we can design and test our template using the fake objects without having to worry about updating it when we move to a database.</p>
<p>On the template side we have to solve a new problem. The list can have any number of elements, it will be up to the view function to decide how many posts need to be presented. The template cannot make any assumptions about the number of posts, so it needs to be prepared to render as many posts as the view sends.</p>
<p>So let’s see how we do this using a for control structure (file app/templates/index.html):<br><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">head</span>&gt;</span></span><br><span class="line">    &#123;% if title %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>&#123;&#123; title &#125;&#125; - microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">    &#123;% else %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>Welcome to microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="title">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">h1</span>&gt;</span>Hi, &#123;&#123; user.nickname &#125;&#125;!<span class="tag">&lt;/<span class="title">h1</span>&gt;</span></span><br><span class="line">    &#123;% for post in posts %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">div</span>&gt;</span><span class="tag">&lt;<span class="title">p</span>&gt;</span>&#123;&#123; post.author.nickname &#125;&#125; says: <span class="tag">&lt;<span class="title">b</span>&gt;</span>&#123;&#123; post.body &#125;&#125;<span class="tag">&lt;/<span class="title">b</span>&gt;</span><span class="tag">&lt;/<span class="title">p</span>&gt;</span><span class="tag">&lt;/<span class="title">div</span>&gt;</span></span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="title">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>Simple, right? Give it a try, and be sure to play with adding more content to the posts array.</p>
<h3 id="5-_Template_inheritance">5. Template inheritance</h3><p>We have one more topic to cover before we close for the day. Our microblog web application will need to have a navigation bar at the top of the page with a few links. Here you will get the link to edit your profile, to login, logout, etc.</p>
<p>We can add a navigation bar to our index.html template, but as our application grows we will be needing to implement more pages, and this navigation bar will have to be copied to all of them. Then you will have to keep all these identical copies of the navigation bar in sync, and that could become a lot of work if you have a lot of pages and templates.</p>
<p>Instead, we can use Jinja2’s template inheritance feature, which allows us to move the parts of the page layout that are common to all templates and put them in a base template from which all other templates are derived.</p>
<p>So let’s define a base template that includes the navigation bar and also the bit of title logic we implemented earlier (file app/templates/base.html):<br><br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">  &lt;head&gt;</span><br><span class="line">    &#123;% if title %&#125;</span><br><span class="line">    &lt;title&gt;&#123;&#123; title &#125;&#125; - microblog&lt;/title&gt;</span><br><span class="line">    &#123;% else %&#125;</span><br><span class="line">    &lt;title&gt;Welcome to microblog&lt;/title&gt;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">  &lt;/head&gt;</span><br><span class="line">  &lt;body&gt;</span><br><span class="line">    &lt;div&gt;Microblog: &lt;a href="/index"&gt;Home&lt;/a&gt;&lt;/div&gt;</span><br><span class="line">    &lt;hr&gt;</span><br><span class="line">    &#123;% block content %&#125;&#123;% endblock %&#125;</span><br><span class="line">  &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<p>In this template we use the block control statement to define the place where the derived templates can insert themselves. Blocks are given a unique name, and their content can be replaced or enhanced in derived templates.</p>
<p>And now what’s left is to modify our index.html template to inherit from base.html (fileapp/templates/index.html):<br><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;% extends "base.html" %&#125;</span><br><span class="line">&#123;% block content %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">h1</span>&gt;</span>Hi, &#123;&#123; user.nickname &#125;&#125;!<span class="tag">&lt;/<span class="title">h1</span>&gt;</span></span><br><span class="line">    &#123;% for post in posts %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">div</span>&gt;</span><span class="tag">&lt;<span class="title">p</span>&gt;</span>&#123;&#123; post.author.nickname &#125;&#125; says: <span class="tag">&lt;<span class="title">b</span>&gt;</span>&#123;&#123; post.body &#125;&#125;<span class="tag">&lt;/<span class="title">b</span>&gt;</span><span class="tag">&lt;/<span class="title">p</span>&gt;</span><span class="tag">&lt;/<span class="title">div</span>&gt;</span></span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">&#123;% endblock %&#125;</span><br></pre></td></tr></table></figure></p>
<p>Since the base.html template will now take care of the general page structure we have removed those elements from this one and left only the content part. The extends block establishes the inheritance link between the two templates, so that Jinja2 knows that when it needs to renderindex.html it needs to include it inside base.html. The two templates have matching blockstatements with name content, and this is how Jinja2 knows how to combine the two into one. When we get to write new templates we will also create them as extensions to base.html.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>NOTE: This article was revised in September 2014 to be in sync with current versions of Python and Flask.<br>If you followed the previous]]>
    </summary>
    
      <category term="falsk, restful" scheme="http://www.notehub.cn/tags/falsk-restful/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Input mono字体]]></title>
    <link href="http://www.notehub.cn/2015/09/03/opensource/input-font-md/"/>
    <id>http://www.notehub.cn/2015/09/03/opensource/input-font-md/</id>
    <published>2015-09-03T03:20:50.000Z</published>
    <updated>2015-09-03T03:23:31.000Z</updated>
    <content type="html"><![CDATA[<p>Input Mono字体作为编程字体挺好看的, 该字体对个人非商业用户是免费的, 并且支持自定义.</p>
<p>地址: <a href="http://input.fontbureau.com" target="_blank" rel="external">http://input.fontbureau.com</a></p>
<p><img src="/images/input_mono.png" alt=""></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Input Mono字体作为编程字体挺好看的, 该字体对个人非商业用户是免费的, 并且支持自定义.</p>
<p>地址: <a href="http://input.fontbureau.com" target="_blank" rel="external">http://]]>
    </summary>
    
      <category term="font" scheme="http://www.notehub.cn/tags/font/"/>
    
  </entry>
  
</feed>
