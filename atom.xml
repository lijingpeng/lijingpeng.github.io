<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Frank]]></title>
  <subtitle><![CDATA[Li Jingpeng's site]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://www.notehub.cn/"/>
  <updated>2015-09-25T14:37:04.000Z</updated>
  <id>http://www.notehub.cn/</id>
  
  <author>
    <name><![CDATA[Li Jingpeng]]></name>
    <email><![CDATA[me@lijingpeng.org]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[特征处理]]></title>
    <link href="http://www.notehub.cn/2015/09/25/algo/ml/Feature%20Processing/"/>
    <id>http://www.notehub.cn/2015/09/25/algo/ml/Feature Processing/</id>
    <published>2015-09-24T16:00:00.000Z</published>
    <updated>2015-09-25T14:37:04.000Z</updated>
    <content type="html"><![CDATA[<p>特征工程（Feature Engineering）经常被说为机器学习中的black art，这里面包含了很多不可言说的方面。怎么处理好特征，最重要的当然还是对要解决问题的了解。但是，它其实也有很多科学的地方。这篇文章我之所以命名为特征处理（Feature Processing），是因为这里面要介绍的东西只是特征工程中的一小部分。这部分比较基础，比较容易说，所以由此开始。单个原始特征（或称为变量）通常属于以下几类之一：</p>
<ul>
<li>连续（continuous）特征；</li>
<li>无序类别（categorical）特征；</li>
<li>有序类别（ordinal）特征。</li>
</ul>
<p>本文中我主要介绍针对单个特征的处理方法，虽然也会附带介绍基础的特征组合方法。同时处理多个特征，以及更复杂的特征处理方法介绍，以后我再另外细说。下面我由浅入深地逐渐说明针对这三类特征的常用处理方法。</p>
<h2 id="初级篇">初级篇</h2><hr>
<h3 id="连续特征">连续特征</h3><p>除了归一化（去中心，方差归一），不用做太多特殊处理，可以直接把连续特征扔到模型里使用。</p>
<h3 id="无序特征">无序特征</h3><p>可以使用One-hot（也叫One-of-k）的方法把每个无序特征转化为一个数值向量。比如一个无序特征color有三种取值：red，green，blue。那么可以用一个长度为3的向量来表示它，向量中的各个值分别对应于red，green，blue。如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">color取值 向量表示</span><br><span class="line">red     (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">green   (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">blue    (<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>这种方法在NLP里用的很多，就是所谓的词向量模型。变换后的向量长度对于词典长度，每个词对应于向量中的一个元素。</p>
<p>机器学习书籍里在讲这个的时候介绍的处理方法可能跟我上面说的有点差别。上面说的表达方式里有一个维度是可以省略的。既然我们知道color一定是取3个值中的一个，那么我们知道向量的前两个元素值，就能推断第3个值是多少。所以，其实用下面的方式就可以表达到底是哪种颜色：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">color取值 向量表示</span><br><span class="line">red     (<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">green   (<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">blue    (<span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>这样表达的好处是少用了一个维度，降低了转化后特征之间的相关性。但在实际问题中特征基本都或多或少会有些缺失。使用第一种表达方式就可以用全0的向量来表示值缺失，而第二种表达方式是没法表达缺失的。</p>
<h3 id="有序特征">有序特征</h3><p>有些特征虽然也像无序特征那样只取限定的几个值，但是这些值之间有顺序的含义。例如一个人的状态status有三种取值：bad, normal, good，显然bad &lt; normal &lt; good。</p>
<p>当然，对有序特征最简单的处理方式是忽略其中的顺序关系，把它看成无序的，这样我们就可以使用处理无序特征的方式来处理它。在实际问题中，这种处理方式其实用的很多。</p>
<p>当然有些问题里有序可能会很重要，这时候就不应该把其中的顺序关系丢掉。一般的表达方式如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">status取值    向量表示</span><br><span class="line">bad     (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">normal  (<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">good    (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>上面这种表达方式很巧妙地利用递进表达了值之间的顺序关系。</p>
<h2 id="中级篇">中级篇</h2><hr>
<p>最容易让人掉以轻心的，往往就是大家觉得最简单的事。在特征处理中，最容易让刚入门同学忽略的，是对连续特征的处理方式。</p>
<p>以线性分类器Linear Regression (LinearReg)为例，它是通过特征的线性加权来预测因变量y：<br><figure class="highlight fix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">y</span>=<span class="string">wTx</span></span><br></pre></td></tr></table></figure></p>
<p>但大部分实际情况下，y与x都不会是这么简单的线性关系，甚至连单调关系都不会有。举个只有一个特征的例子，如果y与x的实际关系如下图：</p>
<p><img src="/images/algo/nonlinear_function1.png" alt=""></p>
<p>那么直接把x扔进LinearReg模型是怎么也得不到好结果的。很多人会想着既然线性分类器搞不定，那就直接找个非线性的好了，比如高斯核的SVM。我们确实可以通过这种简单换算法的方式解决这个简单的问题。但对于很多实际问题（如广告点击率预测），往往特征非常多，这时候时间约束通常不允许我们使用很复杂的非线性分类器。这也是为什么算法发展这么多年，广告点击率预测最常用的方法还是Logistic Regression (LogisticReg)。</p>
<p>对于上面这个问题，有没有什么办法使得LinearReg也能处理得不错？当然是有，就是对原始特征x做转化，把原来的非线性关系转化为线性关系。</p>
<h3 id="方法一：离散化">方法一：离散化</h3><p>最常用的转化方式是对x做离散化(discretization)，也就是把原来的值分段，转化成一个取值为0或1的向量。原始值落在某个段里，向量中此段对应的元素就为1，否则为0。</p>
<p>离散化的目标是y与转化后向量里的每个元素都保持比较好的线性关系。<br>比如取离散点{0.5,1.5,2.5}，通过判断x属于(−∞,0.5)，[0.5,1.5)，[1.5,2.5)，[2.5,+∞)中哪段来把它离散化为4维的向量。下面是一些例子的离散结果：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">原始值x    离散化后的值</span><br><span class="line"><span class="number">0.1</span>     (<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">1.3</span>     (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">3.2</span>     (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="number">5.8</span>     (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<p>离散化方法的关键是怎么确定分段中的离散点。下面是常用的选取离散点的方法：</p>
<p>a. 等距离离散：顾名思义，就是离散点选取等距点。我们上面对x取离散点{0.5,1.5,2.5}就是一种等距离散，见下图。图中垂直的灰线代表离散点。</p>
<p><img src="/images/algo/nonlinear_function2.png" alt=""></p>
<p>b. 等样本点离散：选取的离散点保证落在每段里的样本点数量大致相同，见下图。</p>
<p><img src="/images/algo/nonlinear_function3.png" alt=""></p>
<p>c. 画图观察趋势：以x为横坐标，y为纵坐标，画图，看曲线的趋势和拐点。通过观察下面的图我们发现可以利用3条直线（红色直线）来逐段近似原来的曲线。把离散点设为两条直线相交的各个点，我们就可以把x离散化为长度为3的向量。</p>
<p><img src="/images/algo/nonlinear_function4.png" alt=""></p>
<p>上面介绍的这种离散化为0/1向量的方法有个问题，它在离散时不会考虑到具体的x到离散边界的距离。比如等距离散中取离散点为{0.5,1.5,2.5}，那么1.499，1.501和2.49分别会离散为(0, 1, 0, 0)，(0, 0, 1, 0)和(0, 0, 1, 0)。1.499和1.501很接近，可是就因为这种强制分段的离散导致它们离散的结果差距很大。</p>
<p>针对上面这种硬离散的一种改进就是使用软离散，也就是在离散时考虑到x与附近离散点的距离，离散出来的向量元素值可以是0/1之外的其他值。有兴趣的同学可以去ESL1这本书中找点感觉。</p>
<h3 id="方法二：函数变换">方法二：函数变换</h3><p>函数变换直接把原来的特征通过非线性函数做变换，然后把原来的特征，以及变换后的特征一起加入模型进行训练。常用的变换函数见下表，不过其实你可以尝试任何函数。<br><figure class="highlight openscad"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">常用非线性函数f<span class="params">(x)</span> x的取值范围</span><br><span class="line">xα; α∈<span class="params">(−∞,+∞)</span>   <span class="params">(−∞,+∞)</span></span><br><span class="line"><span class="built_in">log</span><span class="params">(x)</span>          <span class="params">(<span class="number">0</span>,+∞)</span></span><br><span class="line"><span class="built_in">log</span><span class="params">(x1−x)</span>       <span class="params">(<span class="number">0</span>,<span class="number">1</span>)</span></span><br></pre></td></tr></table></figure></p>
<p>这个方法操作起来很简单，但记得对新加入的特征做归一化。</p>
<p>对于我们前面的问题，只要把x2，x3也作为特征加入即可，因为实际上y就是x的一个三次多项式。</p>
<h2 id="高级篇">高级篇</h2><hr>
<h3 id="笛卡尔乘积">笛卡尔乘积</h3><p>我们可以使用笛卡尔乘积的方式来组合2个或更多个特征。比如有两个类别特征color和light，它们分别可以取值为red，green，blue和on, off。这两个特征各自可以离散化为3维和2维的向量。对它们做笛卡尔乘积转化，就可以组合出长度为6的特征，它们分别对应着原始值对(red, on)，(red, off)，(green, on)，(green, off)，(blue, on)，(blue, off)。下面的矩阵表达方式更清楚地说明了这种组合。<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">X</span>       <span class="built_in">on</span>  <span class="built_in">off</span></span><br><span class="line">red      </span><br><span class="line">green        </span><br><span class="line">blue</span><br></pre></td></tr></table></figure></p>
<p>对于3个特征的笛卡尔乘积组合，可以表达为立方的形式。更多特征的组合依次类推。 这个方法也可以直接用于连续特征与类别特征之间的组合，只要把连续特征看成是1维的类别特征就好了，这时候组合后特征对应的值就不是0/1了，而是连续特征的取值。</p>
<h3 id="离散化续篇">离散化续篇</h3><p>在上节中我已经介绍了一些常用的离散化单个连续特征的方法，其中一个是画图观察趋势。画图观察趋势的好处是直观、可解释性强，坏处是很麻烦。当要离散化的特征很多时，这种方法可操作性较差。</p>
<p>机器学习中有个很好解释，速度也不错的模型——决策树模型。大白话说决策树模型就是一大堆的if else。它天生就可以对连续特征分段，所以把它用于离散化连续特征合情合理。我称这种方法为决策树离散化方法。例如Gmail在对信件做重要性排序时就使用了决策树离散化方法2。</p>
<p>决策树离散化方法通常也是每次离散化一个连续特征，做法如下：</p>
<p>单独用此特征和目标值y训练一个决策树模型，然后把训练获得的模型内的特征分割点作为离散化的离散点。<br>这种方法当然也可以同时离散化多个连续特征，但是操作起来就更复杂了，实际用的不多。</p>
<h3 id="核方法">核方法</h3><p>核方法经常作为线性模型的一种推广出现。以线性回归模型为例，它对应的核方法如下：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fθ(x)=∑θ<span class="function"><span class="title">iK</span><span class="params">(x,xi)</span></span></span><br></pre></td></tr></table></figure></p>
<p>其中{xi}=1为训练样本点，K(xi,xj)为核函数，比如常用的高斯核函数为：<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">K</span><span class="params">(xi,xj)</span></span>=<span class="function"><span class="title">exp</span><span class="params">(−exp(∥xi−xj∥, <span class="number">2</span>)</span></span>/<span class="number">2</span>*<span class="function"><span class="title">exp</span><span class="params">(h,<span class="number">2</span>)</span></span>)</span><br></pre></td></tr></table></figure></p>
<p>如果我们把上面模型里的{K(x,xi)}=1看成特征，而θ看成模型参数的话，上面的模型仍旧是个线性模型。所以可以认为核方法只是特征函数变换的一种方式。</p>
<p>当然，如果把核函数K(xi,xj)看成一种相似度的话，那上面的模型就是kNN模型了，或者叫做加权平均模型也可以。因为核方法在预测时也要用到训练样本点，耗内存且计算量大，所以在数据量较大的实际问题中用的并不多。到此，我已经介绍了不少针对单个特征的处理方法。这些处理方法很难说哪个好哪个不好。有些问题这个好，有些问题那个好，也没什么绝招能直接判断出哪种方法能适合哪些问题。唯一的招就是：</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>特征工程（Feature Engineering）经常被说为机器学习中的black art，这里面包含了很多不可言说的方面。怎么处理好特征，最重要的当然还是对要解决问题的了解。但是，它其实也有很多科学的地方。这篇文章我之所以命名为特征处理（Feature Processin]]>
    </summary>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Feature hashing]]></title>
    <link href="http://www.notehub.cn/2015/09/25/algo/ml/feature_hashing/"/>
    <id>http://www.notehub.cn/2015/09/25/algo/ml/feature_hashing/</id>
    <published>2015-09-24T16:00:00.000Z</published>
    <updated>2015-09-25T14:43:22.000Z</updated>
    <content type="html"><![CDATA[<p>In machine learning, feature hashing, also known as the hashing trick(by analogy to the kernel trick), is a fast and space-efficient way of vectorizing features, i.e. turning arbitrary features into indices in a vector or matrix. It works by applying a hash function to the features and using their hash values as indices directly, rather than looking the indices up in an associative array.</p>
<h3 id="Motivating_example">Motivating example</h3><p>In a typical document classification task, the input to the machine learning algorithm (both during learning and classification) is free text. From this, a bag of words (BOW) representation is constructed: the individual tokens are extracted and counted, and each distinct token in the training set defines a feature (independent variable) of each of the documents in both the training and test sets.</p>
<p>Machine learning algorithms, however, are typically defined in terms of numerical vectors. Therefore, the bags of words for a set of documents is regarded as a term-document matrix where each row is a single document, and each column is a single feature/word; the entry i, j in such a matrix captures the frequency (or weight) of the j’th term of the vocabulary in document i. (An alternative convention swaps the rows and columns of the matrix, but this difference is immaterial.) Typically, these vectors are extremely sparse.</p>
<p>The common approach is to construct, at learning time or prior to that, a dictionary representation of the vocabulary of the training set, and use that to map words to indices. Hash tables and tries are common candidates for dictionary implementation. E.g., the three documents</p>
<p>John likes to watch movies.<br>Mary likes movies too.<br>John also likes football.<br>can be converted, using the dictionary<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Term    Index</span><br><span class="line">John    <span class="number">1</span></span><br><span class="line">likes   <span class="number">2</span></span><br><span class="line">to      <span class="number">3</span></span><br><span class="line">watch   <span class="number">4</span></span><br><span class="line">movies  <span class="number">5</span></span><br><span class="line">Mary    <span class="number">6</span></span><br><span class="line">too     <span class="number">7</span></span><br><span class="line">also    <span class="number">8</span></span><br><span class="line">football9</span><br></pre></td></tr></table></figure></p>
<p>to the term-document matrix</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> </span><br><span class="line"><span class="number">0</span> &amp; <span class="number">1</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> </span><br><span class="line"><span class="number">1</span> &amp; <span class="number">1</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">0</span> &amp; <span class="number">1</span> &amp; <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>(Punctuation was removed, as is usual in document classification and clustering.)</p>
<p>The problem with this process is that such dictionaries take up a large amount of storage space and grow in size as the training set grows. On the contrary, if the vocabulary is kept fixed and not increased with a growing training set, an adversary may try to invent new words or misspellings that are not in the stored vocabulary so as to circumvent a machine learned filter. This difficulty is why feature hashing has been tried for spam filtering at Yahoo! Research.</p>
<p>Note that the hashing trick isn’t limited to text classification and similar tasks at the document level, but can be applied to any problem that involves large (perhaps unbounded) numbers of features.</p>
<h3 id="Feature_vectorization_using_the_hashing_trick">Feature vectorization using the hashing trick</h3><p>Instead of maintaining a dictionary, a feature vectorizer that uses the hashing trick can build a vector of a pre-defined length by applying a hash function h to the features (e.g., words) in the items under consideration, then using the hash values directly as feature indices and updating the resulting vector at those indices:</p>
<p> function hashing_vectorizer(features : array of string, N : integer):<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">x :</span>= <span class="keyword">new</span> vector[N]</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> <span class="string">features:</span></span><br><span class="line">    <span class="string">h :</span>= hash(f)</span><br><span class="line">    x[h mod N] += <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p>
<p>It has been suggested that a second, single-bit output hash function ξ be used to determine the sign of the update value, to counter the effect of hash collisions. If such a hash function is used, the algorithm becomes</p>
<p> function hashing_vectorizer(features : array of string, N : integer):<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x := <span class="keyword">new</span> <span class="built_in">vector</span>[N]</span><br><span class="line"><span class="keyword">for</span> f in features:</span><br><span class="line">    h := hash(f)</span><br><span class="line">    idx := h mod N</span><br><span class="line">    <span class="keyword">if</span> ξ(f) == <span class="number">1</span>:</span><br><span class="line">        x[idx] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x[idx] -= <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p>
<p>The above pseudocode actually converts each sample into a vector. An optimized version would instead only generate a stream of (h,ξ) pairs and let the learning and prediction algorithms consume such streams; a linear model can then be implemented as a single hash table representing the coefficient vector.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>In machine learning, feature hashing, also known as the hashing trick(by analogy to the kernel trick), is a fast and space-efficient way ]]>
    </summary>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[机器学习资料大汇总]]></title>
    <link href="http://www.notehub.cn/2015/09/23/algo/ml/"/>
    <id>http://www.notehub.cn/2015/09/23/algo/ml/</id>
    <published>2015-09-22T16:00:00.000Z</published>
    <updated>2015-09-23T05:09:18.000Z</updated>
    <content type="html"><![CDATA[<p><img src="/images/other/ml.jpg" alt=""></p>
<p>注：本页面主要针对想快速上手机器学习而又不想深入研究的同学，对于专门的researcher，建议直接啃PRML，ESL，MLAPP以及你相应方向的书（比如Numerical Optimization，Graphic Model等），另外就是Follow牛会牛paper，如果谁有兴趣也可以一起来整理个专业的汇总页。本页面将持续更新，敬请关注，如有推荐的文章请留言，谢谢！</p>
<h3 id="开源工具">开源工具</h3><hr>
<p><a href="http://www.52ml.net/12043.html" target="_blank" rel="external">机器学习的开源工具</a><br><a href="http://www.52ml.net/13547.html" target="_blank" rel="external">Python机器学习库</a><br><a href="http://www.52ml.net/13002.html" target="_blank" rel="external">C++矩阵运算库推荐</a></p>
<h3 id="公开课">公开课</h3><hr>
<ul>
<li>Machine Learning | Coursera Andrew NG在coursera上的课，难度比公开课略低，适合入门</li>
<li>斯坦福大学公开课 ：机器学习课程 Andrew NG在学校里面的课程，网易公开课有中英文字幕，可以配合笔记来看</li>
<li>CMU机器学习系主任Tom Mitchell院士机器学习课程视频及课件（英文）</li>
<li>机器学习|加州理工，老师是Yaser Abu-Mostafa，会从最基本的理论开始，为你构建机器学习的基础。</li>
<li>机器学习基石 如果想听中文课程，台湾大学的这门就很合适，友情提示，台大的课程基本上都可以加快语速来听，原因你懂的</li>
<li>神经网络|多伦多大学 鼎鼎大名的Geoffrey Hinton ，这门课着实不容错过</li>
<li>凸优化课程|斯坦福 授课老师是凸优化经典教材的作者Stephen Boyd！有难度有挑战！</li>
<li>概率图模型  coursera的另外一个创始人，Daphne Koller的课程，值得一提的是，Koller因提出了Probabilistic Relational Models拿到了2001年的IJCAI Computers and Thought Award</li>
<li>统计学习|斯坦福 授课老师是ESL作者 ，还有同学把视频放在了百度网盘上～ 这个更快一些</li>
</ul>
<h3 id="1-_机器学习入门篇">1. 机器学习入门篇</h3><h4 id="1-1_机器学习介绍">1.1 机器学习介绍</h4><ul>
<li>机器学习-维基百科  Machine Learning-Wikipedia</li>
<li>机器学习简史</li>
<li>规则与机器学习 不建议为了机器学习而机器学习，对于初学者应该是先规则再机器学习，规则直观，可以深入理解领域知识和特征，要记住一个机器学习的专家必须首先是该领域知识的专家。</li>
<li>贝叶斯思想 MLAPP 第5章 Bayesian statistics 第6章 Frequentist statistics 机器学习第6章 贝叶斯学习</li>
<li>监督学习 ESL 第2章 Overview of Supervised Learning</li>
</ul>
<h4 id="1-2_书籍">1.2 书籍</h4><ul>
<li>《统计学习方法》 第1章 统计学习方法概论</li>
<li>《机器学习》（Mitchell） 第1章 引言</li>
<li>PRML 第1章 Introduction</li>
<li>MLAPP 第1章 Introduction 第2章 Probability</li>
<li>ESL 第1章 Introduction</li>
<li>Some Notes on Applied Mathematics for Machine (选修)</li>
<li>Machine Learning Textbook minireviews</li>
<li>List of Cool Machine Learning Books</li>
</ul>
<h4 id="1-3_数学基础">1.3 数学基础</h4><ul>
<li>线性代数：公开课： 线性代数；推荐文章 ： 线性代数的本质，</li>
<li>概率论：公开课： 概率课|台大 叶老师为人风趣幽默，课程也比较简单，容易听进去</li>
<li>书籍：MLAPP第二章</li>
<li>微积分：公开课：单变量微积分|MIT 多变量微积分|MIT</li>
</ul>
<p>——————————————-</p>
<h4 id="1-4_LDA">1.4 LDA</h4><ul>
<li>LDA最佳学习资料汇总</li>
</ul>
<h4 id="1-4_Spectral_Clustering">1.4 Spectral Clustering</h4><ul>
<li>Spectral Clustering最佳学习资料汇总</li>
</ul>
<h4 id="1-5_图像处理">1.5 图像处理</h4><ul>
<li>图像处理和计算机视觉中的经典论文</li>
</ul>
<h4 id="2_线性回归模型">2 线性回归模型</h4><ul>
<li>PRML 第3章 Linear Models for Regression</li>
<li>MLAPP 第7章 Linear Regression 第13章 Sparse Linear Models</li>
<li>ESL 第3章 Linear Method for Regression</li>
</ul>
<h4 id="3_线性分类模型">3 线性分类模型</h4><ul>
<li>PRML 第4章 Linear Models for Classification</li>
<li>MLAPP 第8章 Logistic Regression 第9章 Generalized Linear Models and the exponential family</li>
<li>ESL 第4章 Linear Method for Classification</li>
<li>统计机器学习 第6章 逻辑斯谛回归与最大熵模型</li>
</ul>
<h4 id="4_神经网络">4 神经网络</h4><ul>
<li>PRML 第5章 Neural Networks</li>
<li>ESL 第11章 Neural Networks</li>
<li>统计学习方法 第2章 感知机</li>
<li>机器学习 第4章 人工神经网络</li>
</ul>
<h4 id="5_支持向量机">5 支持向量机</h4><ul>
<li>统计学习方法 第7章 支持向量机 (强烈推荐)</li>
<li>PRML 第6章 Kernel Methods 第7章 Sparse Kernel Machine</li>
<li>ESL 第12章 Support Vector Machines and Flexible Discriminants</li>
<li>MLAPP 第14章 Kernels</li>
</ul>
<h4 id="6_图模型">6 图模型</h4><ul>
<li>PRML 第8章 Graphical Models</li>
<li>MLAPP 第10章 Directed graphical models（Bayes nets） 第19章 Undirected Graphical Models（Marcov random fields）第20章 Exact inference for graphical models 第26章 Graphical model structure learning</li>
<li>统计学习方法 第10章 隐马尔可夫模型 第11章 条件随机场</li>
<li>机器学习 6.11 贝叶斯信念网</li>
<li>ESL 第17章 Undirected Graphical Models</li>
<li>Koller 的书</li>
<li>Jordan 的书</li>
</ul>
<h4 id="7_混合模型和EM">7 混合模型和EM</h4><ul>
<li>PRML 第9章 Mixture Models and EM</li>
<li>MLAPP 第11章 Mixture models and the EM algorithm</li>
<li>ESL 8.5 The EM Algorithm</li>
<li>统计学习方法 第9章 EM算法及其推广</li>
</ul>
<h4 id="8_近似推理">8 近似推理</h4><ul>
<li>PRML 第10章 Approximate Inference</li>
<li>MLAPP 第21章 Variational Inference 第22章 More Variational Inference</li>
</ul>
<h4 id="9_采样方法">9 采样方法</h4><ul>
<li>PRML 第11章 Sampling Methods</li>
<li>MLAPP 第23章 Monte Carlo inference 第24章 Markov Chain Monte Carlo (MCMC) inference</li>
<li>ESL 8.6 MCMC for Sampling from Posterior</li>
</ul>
<h4 id="10_PCA">10 PCA</h4><ul>
<li>PRML 第12章 Continuous Latent Variables</li>
<li>MLAPP 第12章 Latent Linear Models</li>
<li>ESL 14.5 Principal Componens， Curves and Surfaces</li>
</ul>
<h4 id="11_HMM">11 HMM</h4><ul>
<li>PRML 13.1 13.2 Hidden Marcov Models</li>
<li>MLAPP 第17章 Marcov and Hidden Marcov Models</li>
</ul>
<h4 id="12_组合模型">12 组合模型</h4><ul>
<li>(投票，boosting，bagging，树模型，model averaging)</li>
<li>PRML 第14章 Combining Models</li>
<li>统计学习方法 第5章 决策树 第8章 提升方法</li>
<li>MLAPP 第16章 Adaptive basis function models</li>
<li>ESL 第15章 Random Forests 第16章 Ensemble Learning 8.7 Bagging 第9章 Additive Models, Trees, and Related Methods 第10章 Boosting and Additive Trees</li>
<li>机器学习 第3章 决策树学习</li>
</ul>
<h4 id="14_聚类">14 聚类</h4><ul>
<li>ESL 14.3 Cluster Analysis</li>
<li>MLAPP 25章 Clustering</li>
<li>PRML 9.1 K-means Clustering</li>
</ul>
<h4 id="15_近邻">15 近邻</h4><ul>
<li>ELS 第13章 Protype Methods and Nearest-Neighbors</li>
</ul>
<h4 id="16_Deep_Learning">16 Deep Learning</h4><ul>
<li><a href="http://deeplearning.net/" target="_blank" rel="external">http://deeplearning.net/</a></li>
<li>Deep Learning Tutorial</li>
<li>MLAPP 第28章 Deep Learning</li>
</ul>
<h4 id="2-2_Deep_Learning教程">2.2 Deep Learning教程</h4><ul>
<li>UFLDL-斯坦福大学Andrew Ng教授“Deep Learning”教程</li>
</ul>
<h3 id="3-_自然语言处理入门篇">3. 自然语言处理入门篇</h3><h4 id="3-1_斯坦福大学自然语言处理公开课">3.1 斯坦福大学自然语言处理公开课</h4><ul>
<li>NLP | 斯坦福  授课教师是 Dan Jurafsky 以及 Christopher Manning，英文不是很有信心的可以参考《斯坦福大学自然语言处理公开课中文解读》</li>
<li>NLP | 哥伦比亚 授课老师是Michael Collins大神</li>
</ul>
<h4 id="3-2_统计机器翻译">3.2 统计机器翻译</h4><ul>
<li>Statistical Machine Translation</li>
<li>统计机器翻译开源软件汇总</li>
</ul>
<p>转自：<a href="http://www.52ml.net/star?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="external">http://www.52ml.net/star?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><img src="/images/other/ml.jpg" alt=""></p>
<p>注：本页面主要针对想快速上手机器学习而又不想深入研究的同学，对于专门的researcher，建议直接啃PRML，ESL，MLAPP以及你相应方向的书（比如Numerical Opt]]>
    </summary>
    
      <category term="PPTP, vpn" scheme="http://www.notehub.cn/tags/PPTP-vpn/"/>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to customize Writable class in Hadoop]]></title>
    <link href="http://www.notehub.cn/2015/09/21/dev/How%20to%20customize%20Writable%20class%20in%20Hadoop/"/>
    <id>http://www.notehub.cn/2015/09/21/dev/How to customize Writable class in Hadoop/</id>
    <published>2015-09-21T04:49:45.000Z</published>
    <updated>2015-09-21T06:13:25.000Z</updated>
    <content type="html"><![CDATA[<p>I’m trying to implement Writable class, but i have no idea on how to implement a writable class if in my class there is nested object, such as list, etc.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StorageClass</span> <span class="keyword">implements</span> <span class="title">Writable</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> String xStr;</span><br><span class="line"><span class="keyword">public</span> String yStr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> List&lt;Field&gt; sStor</span><br><span class="line"></span><br><span class="line"><span class="comment">//omitted ctors</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="annotation">@override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    out.writeChars(xStr);</span><br><span class="line">    out.WriteChars(yStr);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//WHAT SHOULD I DO FOR List&lt;Field&gt;</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="annotation">@override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    xStr = in.readLine();</span><br><span class="line">    yStr = in.readLine();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//WHAT SHOULD I DO FOR List&lt;Field&gt;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SubStorage</span></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> String x;</span><br><span class="line">    <span class="keyword">public</span> String y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Following is the Field class:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Field</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Field</span>&gt;, <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> DataType dataType;</span><br><span class="line">    <span class="keyword">private</span> Object value;</span><br><span class="line">    <span class="keyword">private</span> FieldType fieldType;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Field</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  <span class="title">Field</span><span class="params">(String name, DataType dataType, FieldType fieldType)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(name, dataType, <span class="keyword">null</span>, fieldType);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  <span class="title">Field</span><span class="params">(String name, DataType type, Object value, FieldType fieldType)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.dataType = type;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.fieldType = fieldType;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> FieldType &#123;</span><br><span class="line">    PRI, LOOKUP, SCD, VERSION, OTHER</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> DataType &#123;</span><br><span class="line"></span><br><span class="line">    UNDEFINED(<span class="number">4</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSizeInBytes</span><span class="params">(Object value)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> STRING.getSizeInBytes(value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    STRING(<span class="number">4</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSizeInBytes</span><span class="params">(Object value)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">super</span>.getSizeInBytes(value) + (value.toString().length() * <span class="number">2</span>); <span class="comment">// length + chars</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    INT(<span class="number">4</span>),</span><br><span class="line">    LONG(<span class="number">8</span>),</span><br><span class="line">    DOUBLE(<span class="number">8</span>),</span><br><span class="line">    DATETIME(<span class="number">8</span>),</span><br><span class="line">    BOOLEAN(<span class="number">1</span>),</span><br><span class="line">    BYTE(<span class="number">1</span>),</span><br><span class="line">    FLOAT(<span class="number">4</span>),</span><br><span class="line">    SHORT(<span class="number">2</span>),</span><br><span class="line">    CHAR(<span class="number">2</span>),</span><br><span class="line">    DATE(<span class="number">8</span>),</span><br><span class="line">    TIME(<span class="number">8</span>),</span><br><span class="line"></span><br><span class="line">    BLOB(<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSizeInBytes</span><span class="params">(Object value)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> ((<span class="keyword">byte</span>[])value).length;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sizeInBytes;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">DataType</span><span class="params">(<span class="keyword">int</span> sizeInBytes)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sizeInBytes = sizeInBytes;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSizeInBytes</span><span class="params">(Object value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> sizeInBytes;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Serializing collections is quite simple.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> size = in.readInt();</span><br><span class="line">    list= <span class="keyword">new</span> ArrayList&lt;Field&gt;(size);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)&#123;</span><br><span class="line">        Field f = <span class="keyword">new</span> Field();</span><br><span class="line">        f.readFields(in);</span><br><span class="line">        list.add(f);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    out.writeInt(list.size());</span><br><span class="line">    <span class="keyword">for</span> (Field l : list) &#123;</span><br><span class="line">        l.write(out);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>I’m trying to implement Writable class, but i have no idea on how to implement a writable class if in my class there is nested object, su]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[MurmurHash]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/murmurhash-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/murmurhash-md/</id>
    <published>2015-09-03T06:55:54.000Z</published>
    <updated>2015-09-03T06:58:03.000Z</updated>
    <content type="html"><![CDATA[<p>　　MurmurHash 是一种非加密型哈希函数，适用于一般的哈希检索操作。由Austin Appleby在2008年发明，并出现了多个变种，都已经发布到了公有领域(public domain)。与其它流行的哈希函数相比，对于规律性较强的key，MurmurHash的随机分布特征表现更良好。</p>
<h3 id="变种">变种</h3><p>　　当前的版本是MurmurHash3， 能够产生出32-bit或128-bit哈希值。较早的MurmurHash2能产生32-bit或64-bit哈希值。对于大端存储和强制对齐的硬件环境有一个较慢的MurmurHash2可以用。MurmurHash2A 变种增加了Merkle–Damgård 构造，所以能够以增量方式调用。 有两个变种产生64-bit哈希值：MurmurHash64A，为64位处理器做了优化；MurmurHash64B，为32位处理器做了优化。MurmurHash2-160用于产生160-bit 哈希值，而MurmurHash1已经不再使用。</p>
<h3 id="实现">实现</h3><p>　　最初的实现是C++的，但是被移植到了其他的流行语言上，包括 Python, C,C#, Perl, Ruby, PHP,Haskell,、Scala、Java和JavaScript等。这个算法已经被若干开源计划所采纳，最重要的有libstdc++ (4.6版)、Perl、nginx (不早于1.0.1版)、Rubinius、 libmemcached (Memcached的C语言客户端驱动)、maatkit、Hadoop、Kyoto Cabinet以及RaptorDB。</p>
<p>A sample C implementation follows:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">uint32_t</span> murmur3_32(<span class="keyword">const</span> <span class="keyword">char</span> *key, <span class="keyword">uint32_t</span> len, <span class="keyword">uint32_t</span> seed) &#123;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> c1 = <span class="number">0xcc9e2d51</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> c2 = <span class="number">0x1b873593</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> r1 = <span class="number">15</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> r2 = <span class="number">13</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> m = <span class="number">5</span>;</span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">uint32_t</span> n = <span class="number">0xe6546b64</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">uint32_t</span> hash = seed;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">int</span> nblocks = len / <span class="number">4</span>;</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">uint32_t</span> *blocks = (<span class="keyword">const</span> <span class="keyword">uint32_t</span> *) key;</span><br><span class="line">	<span class="keyword">int</span> i;</span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; nblocks; i++) &#123;</span><br><span class="line">		<span class="keyword">uint32_t</span> k = blocks[i];</span><br><span class="line">		k *= c1;</span><br><span class="line">		k = (k &lt;&lt; r1) | (k &gt;&gt; (<span class="number">32</span> - r1));</span><br><span class="line">		k *= c2;</span><br><span class="line"> </span><br><span class="line">		hash ^= k;</span><br><span class="line">		hash = ((hash &lt;&lt; r2) | (hash &gt;&gt; (<span class="number">32</span> - r2))) * m + n;</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">uint8_t</span> *tail = (<span class="keyword">const</span> <span class="keyword">uint8_t</span> *) (key + nblocks * <span class="number">4</span>);</span><br><span class="line">	<span class="keyword">uint32_t</span> k1 = <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">switch</span> (len &amp; <span class="number">3</span>) &#123;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">		k1 ^= tail[<span class="number">2</span>] &lt;&lt; <span class="number">16</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">		k1 ^= tail[<span class="number">1</span>] &lt;&lt; <span class="number">8</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">		k1 ^= tail[<span class="number">0</span>];</span><br><span class="line"> </span><br><span class="line">		k1 *= c1;</span><br><span class="line">		k1 = (k1 &lt;&lt; r1) | (k1 &gt;&gt; (<span class="number">32</span> - r1));</span><br><span class="line">		k1 *= c2;</span><br><span class="line">		hash ^= k1;</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">	hash ^= len;</span><br><span class="line">	hash ^= (hash &gt;&gt; <span class="number">16</span>);</span><br><span class="line">	hash *= <span class="number">0x85ebca6b</span>;</span><br><span class="line">	hash ^= (hash &gt;&gt; <span class="number">13</span>);</span><br><span class="line">	hash *= <span class="number">0xc2b2ae35</span>;</span><br><span class="line">	hash ^= (hash &gt;&gt; <span class="number">16</span>);</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">return</span> hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="相关资源：">相关资源：</h3><ol>
<li><a href="http://blog.csdn.net/yfkiss/article/details/7337382" target="_blank" rel="external">http://blog.csdn.net/yfkiss/article/details/7337382</a></li>
<li><a href="https://zh.wikipedia.org/wiki/Murmur%E5%93%88%E5%B8%8C" target="_blank" rel="external">https://zh.wikipedia.org/wiki/Murmur%E5%93%88%E5%B8%8C</a></li>
<li><a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="external">https://en.wikipedia.org/wiki/MurmurHash</a></li>
<li><a href="https://github.com/lijingpeng/java_util/tree/master/src/util/hash" target="_blank" rel="external">https://github.com/lijingpeng/java_util/tree/master/src/util/hash</a></li>
<li><a href="https://github.com/huichen/murmur/blob/master/murmur.go" target="_blank" rel="external">https://github.com/huichen/murmur/blob/master/murmur.go</a></li>
<li><a href="https://pypi.python.org/pypi/mmh3/2.0" target="_blank" rel="external">https://pypi.python.org/pypi/mmh3/2.0</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　MurmurHash 是一种非加密型哈希函数，适用于一般的哈希检索操作。由Austin Appleby在2008年发明，并出现了多个变种，都已经发布到了公有领域(public domain)。与其它流行的哈希函数相比，对于规律性较强的key，MurmurHash的随机分]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Java beta distribution]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/java-beta-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/java-beta-md/</id>
    <published>2015-09-03T06:51:59.000Z</published>
    <updated>2015-09-03T06:54:33.000Z</updated>
    <content type="html"><![CDATA[<p>维基百科介绍：<a href="https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83" target="_blank" rel="external">https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83</a><br><a href="https://en.wikipedia.org/wiki/Beta_distribution" target="_blank" rel="external">https://en.wikipedia.org/wiki/Beta_distribution</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.commons.math3.distribution.BetaDistribution;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">test</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span><br><span class="line">     * <span class="doctag">@param</span> args</span><br><span class="line">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span> x;</span><br><span class="line">        <span class="keyword">double</span> b;</span><br><span class="line">        BetaDistribution beta = <span class="keyword">new</span> BetaDistribution(<span class="number">40.0</span>, <span class="number">40.0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">            x = Math.random();</span><br><span class="line">            b = beta.inverseCumulativeProbability(x);</span><br><span class="line">            System.out.println(b);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实现：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BetaDistributionE</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getBetaDistribution</span><span class="params">(<span class="keyword">double</span> alpha, <span class="keyword">double</span> beta)</span></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> a = alpha + beta;</span><br><span class="line">	<span class="keyword">double</span> b;</span><br><span class="line">	<span class="keyword">if</span>(Math.min(alpha, beta) &lt;= <span class="number">1</span>)&#123;</span><br><span class="line">		b = Math.max(<span class="number">1</span>/alpha, <span class="number">1</span>/beta);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span>&#123;</span><br><span class="line">	b = Math.sqrt((a - <span class="number">2</span>) / (<span class="number">2</span>*alpha*beta - a));</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">double</span> c = alpha + <span class="number">1</span>/b;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">double</span> W = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">boolean</span> reject = <span class="keyword">true</span>;</span><br><span class="line">	<span class="keyword">for</span> (reject = <span class="keyword">true</span>; reject; ) &#123;</span><br><span class="line"> 		<span class="keyword">double</span> U1 = Math.random();</span><br><span class="line"> 		<span class="keyword">double</span> U2 = Math.random();</span><br><span class="line"> 		<span class="keyword">double</span> V = b * Math.log(U1/(<span class="number">1</span>-U1));</span><br><span class="line"> 		W = alpha * Math.exp(V);</span><br><span class="line"> 		reject = (a*Math.log(a/(beta+W)) + c*V - Math.log(<span class="number">4</span>)) &lt; Math.log(U1*U1*U2);</span><br><span class="line"> 	&#125;</span><br><span class="line"> 	<span class="keyword">return</span> (W / (beta + W));</span><br><span class="line"> 	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>相关资源：</p>
<ol>
<li><a href="http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math3/distribution/BetaDistribution.html" target="_blank" rel="external">http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math3/distribution/BetaDistribution.html</a></li>
<li><a href="http://stackoverflow.com/questions/13634170/java-using-beta-distribution-to-generate-a-random-number-from-0-to-1" target="_blank" rel="external">http://stackoverflow.com/questions/13634170/java-using-beta-distribution-to-generate-a-random-number-from-0-to-1</a></li>
<li>go语言实现：<a href="https://github.com/purzelrakete/bandit/blob/4fca67f963006845de83860fcd849625251fce57/math/rand.go#L21" target="_blank" rel="external">https://github.com/purzelrakete/bandit/blob/4fca67f963006845de83860fcd849625251fce57/math/rand.go#L21</a></li>
<li>非均衡抽样，在一个概率区间内抽样：Paper：Generating Beta Variates with Nonintegral Shape Parameters</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>维基百科介绍：<a href="https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83" target="_blank" rel="external">https://zh.wikipedia.org/wiki/%CE%]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[二项分布和Beta分布]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/beta-a-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/beta-a-md/</id>
    <published>2015-09-03T06:33:26.000Z</published>
    <updated>2015-09-03T06:49:32.000Z</updated>
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br></pre></td></tr></table></figure>
<h2 id="二项分布">二项分布</h2><hr>
<p>　　在概率论和统计学中，二项分布是n个独立的[是/非]试验中成功的次数的离散概率分布，其中每次试验的成功概率为$p$。举两个例子就很容易理解二项分布的含义了：</p>
<ul>
<li>抛一次硬币出现正面的概率是0.5($p$)，抛10(n)次硬币，出现k次正面的概率。</li>
<li>掷一次骰子出现六点的概率是1/6，投掷6次骰子出现k次六点的概率。</li>
</ul>
<p>　　在上面的两个例子中，每次抛硬币或者掷骰子都和上次的结果无关，所以每次实验都是独立的。二项分布是一个离散分布，k的取值范围为从0到n，只有n+1种可能的结果。scipy.stats.binom为二项分布，下面用它计算抛十次硬币，出现k次正面的概率分布。</p>
<h4 id="In_[16]:">In [16]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = np.arange(n+<span class="number">1</span>)</span><br><span class="line">pcoin = stats.binom.pmf(k, n, <span class="number">0.5</span>)</span><br><span class="line">pcoin</span><br></pre></td></tr></table></figure>
<h4 id="Out[16]:">Out[16]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([ <span class="number">0.00097656</span>,  <span class="number">0.00976563</span>,  <span class="number">0.04394531</span>,  <span class="number">0.1171875</span> ,  <span class="number">0.20507813</span>,</span><br><span class="line">        <span class="number">0.24609375</span>,  <span class="number">0.20507813</span>,  <span class="number">0.1171875</span> ,  <span class="number">0.04394531</span>,  <span class="number">0.00976563</span>,</span><br><span class="line">        <span class="number">0.00097656</span>])</span><br></pre></td></tr></table></figure>
<h4 id="In_[17]:">In [17]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pl.stem(k, pcoin, basefmt=<span class="string">"k-"</span>)</span><br><span class="line">pl.margins(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss.png" alt=""><br>下面是投掷6次骰子，出现6点的概率分布。</p>
<h4 id="In_[18]:">In [18]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">6</span></span><br><span class="line">k = np.arange(n+<span class="number">1</span>)</span><br><span class="line">pdice = stats.binom.pmf(k, n, <span class="number">1.0</span>/<span class="number">6</span>)</span><br><span class="line">pdice</span><br></pre></td></tr></table></figure>
<h4 id="Out[18]:">Out[18]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([  <span class="number">3.34897977e-01</span>,   <span class="number">4.01877572e-01</span>,   <span class="number">2.00938786e-01</span>,</span><br><span class="line">         <span class="number">5.35836763e-02</span>,   <span class="number">8.03755144e-03</span>,   <span class="number">6.43004115e-04</span>,</span><br><span class="line">         <span class="number">2.14334705e-05</span>])</span><br></pre></td></tr></table></figure>
<h4 id="In_[19]:">In [19]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pl.stem(k, pdice, basefmt=<span class="string">"k-"</span>)</span><br><span class="line">pl.margins(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss1.png" alt=""></p>
<h2 id="Beta分布">Beta分布</h2><hr>
<p>　　对于硬币或者骰子这样的简单实验，我们事先能很准确地掌握系统成功的概率。然而通常情况下，系统成功的概率是未知的。为了测试系统的成功概率$p$，我们做n次试验，统计成功的次数k，于是很直观地就可以计算出$p = k/n$。然而由于系统成功的概率是未知的，这个公式计算出的$p$只是系统成功概率的最佳估计。也就是说实际上$p$也可能为其它的值，只是为其它的值的概率较小。</p>
<p>　　例如有某种特殊的硬币，我们事先完全无法确定它出现正面的概率。然后抛10次硬币，出现5次正面，于是我们认为硬币出现正面的概率最可能是0.5。但是即使硬币出现正面的概率为0.4，也会出现抛10次出现5次正面的情况。因此我们并不能完全确定硬币出现正面的概率就是0.5，所以$p$也是一个随机变量，它符合Beta分布。</p>
<p>　　Beta分布是一个连续分布，由于它描述概率$p$的分布，因此其取值范围为0到1。 Beta分布有$\alpha$和$\beta$两个参数，其中$\alpha$为成功次数加1，$\beta$为失败次数加1。连续分布用概率密度函数描述，下面绘制实验10次，成功4次和5次时，系统成功概率$p$的分布情况。可以看出$k=5$时，曲线的峰值在$p=0.5$处，而$k=4$时，曲线的峰值在$p=0.4$处。</p>
<h4 id="In_[20]:">In [20]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = <span class="number">5</span></span><br><span class="line">p = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"k=5"</span>, lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"k=4"</span>, lw=<span class="number">2</span>)</span><br><span class="line">xlabel(<span class="string">"$p$"</span>)</span><br><span class="line">legend(loc=<span class="string">"best"</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss3.png" alt=""><br>　　下面绘制$n=10, k=4$和$n=20, k=8$的概率分布。可以看出峰值都在$p=0.4$处，但是$n=20$的山峰更陡峭。也就是说随着实验次数的增加，$p$取其它值的可能就越小，对$p$的估计就更有信心，因此山峰也就更陡峭了。</p>
<h4 id="In_[30]:">In [30]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">p = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"n=10"</span>, lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">20</span></span><br><span class="line">k = <span class="number">8</span></span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"n=20"</span>, lw=<span class="number">2</span>)</span><br><span class="line">xlabel(<span class="string">"$p$"</span>)</span><br><span class="line">legend(loc=<span class="string">"best"</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss4.png" alt=""></p>
<h2 id="用pymc模拟">用pymc模拟</h2><hr>
<p>　　假设我们的知识库中没有Beta分布，如何通过模拟实验找出$p$的概率分布呢？pymc是一个用于统计估计的库，它可以通过 先验概率和 观测值 模拟出 后验概率 的分布。下面先解释一下这两个概率：</p>
<ul>
<li>先验概率：在贝叶斯统计中，某一不确定量p的先验概率分布是在考虑”观测数据”前，能表达p不确定性的概率分布。</li>
<li>后验概率：在考虑相关证据或数据后所得到的不确定量p的概率分布。</li>
</ul>
<p>　　拿前面抛硬币的实验来说，如果在做实验之前能确信硬币出现正面的概率大概在0.5附近的话，那么它的先验概率就是一个以0.5为中心的山峰波形。而如果是某种特殊的硬币，我们对其出现正面的概率完全不了解，那么它的先验概率就是一个从0到1的平均分布。为了估计这个特殊硬币出现正面的概率，我们做了20次实验，其中出现了8次正面。通过这个实验，硬币出现正面的可能性的后验概率就如上图中的绿色曲线所示。</p>
<p>　　pymc库可以通过先验概率和观测值模拟出后验概率的分布，这对于一些复杂的系统的估计是很有用的。下面我们看看如何用pymc来对这个特殊硬币出现正面的可能性进行估计：首先pcoin是这个特殊硬币出现正面的概率，由于我们没有任何先验知识，因此它的先验概率是一个从0到1的平均分布(Uniform)。假设我们做了20次实验，其中8次为正面。根据前面的介绍可知，出现正面的次数符合二项分布(Binomial)，并且这个二项分布的概率$p$为pcoin。这个通过value参数指定了实验的结果。因此experiment虽然是一个二项分布，但是它已经不能取其它值了。</p>
<h4 id="In_[32]:">In [32]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymc</span><br><span class="line">pcoin = pymc.Uniform(<span class="string">"pcoin"</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">experiment = pymc.Binomial(<span class="string">"experiment"</span>, <span class="number">20</span>, pcoin, value=<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<p>　　接下来通过MCMC对象模拟pcoin的后验概率。MCMC是Markov chain Monte Carlo(马尔科夫蒙特卡洛)的缩写，它是一种用马尔可夫链从随机分布取样的算法。通过调用MCMC对象的sample()，可以对pcoin的后验概率分布进行取样。这里30000为取样次数，5000表示不保存头5000次取样值。这时因为MCMC算法通常有一个收敛过程，我们希望只保留收敛之后的取样值。</p>
<h4 id="In_[33]:">In [33]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mc = pymc.MCMC([pcoin])</span><br><span class="line">mc.sample(<span class="number">30000</span>, <span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<p>[<strong><strong><strong><em>**</em></strong></strong></strong>100%<strong><strong><strong><strong>**</strong></strong></strong></strong>]  30000 of 30000 complete<br>　　通过MCMC对象trace()可以获得某个不确定量的取样值。下面的程序获得pcoin的25000次取样值，并用hist()显示其分布情况。由结果可知pcoin的分布与前面介绍的Beta分布一致。</p>
<h4 id="In_[31]:">In [31]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pcoin_trace = mc.trace(<span class="string">"pcoin"</span>)[:]</span><br><span class="line">hist(pcoin_trace, normed=<span class="keyword">True</span>, bins=<span class="number">30</span>);</span><br><span class="line">plot(p, pbeta, <span class="string">"r"</span>, label=<span class="string">"n=20"</span>, lw=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Out[31]:">Out[31]:</h4><p><img src="/images/algo/ssss5.png" alt=""></p>
<h4 id="In_[34]:">In [34]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcoin_trace.shape</span><br></pre></td></tr></table></figure>
<h4 id="Out[34]:">Out[34]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">25000</span>,)</span><br></pre></td></tr></table></figure>
<p>链接：<a href="http://hyry.dip.jp/tech/slice/slice.html/42" target="_blank" rel="external">http://hyry.dip.jp/tech/slice/slice.html/42</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span clas]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[理解Beta分布和Dirichlet分布]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/beta-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/beta-md/</id>
    <published>2015-09-03T06:18:04.000Z</published>
    <updated>2015-09-03T06:31:39.000Z</updated>
    <content type="html"><![CDATA[<p><br><br>在Machine Learning中，有一个很常见的概率分布叫做Beta Distribution：<br><img src="/images/algo/j8b261e3942f702b2a36d5221f9a006bf.png" alt=""><br>同时，Dirichelet Distribution：</p>
<p><img src="/images/algo/j24fc194e3126c49d315032f55d0a52e2.png" alt=""></p>
<h3 id="解释">解释</h3><hr>
<p>　　如果给你一个硬币，投这个硬币有\theta的概率抛出Head，有(1-\theta)的概率抛出Tail。如果在未来抛了五次这个硬币，有三次是Head，有两次是Tail，这个\theta最有可能是多少呢？如果你必须给出一个确定的值，并且你完全根据目前观测的结果来估计\theta，那么\theta = 3/5。</p>
<p><img src="/images/algo/a.png" alt=""></p>
<p>　　如果未来抛出五次硬币，全部都是Head。那么按照1中的逻辑，你将估计\theta为1。也就是说，你估计这枚硬币不管怎么投，都朝上！可是，你想这或许是巧合：世界上没有这么屌的硬币，硬币还是有一定可能抛出Tail的。就算观测到再多次的Head，抛出Tail的概率还是不可能为0。这时候，Bayesian公式横空出世（如下图所示）。我们在估计\theta时，心中先有一个估计，即先验概率。这个估计，表现在Probability中，就是一个概率分布。通俗得来讲，我们不再认为\theta是个固定的值了。</p>
<p><img src="/images/algo/j8b6e228eaeb570260d0f8c12a18add50.png" alt=""></p>
<p>　　在上面的Bayesian公式中，p(\theta)就是个概率分布。这个概率分布可以是任何概率分布，比如高斯分布，比如我们想要说的Beta Distribution。下图是Beta(5,2)的概率分布图。如果我们将这个概率分布作为p(\theta)，那么我们在还未抛硬币前，便认为\theta很可能接近于0.8，而不大可能是个很小的值或是一个很大的值。即，我们在抛硬币前，便估计这枚硬币更可能有0.8的概率抛出正面。</p>
<p><img src="/images/algo/j9f3ba3610336773ac92573a548621b3e.png" alt=""></p>
<p>　　虽然p(\theta)可以是任何种类的概率分布，但是如果使用Beta Distribution，会让之后的计算更加方便。我们接着继续看便知道这是为什么了。况且，通过调节Beta Distribution中的a和b，你可以让这个概率分布变成各种你想要的形状！Beta Distribution已经很足够表达你事先对\theta的估计了。现在我们已经估计好了p(\theta)为一个Beta Distribution，那么p(X|\theta)是多少呢？其实就是个二项分布。继续以1中抛5次硬币抛出3次Head为例，X=抛5次硬币抛出3个Head的事件。</p>
<p><img src="/images/algo/ja3a99d005b464c5164166547afc9e13b.png" alt=""><br>　　Bayesian公式下的p(X)是个Normalizer，或者叫做marginal probability。在\theta离散的情况下，p(X)就是\theta为不同值的时候，p(X|\theta)的求和。比如，如果我们事先估计硬币抛出正面的概率只可能是0.5或者0.8，那么p(X) = p(X|\theta=0.5)+p(X|\theta=0.8)，计算时分别将\theta=0.5和\theta=0.8代入到7中的公式中。而如果我们用Beta Distribution，\theta的概率分布在[0,1]之间是连续的，所以要用积分。</p>
<p><img src="/images/algo/j48e8020e87f818d9414e03ffb9fcf248.png" alt=""></p>
<p>　　p(\theta)是个Beta Distribution，那么在观测到X=抛5次硬币中有3个head的事件后，p(\theta|X)依旧是个Beta Distribution！只是这个概率分布的形状因为观测的事件而发生了变化。<br><img src="/images/algo/j0eca37b51f989944703ffbabadb40086.png" alt=""></p>
<p>　　因为观测前后，对\theta估计的概率分布均为Beta Distribution，这就是为什么使用Beta Distribution方便我们计算的原因了。当我们得知p(\theta|X)=Beta(\theta|a+3, b+2)后，我们就只要根据Beta Distribution的特性，得出\theta最有可能等于多少了。（即\theta等于多少时，观测后得到的Beta distribution有最大的概率密度）。例如下图，仔细观察新得到的Beta Distribution，和（5）中的概率分布对比，发现峰值从0.8左右的位置移向了0.7左右的位置。这是因为新观测到的数据中，5次有3次是head（60%），这让我们觉得，\theta没有0.8那么高。但由于我们之前觉得\theta有0.8那么高，我们觉得抛出head的概率肯定又要比60%高一些！这就是Bayesian方法和普通的统计方法不同的地方。我们结合自己的先验概率和观测结果来给出预测。</p>
<p><img src="/images/algo/j01a0b8b112291e2355890ac32572b01b.png" alt=""></p>
<p>　　如果我们投的不是硬币，而是一个多面体（比如筛子），那么我们就要使用Dirichlet Distribution了。使用Dirichlet Distributio的目的，也是为了让观测后得到的posterior probability依旧是Dirichlet Distribution。比如，我们抛掷一个三面体。抛出这三个面的概率分别为\theta_1, \theta_2和\theta_3。不论\theta_1, \theta_2和\theta_3如何分布，它们相加必须等于1。那它们的概率分布，是在一个立体的空间里的一个面。这个面由\theta_1+\theta_2+\theta_3=1表示。这个面上的任意一点，表示某种\theta_1, \theta_2和\theta_3组合的概率密度。下三图分别由不同的\alpha vector初始化得到不同的Dirichlet Distribution，红颜色代表概率密度较大，蓝颜色的区域概率密度较小。</p>
<p><img src="/images/algo/j3f8307ef170c6664eea5996932322a29.png" alt=""><br>　　Dirichlet Distribution和Beta Distribution都叫做Conjugate Prior。根据你的likelihood function，你可以选择对应的conjugate prior作为你对p(\theta)事先的估计。<br><img src="/images/algo/j3481aac389b57152d20380150d0abd4a.png" alt=""><br>转自：<a href="http://maider.blog.sohu.com/306392863.html" target="_blank" rel="external">http://maider.blog.sohu.com/306392863.html</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><br><br>在Machine Learning中，有一个很常见的概率分布叫做Beta Distribution：<br><img src="/images/algo/j8b261e3942f702b2a36d5221f9a006bf.png" alt=""><br>同时]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[忠诚度越高买东西越贵]]></title>
    <link href="http://www.notehub.cn/2015/09/03/other/nitian-md/"/>
    <id>http://www.notehub.cn/2015/09/03/other/nitian-md/</id>
    <published>2015-09-03T06:01:28.000Z</published>
    <updated>2015-09-03T06:07:50.000Z</updated>
    <content type="html"><![CDATA[<p>　　引言：马云曾说，阿里巴巴本质上就是一家数据公司，做淘宝的目的也不是为了卖货，而是获得所有零售的数据和制造业的数据；做物流也不仅仅为了送包裹，而是要把这些数据合在一起。而亚马逊公司作为美国最大的一家网络电子商务公司，是网络上最早开始经营电子商务的公司之一，20年的持续发展关键也离不开对数据的分析。如今，我们正从IT时代走向DT时代，即从information technology转向data technology。</p>
<p>　　先问大家一个问题，AB两个顾客同时想买某个品牌的东西，其中A顾客对这个品牌非常喜欢，B是新顾客。如果你是这个品牌的经营者的话，你会卖给谁更贵（假设不是标准定价）？</p>
<p>　　答案是A，我们很多人的观点是我们一定要对老顾客好一些，给他们最优的待遇。这其实是从消费者的角度出发思考，其实从经营的角度来说，忠诚度越高我们反而应该卖得更贵，因为企业经营是追求利润最大化（互联网思维的企业除外哈），另外忠诚度高的顾客不用太担心流失。</p>
<p>　　欺负老顾客，这是一个人艰不拆的真理，会让很多人眼泪忍不住的流下来。其实现在不就是这样的吗？首次打车的顾客免单，第一次购买电影票补贴，第一次消费打折等等。只是这些我们能接受，我们认为合理，接下来讲一个真实的差异化定价的案例。</p>
<h3 id="亚马逊差异化定价测试">亚马逊差异化定价测试</h3><p>　　为提高在主营产品上的赢利，亚马逊在2000年9月中旬开始了著名的差别定价实验。他们选择了68种DVD碟片进行动态定价试验。试验当中，亚马逊根据潜在客户的人口统计资料、在亚马逊的购物历史、上网行为以及上网使用的软件系统确定对这68种碟片的报价水平。</p>
<p>　　例如，名为《泰特斯》（Titus）的碟片对新顾客的报价为22.74美元，而对那些对该碟片表现出兴趣的老顾客的报价则为26.24美元。通过这一定价策略，部分顾客付出了比其他顾客更高的价格，亚马逊因此提高了销售的毛利率。（网络购物可以做到千人千面，每个人看到的页面不一样，价格也可以不一样）</p>
<p>　　但是好景不长，这一差别定价策略实施不到一个月，就有细心的消费者发现了这一秘密，通过在名为DVDTalk 的音乐爱好者社区的交流，成百上千的DVD消费者知道了此事，那些付出高价的顾客当然怨声载道，纷纷在网上以激烈的言辞对亚马逊的做法进行口诛笔伐，有人甚至公开表示以后绝不会在亚马逊购买任何东西。更不巧的是，由于亚马逊前不久才公布了它对消费者在网站上的购物习惯和行为进行了跟踪和记录，因此，这次事件曝光后，消费者和媒体开始怀疑亚马逊是否利用其收集的消费者资料作为其价格调整的依据，这样的猜测让亚马逊的价格事件与敏感的网络隐私问题联系在了一起。最后的结局是亚马逊道歉，然后将差价退给了那些买贵了的顾客。这件事虽然以失败告终，但是这种差异化定价的思路却是可以借鉴的。</p>
<p>　　放眼望去，我们身边到处都是差异化定价的案例：菜市场的小贩看人下菜单，不同顾客买到的机票价格都不同，会员和非会员的价格也不一样，买的多和买得少价格也不一样。唯一不一样的是，这些差异化定价是按照我们常人的逻辑在运行，如买的多就应该便宜。亚马逊的案例恰恰和常规相反，但确实是经营的需要。那么如何做到根据需求差异定价呢？这种需求差异主要体现在时间、地点、消费对象之间三个方面。“时间就是金钱”在这点上彻底体现出来了，新手机上市，如果你是品牌忠实的追随者，那你必须付高价才能得到它，反之，你可以慢慢等待，等到价格降到你的目标价位的时候出手，有些地方高峰电价和平峰电价不一样，机票的价格和距起飞时间成反比，旅游景区的淡旺季门票差异等，这都是需求中利用时间差异的定价方法。</p>
<p>　　新开一个超市如果附近没有竞争对手和有竞争对手时的定价策略是不一样的，一瓶同样品牌的啤酒在超市和酒吧的价格大相径庭，演唱会前排的价格高于后排的价格，海景房的价格比山景房的价格贵等等，这都是需求中地点差异的定价方法。消费对象的定价差异更多体现在会员顾客和非会员顾客的价格差异上，以及女性相对于男性对价格敏感的差异上。未来随着科技的进步会逐渐发展到个体的定价差异上，例如零售商根据你购买或维修冰箱的数据，发现你的冰箱到了更换的时候，就可以给你寄一张200元的冰箱代金券，这样你的价格就和其他人不一样了。需要注意的是差异定价不能引起顾客的反感，需要透彻分析其中的风险。针对亚马逊这个案例，错就错在互联网购物价格太透明了，一旦穿帮就是丑闻。那怎么让顾客不反感，同时企业又能贯彻忠诚度高的顾客价格越贵的原则呢？答案见下图。</p>
<p><img src="/images/bb/792c43ea9c648c61a22c1a50a6439b15.jpg" alt=""><br>看明白了吗？</p>
<p>没看明白的话我就给大家点破吧！</p>
<p>将抽奖结果关联用户数据！</p>
<p>　　怎么理解这句话？就是当买家在网站买东西的时候，旁边放一个抽奖链接，买家可以根据抽奖结果来付款，抽奖结果又减30，减50，一分不减等选项。当买家在按下抽奖按钮的同时，后台大数据就开始工作了，根据你以往的购买数据很快可以算出你对这个商品的忠诚度，喜好度，需要的紧迫性等。当发现你从来没有买过类似的商品的话，就会让你中“大奖”。当发现你是优质买家，那不好意思了，一分不减。这样是不是每个人都高高兴兴的了？你还以为抽奖结果是随机的呢。其实买的永远没有卖的精！你可以看看现在淘宝、京东等消费性电商培都用了这一招！</p>
<h3 id="比较有价值的评论：">比较有价值的评论：</h3><ol>
<li><p>就是利用信息不对称赚钱，不过互联网就是要消除信息不对称，所以这条路其实在互联网上是走不通的</p>
</li>
<li><p>互联网时代，价格是透明的，跨店比价购买的成本近乎为零，同一件商品如果亚马逊卖50，京东卖49，天猫卖45，你猜消 费者会怎么选择？</p>
</li>
<li><p>杀熟很危险，如果用户知道了，可能会对品牌造成致命的影响，而你得到的不过蝇头小利。</p>
</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　引言：马云曾说，阿里巴巴本质上就是一家数据公司，做淘宝的目的也不是为了卖货，而是获得所有零售的数据和制造业的数据；做物流也不仅仅为了送包裹，而是要把这些数据合在一起。而亚马逊公司作为美国最大的一家网络电子商务公司，是网络上最早开始经营电子商务的公司之一，20年的持续发展]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Bayesian Bandits原理及在互联网广告行业的应用]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/</id>
    <published>2015-09-03T05:48:13.000Z</published>
    <updated>2015-09-03T05:59:25.000Z</updated>
    <content type="html"><![CDATA[<h2 id="1-_The_Multi-Armed_Bandit_Problem">1. The Multi-Armed Bandit Problem</h2><p>Suppose you are faced with N slot machines (colourfully called multi-armed bandits). Each bandit has an unknown probability of distributing a prize (assume for now the prizes are the same for each bandit, only the probabilities differ). Some bandits are very generous, others not so much. Of course, you don’t know what these probabilities are. By only choosing one bandit per round, our task is devise a strategy to maximize our winnings.</p>
<p>Of course, if we knew the bandit with the largest probability, then always picking this bandit would yield the maximum winnings. So our task can be phrased as “Find the best bandit, and as quickly as possible”.</p>
<p>The task is complicated by the stochastic nature of the bandits. A suboptimal bandit can return many winnings, purely by chance, which would make us believe that it is a very profitable bandit. Similarly, the best bandit can return many duds. Should we keep trying losers then, or give up?</p>
<p>A more troublesome problem is, if we have a found a bandit that returns pretty good results, do we keep drawing from it to maintain our pretty good score, or do we try other bandits in hopes of finding an even-better bandit? This is the exploration vs. exploitation dilemma.</p>
<h2 id="2-_Applications">2. Applications</h2><p>The Multi-Armed Bandit problem at first seems very artificial, something only a mathematician would love, but that is only before we address some applications:</p>
<p>Internet display advertising: companies have a suite of potential ads they can display to visitors, but the company is not sure which ad strategy to follow to maximize sales. This is similar to A/B testing, but has the added advantage of naturally minimizing strategies that do not work (and generalizes to A/B/C/D… strategies)</p>
<ol>
<li>Ecology: animals have a finite amount of energy to expend, and following certain behaviours has uncertain rewards. How does the animal maximize its fitness?</li>
<li>Finance: which stock option gives the highest return, under time-varying return profiles.</li>
<li>Clinical trials: a researcher would like to find the best treatment, out of many possible treatments, while minimizing losses.</li>
</ol>
<p>Many of these questions above are fundamental to the application’s field. It turns out the optimal solution is incredibly difficult, and it took decades for an overall solution to develop. There are also many approximately-optimal solutions which are quite good. The one I wish to discuss is one of the few solutions that can scale incredibly well. The solution is known asBayesian Bandits.</p>
<h2 id="3-_A_Proposed_Solution">3. A Proposed Solution</h2><p>Any proposed strategy is called an online algorithm (not in the internet sense, but in the continuously-being-updated sense), and more specifically a reinforcement learning algorithm. The algorithm starts in an ignorant state, where it knows nothing, and begins to acquire data by testing the system. As it acquires data and results, it learns what the best and worst behaviours are (in this case, it learns which bandit is the best). With this in mind, perhaps we can add an additional application of the Multi-Armed Bandit problem:</p>
<p>Psychology: how does punishment and reward effect our behaviour? How do humans’ learn?<br>The Bayesian solution begins by assuming priors on the probability of winning for each bandit. In our vignette we assumed complete ignorance of the these probabilities. So a very natural prior is the flat prior over 0 to 1. The algorithm proceeds as follows:</p>
<p>For each round,</p>
<ol>
<li>Sample a random variable Xb from the prior of bandit b, for all b.</li>
<li>Select the bandit with largest sample, i.e. select bandit B=argmaxXb.</li>
<li>Observe the result of pulling bandit B, and update your prior on bandit B.</li>
<li>Return to 1.</li>
</ol>
<p>That’s it. Computationally, the algorithm involves sampling from N distributions. Since the initial priors are Beta(α=1,β=1) (a uniform distribution), and the observed result X (a win or loss, encoded 1 and 0 respectfully) is Binomial, the posterior is a Beta(α=1+X,β=1+1−X)(see here for why to is true). </p>
<p>To answer a question from before, this algorithm suggests that we should not discard losers, but we should pick them at a decreasing rate as we gather confidence that there exist better bandits. This follows because there is always a non-zero chance that a loser will achieve the status of B, but the probability of this event decreases as we play more rounds (see figure below). Below is an implementation of the Bayesian Bandits strategy (which can be skipped for the less Pythonic-ly interested).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pymc <span class="keyword">import</span> rbeta</span><br><span class="line"> </span><br><span class="line">rand = np.random.rand</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bandits</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    This class represents N bandits machines.</span><br><span class="line"> </span><br><span class="line">    parameters:</span><br><span class="line">        p_array: a (n,) Numpy array of probabilities &gt;0, &lt;1.</span><br><span class="line"> </span><br><span class="line">    methods:</span><br><span class="line">        pull( i ): return the results, 0 or 1, of pulling </span><br><span class="line">                   the ith bandit.</span><br><span class="line">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, p_array)</span>:</span></span><br><span class="line">        self.p = p_array</span><br><span class="line">        self.optimal = np.argmax(p_array)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pull</span><span class="params">( self, i )</span>:</span></span><br><span class="line">        <span class="comment">#i is which arm to pull</span></span><br><span class="line">        <span class="keyword">return</span> rand() &lt; self.p[i]</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.p)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BayesianStrategy</span><span class="params">( object )</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Implements a online, learning strategy to solve</span><br><span class="line">    the Multi-Armed Bandit problem.</span><br><span class="line"> </span><br><span class="line">    parameters:</span><br><span class="line">        bandits: a Bandit class with .pull method</span><br><span class="line"> </span><br><span class="line">    methods:</span><br><span class="line">        sample_bandits(n): sample and train on n pulls.</span><br><span class="line"> </span><br><span class="line">    attributes:</span><br><span class="line">        N: the cumulative number of samples</span><br><span class="line">        choices: the historical choices as a (N,) array</span><br><span class="line">        bb_score: the historical score as a (N,) array</span><br><span class="line"> </span><br><span class="line">    """</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, bandits)</span>:</span></span><br><span class="line"> </span><br><span class="line">        self.bandits = bandits</span><br><span class="line">        n_bandits = len( self.bandits )</span><br><span class="line">        self.wins = np.zeros( n_bandits )</span><br><span class="line">        self.trials = np.zeros(n_bandits )</span><br><span class="line">        self.N = <span class="number">0</span></span><br><span class="line">        self.choices = []</span><br><span class="line">        self.bb_score = []</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample_bandits</span><span class="params">( self, n=<span class="number">1</span> )</span>:</span></span><br><span class="line"> </span><br><span class="line">        bb_score = np.zeros( n )</span><br><span class="line">        choices = np.zeros( n )</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="comment">#sample from the bandits's priors, and select the largest sample</span></span><br><span class="line">            choice = np.argmax( rbeta( <span class="number">1</span> + self.wins, <span class="number">1</span> + self.trials - self.wins) )</span><br><span class="line"> </span><br><span class="line">            <span class="comment">#sample the chosen bandit</span></span><br><span class="line">            result = self.bandits.pull( choice )</span><br><span class="line"> </span><br><span class="line">            <span class="comment">#update priors and score</span></span><br><span class="line">            self.wins[ choice ] += result</span><br><span class="line">            self.trials[ choice ] += <span class="number">1</span></span><br><span class="line">            bb_score[ k ] = result </span><br><span class="line">            self.N += <span class="number">1</span></span><br><span class="line">            choices[ k ] = choice</span><br><span class="line"> </span><br><span class="line">        self.bb_score = np.r_[ self.bb_score, bb_score ]</span><br><span class="line">        self.choices = np.r_[ self.choices, choices ]</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>Below we present a visualization of the algorithm sequentially learning the solution. In the figure below, the dashed lines represent the true hidden probabilities, which are (0.85, 0.60, 0.75)(this can be extended to many more dimensions, but the figure suffers, so I kept it at 3).</p>
<p><img src="/images/bb/updating2.png" alt=""></p>
<p>Note that we don’t real care how accurate we become about inference of the hidden probabilities — for this problem we are more interested in choosing the best bandit (or more accurately, becoming more confident in choosing the best bandit). For this reason, the distribution of the red bandit is very wide (representing ignorance about what that hidden probability might be) but we are reasonably confident that it is not the best, so the algorithm chooses to ignore it.</p>
<h3 id="几篇介绍Bayesian_Bandits的原理的文章：">几篇介绍Bayesian Bandits的原理的文章：</h3><ol>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html</a></li>
<li>在线演示博弈过程： <a href="https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/" target="_blank" rel="external">https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/</a></li>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html</a></li>
<li><a href="http://camdp.com/blogs/multi-armed-bandits" target="_blank" rel="external">http://camdp.com/blogs/multi-armed-bandits</a></li>
<li>贝叶斯书籍：<a href="https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers" target="_blank" rel="external">https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</a></li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="1-_The_Multi-Armed_Bandit_Problem">1. The Multi-Armed Bandit Problem</h2><p>Suppose you are faced with N slot machines (colourfully ]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Bayesian Bandits – optimizing click throughs with statistics]]></title>
    <link href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/"/>
    <id>http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/</id>
    <published>2015-09-03T05:36:48.000Z</published>
    <updated>2015-09-03T05:46:55.000Z</updated>
    <content type="html"><![CDATA[<p>Great news! A murder victim has been found. No slow news day today! The story is already written, now a title needs to be selected. The clever reporter who wrote the story has come up with two potential titles – “Murder victim found in adult entertainment venue” and “Headless Body found in Topless Bar”. (The latter title is one I’ve shamelessly stolen from the NY Daily News.) Once upon a time, deciding which title to run was a matter for a news editor to decide. Those days are now over – the geeks now rule the earth. Title selection is now primarily an algorithmic problem, not an editorial one.</p>
<p>One common approach is to display both potential versions of the title on the homepage or news feed, and measure the Click Through Rate (CTR) of each version of the title. At some point, when the measured CTR for one title exceeds that of the other title, you’ll switch to the one with the highest for all users. Algorithms for solving this problem are called bandit algorithms.</p>
<p>In this blog post I’ll describe one of my favorite bandit algorithms, the Bayesian Bandit, and show why it is an excellent method to use for problems which give us more information than typical bandit algorithms.</p>
<p>Unless you are already familiar with Bayesian statistics and beta distributions, I strongly recommend reading the previous blog post. That post provides much introductory material, and I’ll depend on it heavily.</p>
<h2 id="1-_The_problem_to_be_solved,_and_the_underlying_model">1. The problem to be solved, and the underlying model</h2><hr>
<p>Ultimately the problem we want to solve is the following. Consider an article being published on a website. The author or editor has come up with several possible titles – “Murder victim found in adult entertainment venue”, “Headless Body found in Topless Bar”, etc. We want to choose the title with the best click through rate (CTR). Let us represent each CTR by θi – i.e., θi is the true probability that an individual user will click on the i-th title. As a simplifying assumption, we assume that these rates θi do not change over time. It is important to note that we don’t actually know what θi is – if we did, we could simply choose i for which θi was largest and move on.</p>
<p>The goal of the bandit algorithm is to do the following. To begin with, it should display all possible titles to a random selection of users, and measure which titles are clicked on more frequently. Over time, it will use these observations to infer which articles have the higher CTR. Then, once the estimation of the CTR becomes more precise, it will preferentially display articles with the higher CTR.</p>
<h2 id="2-_The_Bayesian_Approach">2. The Bayesian Approach</h2><hr>
<p>In the model described above, we have N possible story titles, each of which has a click through rate θi. Unfortunately we do not know what θi is. As the astute reader can guess from the title, we are following a Bayesian approach, so we will construct a probability distribution which represents our belief about what the actual value of θi is.<br><img src="/images/bb/beliefs_about_theta.png" alt=""><br>In the figure above, we believe that θi is somewhere between 0.1 and 0.7, with values of 0.3-0.4 being considerably more likely than values of 0.1-0.2 or 0.6-0.7. For those who forgot STATS 101, the area under this curve between the points a and b is the probability thta θi lies between a and b. I.e.:<br><img src="/images/bb/11.png" alt=""><br>The basic idea behind Bayesian methods is to update our beliefs based on evidence. As we gather more data by showing different titles to other users and observing click throughs, we can incrementally narrow the width of the probability distribution.</p>
<p>As in all Bayesian inference, we need to choose a prior. The prior is something we believe to be true before we have any evidence – i.e., before we have shown the title to any visitors. This is just a starting point – after enough evidence is gathered, our prior will play a very minimal role in what we actually believe. Choosing a good prior is important both for mathematical simplicity, and because if your prior is accurate, you don’t need as much evidence to get the correct answer.</p>
<p>I’ll follow the approach I described in a previous blog post, and I’ll use a beta distribution as the prior:<br><img src="/images/bb/31.png" alt=""><br>The parameters αi,βi&gt;1 are the prior parameters. One reasonable choice is αi=βi=1, which amounts to the uniform distribution on [0,1]. What this means is that we are assuming that all possible values of θi are equally likely. Depending on the circumstances (which I’ll explain shortly), we might want to choose other possible values.</p>
<h2 id="3-_Updating_our_beliefs">3. Updating our beliefs</h2><p>Now we address the question of using evidence. After showing title i to ni visitors, we have observed that si of them have actually clicked on the title. We now want to compute theposterior distribution, which is to say the distribution that represents our beliefs after we have evidence.</p>
<p>I did a little bit of algebra previously, in which I showed that if the prior is fαi,βi(θi), then the posterior distribution is:<br><img src="/images/bb/21.png" alt=""><br>The key idea here is that to update our probability distribution describing θi, we need only update the parameters of our beta distribution.</p>
<p>So what does this mean in practice? As we run more experiments, our probability distribution on where θi lives becomes sharper:</p>
<p><img src="/images/bb/beta_distribution_evolution.png" alt=""><br>Before we run any experiments, θi could be anything (as represented by the blue line). Once we have run 700 experiments, yielding 175 click throughs, we are reasonably confident that θi lives roughly between 0.2 and 0.3.</p>
<p>What we’ve done so far is figured out how to estimate what our click through rates actually are based on empirical evidence. But that doesn’t actually give us a method of optimizing them yet.</p>
<h2 id="4-_Optimizing_click_throughs">4. Optimizing click throughs</h2><p>Now that we have a method of representing our beliefs about CTRs, it is useful to construct an algorithm to identify the best ones. There are many popular choices – I’ve written about the UCB Algorithm before, and I consider it a good choice.</p>
<p>But my new favorite method is a Monte Carlo method which I’ll describe now.</p>
<p>The ultimate goal of the bandit algorithm is to display to the user whichever title has the highest CTR. One method of estimating the CTRs of the articles is to sample the posterior distribution. I.e., suppose we have two possible titles, from which we have drawn n0=200,s0=64and n1=180,n2=40. Then one possible set of samples we might observe is this:</p>
<p><img src="/images/bb/beta_distribution_sampling1.png" alt=""></p>
<p>For title 0, our sample of θ0 has worked out to be 0.35, while our sample of θ1 is only 0.28. Since θ0=0.35&gt;θ1=0.28, we will display title 0 to the user.</p>
<p>However, there was no guarantee that things worked out this way. It was possible, although less likely, that θ1 could come out larger than θ0:<br><img src="/images/bb/beta_distribution_sampling2.png" alt=""><br>In this case, we would have displayed title 1 to the user rather than title 0.</p>
<p>The net result is that for overlapping probability distributions, we will display the title with the larger expected CTR the majority of the time. But occasionally, we will draw from the other distributions simply because it is within the realm of possibility that they are greater.</p>
<p>As we gather more data our probability distributions will become narrower and a clear winner will become apparent. When this occurs, we will almost surely choose the winner:<br><img src="/images/bb/beta_distribution_sampling3.png" alt=""><br>In python, the algorithm looks like this:</p>
<p>The results of this algorithm are exactly what any good bandit algorithm should do. I ran the following simulation, giving the beta bandit two titles – title 0 had a CTR of 0.25, title 1 had a CTR of 0.35. To start with, both titles were displayed to the user with roughly equal probability. Over time, evidence accumulated that title 1 was considerably better than title 0. At this point the algorithm switched to displaying primarily title 1, and the overall CTR of the experiment converged to 0.35 (the optimal CTR).</p>
<p><img src="/images/bb/beta_bandit_results.png" alt=""></p>
<p>Source code to generate this graph is available here. This method is called Thompson Sampling and is a a fairly popular method in Bayesian AI techniques. For the remainder of this post, I’ll call this method the Bayesian Bandit.</p>
<h2 id="5-Incorporating_common_sense">5.Incorporating common sense</h2><p>Anyone with common sense is now scoffing at the geekiness embodied in this post. Even before using statistics, it was fairly obvious that “Headless Body found in Topless Bar” was going to beat “Murder victim found in adult entertainment venue”. The former just sounds catchier and any good editor would run with it.</p>
<p>The wonderful thing about Bayesian methods is that we can modify them to take into account our prior knowledge. Suppose we believe editors intuition is a real thing – can we quantify it? Certainly. We can do this with a fairly simple experiment. We require editors to rate a collection of titles as “catchy” or “not catchy”, run them on the site, and then measure the CTR of the “catchy” and “not catchy” samples. Suppose we did such an experiment, and observed the following aggregate results:</p>
<p><img src="/images/bb/empirical_prior.png" alt=""></p>
<p>This isn’t a solid win for the editor – some catchy titles have low CTRs, and some boring titles have good CTRs. But nevertheless, it’s better for a story to have catchy title than not.</p>
<p>What we want to do is incorporate this information into our bandit algorithm. The beauty of a Bayesian method is that it gives you a clear and meaningful place to plug this information in, namely the prior. In contrast, for many other methods (e.g., UCB) it’s somewhat difficult to do this – there is no obvious parameter to tune as a result of our prior empirical data.</p>
<p>The first step is to fit a theoretical distribution to the empirical data. Due to the fact that I chose the “empirical” (i.e., made up) data to be very nice, a beta distribution fits well [1] – specifically beta distributions with (α0,β0)=(9,20) and (α1,β1)=(4,20).<br><img src="/images/bb/theoretical_prior.png" alt=""></p>
<p>Then the only modification needed to the algorithm is to plug these variables into the prior:<br><img src="/images/bb/41.png" alt=""><br>Everything else remains unchanged. In terms of modifications to source code, this is only a very small change to the previous code – an implementation can be found here.</p>
<h2 id="6-_Empirics_of_including_priors">6. Empirics of including priors</h2><p>To measure the benefits of incorporating priors into the Bayesian bandit, I ran some numerical experiments, the source code of which is available in this github gist. The methodology was the following.</p>
<p>To compare the Bayesian bandit with priors to that without, I drew a pair (θ0,θ1) from the prior distribution given above. For each pair, I then ran the Bayes Bandit with and without priors for this pair theta, for k trials. This is modelling the scenario that we have k page views on our homepage, and we can only leave a story on the homepage for 1 day.</p>
<p>I then repeated the experiment for 1000 different possible days, or equivalently for 1000 different pairs of (θ0,θ1). I then computed the average gain per page view over all trials and all days.</p>
<p>The result is the following. If we get 50 page views/day (i.e., the Bayes Bandit has very little data to use), the prior gives us a big gain. Without prior knowledge, the Bandit achieved a gain of 0.3749 on average, whereas the bandit with prior knowledge achieved a gain of 0.4274. If we run 150 experiments, the Bayes Bandit improves significantly – it achieves a gain of 0.40. If we run 300 experiments, the Bayes Bandit improves to 0.4146, while the bandit with priors improves to 0.4296. If we get 1000 page views/day, the Bayes Bandit improves to 0.4211, while the bandit with priors gains 0.4249.</p>
<p>The net result is the following – incorporating priors into the Bayes Bandit is an excellent way to improve your results when you don’t have a large number data points to use to train the bandit. If you have a lot of data points, you don’t need strong priors (but they still help a little).</p>
<h2 id="7-Conclusion">7.Conclusion</h2><p>Bandit algorithms are a great way of optimizing many factors of your website. There are many good options – I’ve written about UCB before and consider it a great choice. But if you have other information you want to include, consider using the Bayesian Bandit. It’s simple to implement, straightforward to use, and very importantly it’s also straightforward to extend.</p>
<p>It’s also important to note that the theoretical properties of the Bayesian Bandit (namely logarithmic regret) have been proven. So asymptotically, you lose nothing by using it. There are also attempts at constructing a Bayesian UCB algorithm – I don’t currently understand it well enough to comment.</p>
<p>I’ve written other articles related to this post. I have one post comparing bandit algorithms to a/b testing. I also I wrote about measuring a changing conversion rate, which provides an alternate algorithm for computing the posterior distribution if your conversion rate is not constant.</p>
<p>[1] If a single Beta distribution doesn’t fit, one can also use a convex combination of Beta distributions. The math works out just as nicely.</p>
<p>P.S. After I published this blog post, this related article was also pointed out to me, as was this online simulation of the Bayesian bandit.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Great news! A murder victim has been found. No slow news day today! The story is already written, now a title needs to be selected. The c]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hive UDF开发]]></title>
    <link href="http://www.notehub.cn/2015/09/03/dev/hive-udf-md/"/>
    <id>http://www.notehub.cn/2015/09/03/dev/hive-udf-md/</id>
    <published>2015-09-03T04:49:45.000Z</published>
    <updated>2015-09-03T04:53:26.000Z</updated>
    <content type="html"><![CDATA[<p>Hive进行UDAF开发，相对要比UDF复杂一些，不过也不是很难。请看一个例子:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.hrj.hive.udf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDAFEvaluator;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.io.DoubleWritable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UDAFSum_Sample</span> <span class="keyword">extends</span> <span class="title">NumericUDAF</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Evaluator</span> <span class="keyword">implements</span> <span class="title">UDAFEvaluator</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">boolean</span> mEmpty;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">double</span> mSum;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Evaluator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">super</span>();</span><br><span class="line">            init();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            mSum = <span class="number">0</span>;</span><br><span class="line">            mEmpty = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">iterate</span><span class="params">(DoubleWritable o)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</span><br><span class="line">                mSum += o.get();</span><br><span class="line">                mEmpty = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> DoubleWritable <span class="title">terminatePartial</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// This is SQL standard - sum of zero items should be null.</span></span><br><span class="line">            <span class="keyword">return</span> mEmpty ? <span class="keyword">null</span> : <span class="keyword">new</span> DoubleWritable(mSum);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">merge</span><span class="params">(DoubleWritable o)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</span><br><span class="line">                mSum += o.get();</span><br><span class="line">                mEmpty = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> DoubleWritable <span class="title">terminate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// This is SQL standard - sum of zero items should be null.</span></span><br><span class="line">            <span class="keyword">return</span> mEmpty ? <span class="keyword">null</span> : <span class="keyword">new</span> DoubleWritable(mSum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>1.将java文件编译成Sum_Sample.jar</p>
<p>2.进入hive<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">hive&gt; add jar Sum_sample.jar;</span><br><span class="line"></span><br><span class="line">hive&gt; create temporary <span class="keyword">function</span> sum_<span class="built_in">test</span> as <span class="string">'com.hrj.hive.udf.UDAFSum_Sample'</span>;</span><br><span class="line"></span><br><span class="line">hive&gt; select sum_<span class="built_in">test</span>(t.num) from t;</span><br><span class="line"></span><br><span class="line">hive&gt; drop temporary <span class="keyword">function</span> sum_<span class="built_in">test</span>;</span><br><span class="line"></span><br><span class="line">hive&gt; quit;</span><br></pre></td></tr></table></figure></p>
<p>关于UDAF开发注意点：</p>
<p>1.需要import org.apache.hadoop.hive.ql.exec.UDAF以及org.apache.hadoop.hive.ql.exec.UDAFEvaluator,这两个包都是必须的</p>
<p>2.函数类需要继承UDAF类，内部类Evaluator实现UDAFEvaluator接口</p>
<p>3.Evaluator需要实现 init、iterate、terminatePartial、merge、terminate这几个函数</p>
<pre><code><span class="number">1</span>）init函数类似于构造函数，用于UDAF的初始化

<span class="number">2</span>）iterate接收传入的参数，并进行内部的轮转。其返回类型为boolean

<span class="number">3</span>）terminatePartial无参数，其为iterate函数轮转结束后，返回乱转数据，iterate和terminatePartial类似于hadoop的Combiner

<span class="number">4</span>）merge接收terminatePartial的返回结果，进行数据merge操作，其返回类型为boolean

<span class="number">5</span>）terminate返回最终的聚集函数结果
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<p>Hive进行UDAF开发，相对要比UDF复杂一些，不过也不是很难。请看一个例子:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span>]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Flask microframework example]]></title>
    <link href="http://www.notehub.cn/2015/09/03/opensource/flask-example-md/"/>
    <id>http://www.notehub.cn/2015/09/03/opensource/flask-example-md/</id>
    <published>2015-09-03T03:25:14.000Z</published>
    <updated>2015-09-03T04:48:45.000Z</updated>
    <content type="html"><![CDATA[<p>NOTE: This article was revised in September 2014 to be in sync with current versions of Python and Flask.<br>If you followed the previous chapter you should have a fully working, yet very simple web application that has the following file structure:<br><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">microblog<span class="string">\</span></span><br><span class="line">  flask<span class="string">\</span></span><br><span class="line">    &lt;virtual environment files&gt;</span><br><span class="line">  app<span class="string">\</span></span><br><span class="line">    static<span class="string">\</span></span><br><span class="line">    templates<span class="string">\</span></span><br><span class="line">    __init__.py</span><br><span class="line">    views.py</span><br><span class="line">  tmp<span class="string">\</span></span><br><span class="line">  run.py</span><br></pre></td></tr></table></figure></p>
<p>To run the application you execute the run.py script and then open the<a href="http://localhost:5000" target="_blank" rel="external">http://localhost:5000</a> URL on your web browser.</p>
<p>We are picking up exactly from where we left off, so you may want to make sure you have the above application correctly installed and working.</p>
<h3 id="1-_Why_we_need_templates">1. Why we need templates</h3><p>Let’s consider how we can expand our little application.</p>
<p>We want the home page of our microblogging app to have a heading that welcomes the logged in user, that’s pretty standard for applications of this kind. Ignore for now the fact that we have no way to log a user in, I’ll present a workaround for this issue in a moment.</p>
<p>An easy option to output a nice and big heading would be to change our view function to output HTML, maybe something like this:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> app <span class="keyword">import</span> app</span><br><span class="line"></span><br><span class="line"><span class="decorator">@app.route('/')</span></span><br><span class="line"><span class="decorator">@app.route('/index')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    user = &#123;<span class="string">'nickname'</span>: <span class="string">'Miguel'</span>&#125;  <span class="comment"># fake user</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'''</span><br><span class="line">&lt;html&gt;</span><br><span class="line">  &lt;head&gt;</span><br><span class="line">    &lt;title&gt;Home Page&lt;/title&gt;</span><br><span class="line">  &lt;/head&gt;</span><br><span class="line">  &lt;body&gt;</span><br><span class="line">    &lt;h1&gt;Hello, '''</span> + user[<span class="string">'nickname'</span>] + <span class="string">'''&lt;/h1&gt;</span><br><span class="line">  &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">'''</span></span><br></pre></td></tr></table></figure></p>
<p>Give the application a try to see how this looks in your browser.</p>
<p>Since we don’t have support for users yet I have resorted to using a placeholder user object, sometimes called fake or mock object. This allows us to concentrate on certain aspects of our application that depend on parts of the system that haven’t been built yet.</p>
<p>I hope you agree with me that the solution used above to deliver HTML to the browser is very ugly. Consider how complex the code will become if you have to return a large and complex HTML page with lots of dynamic content. And what if you need to change the layout of your web site in a large app that has dozens of views, each returning HTML directly? This is clearly not a scalable option.</p>
<h3 id="2-_Templates_to_the_rescue">2. Templates to the rescue</h3><p>If you could keep the logic of your application separate from the layout or presentation of your web pages things would be much better organized, don’t you think? You could even hire a web designer to create a killer web site while you code the site’s behaviors in Python. Templates help implement this separation.</p>
<p>Let’s write our first template (file app/templates/index.html):<br><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>&#123;&#123; title &#125;&#125; - microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="title">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">body</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">h1</span>&gt;</span>Hello, &#123;&#123; user.nickname &#125;&#125;!<span class="tag">&lt;/<span class="title">h1</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="title">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>As you see above, we just wrote a mostly standard HTML page, with the only difference that there are some placeholders for the dynamic content enclosed in {{ ... }} sections.<br></p>
<p>Now let’s see how we use this template from our view function (file app/views.py):<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> render_template</span><br><span class="line"><span class="keyword">from</span> app <span class="keyword">import</span> app</span><br><span class="line"></span><br><span class="line"><span class="decorator">@app.route('/')</span></span><br><span class="line"><span class="decorator">@app.route('/index')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    user = &#123;<span class="string">'nickname'</span>: <span class="string">'Miguel'</span>&#125;  <span class="comment"># fake user</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">'index.html'</span>,</span><br><span class="line">                           title=<span class="string">'Home'</span>,</span><br><span class="line">                           user=user)</span><br></pre></td></tr></table></figure></p>
<p>Try the application at this point to see how the template works. Once you have the rendered page in your browser you may want to view the source HTML and compare it against the original template.</p>
<p>To render the template we had to import a new function from the Flask framework calledrender_template. This function takes a template filename and a variable list of template arguments and returns the rendered template, with all the arguments replaced.<br><br>Under the covers, the render_template function invokes the Jinja2 templating engine that is part of the Flask framework. Jinja2 substitutes {{...}} blocks with the corresponding values provided as template arguments.<br><br></p>
<h3 id="3-_Control_statements_in_templates">3. Control statements in templates</h3><p>The Jinja2 templates also support control statements, given inside {%...%} blocks. Let’s add an if statement to our template (file app/templates/index.html):<br><br><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">head</span>&gt;</span></span><br><span class="line">    &#123;% if title %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>&#123;&#123; title &#125;&#125; - microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">    &#123;% else %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>Welcome to microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="title">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">body</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">h1</span>&gt;</span>Hello, &#123;&#123; user.nickname &#125;&#125;!<span class="tag">&lt;/<span class="title">h1</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="title">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>Now our template is a bit smarter. If the view function forgets to define a page title then instead of showing an empty title the template will provide its own title. Feel free to remove the titleargument in the render_template call of our view function to see how the conditional statement works.</p>
<h3 id="4-_Loops_in_templates">4. Loops in templates</h3><p>The logged in user in our microblog application will probably want to see recent posts from followed users in the home page, so let’s see how we can do that.</p>
<p>To begin, we use our handy fake object trick to create some users and some posts to show (fileapp/views.py):<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">()</span>:</span></span><br><span class="line">    user = &#123;<span class="string">'nickname'</span>: <span class="string">'Miguel'</span>&#125;  <span class="comment"># fake user</span></span><br><span class="line">    posts = [  <span class="comment"># fake array of posts</span></span><br><span class="line">        &#123; </span><br><span class="line">            <span class="string">'author'</span>: &#123;<span class="string">'nickname'</span>: <span class="string">'John'</span>&#125;, </span><br><span class="line">            <span class="string">'body'</span>: <span class="string">'Beautiful day in Portland!'</span> </span><br><span class="line">        &#125;,</span><br><span class="line">        &#123; </span><br><span class="line">            <span class="string">'author'</span>: &#123;<span class="string">'nickname'</span>: <span class="string">'Susan'</span>&#125;, </span><br><span class="line">            <span class="string">'body'</span>: <span class="string">'The Avengers movie was so cool!'</span> </span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">"index.html"</span>,</span><br><span class="line">                           title=<span class="string">'Home'</span>,</span><br><span class="line">                           user=user,</span><br><span class="line">                           posts=posts)</span><br></pre></td></tr></table></figure></p>
<p>To represent user posts we are using a list, where each element has author and body fields. When we get to implement a real database we will preserve these field names, so we can design and test our template using the fake objects without having to worry about updating it when we move to a database.</p>
<p>On the template side we have to solve a new problem. The list can have any number of elements, it will be up to the view function to decide how many posts need to be presented. The template cannot make any assumptions about the number of posts, so it needs to be prepared to render as many posts as the view sends.</p>
<p>So let’s see how we do this using a for control structure (file app/templates/index.html):<br><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">head</span>&gt;</span></span><br><span class="line">    &#123;% if title %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>&#123;&#123; title &#125;&#125; - microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">    &#123;% else %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">title</span>&gt;</span>Welcome to microblog<span class="tag">&lt;/<span class="title">title</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="title">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">h1</span>&gt;</span>Hi, &#123;&#123; user.nickname &#125;&#125;!<span class="tag">&lt;/<span class="title">h1</span>&gt;</span></span><br><span class="line">    &#123;% for post in posts %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">div</span>&gt;</span><span class="tag">&lt;<span class="title">p</span>&gt;</span>&#123;&#123; post.author.nickname &#125;&#125; says: <span class="tag">&lt;<span class="title">b</span>&gt;</span>&#123;&#123; post.body &#125;&#125;<span class="tag">&lt;/<span class="title">b</span>&gt;</span><span class="tag">&lt;/<span class="title">p</span>&gt;</span><span class="tag">&lt;/<span class="title">div</span>&gt;</span></span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="title">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>Simple, right? Give it a try, and be sure to play with adding more content to the posts array.</p>
<h3 id="5-_Template_inheritance">5. Template inheritance</h3><p>We have one more topic to cover before we close for the day. Our microblog web application will need to have a navigation bar at the top of the page with a few links. Here you will get the link to edit your profile, to login, logout, etc.</p>
<p>We can add a navigation bar to our index.html template, but as our application grows we will be needing to implement more pages, and this navigation bar will have to be copied to all of them. Then you will have to keep all these identical copies of the navigation bar in sync, and that could become a lot of work if you have a lot of pages and templates.</p>
<p>Instead, we can use Jinja2’s template inheritance feature, which allows us to move the parts of the page layout that are common to all templates and put them in a base template from which all other templates are derived.</p>
<p>So let’s define a base template that includes the navigation bar and also the bit of title logic we implemented earlier (file app/templates/base.html):<br><br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">  &lt;head&gt;</span><br><span class="line">    &#123;% if title %&#125;</span><br><span class="line">    &lt;title&gt;&#123;&#123; title &#125;&#125; - microblog&lt;/title&gt;</span><br><span class="line">    &#123;% else %&#125;</span><br><span class="line">    &lt;title&gt;Welcome to microblog&lt;/title&gt;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">  &lt;/head&gt;</span><br><span class="line">  &lt;body&gt;</span><br><span class="line">    &lt;div&gt;Microblog: &lt;a href="/index"&gt;Home&lt;/a&gt;&lt;/div&gt;</span><br><span class="line">    &lt;hr&gt;</span><br><span class="line">    &#123;% block content %&#125;&#123;% endblock %&#125;</span><br><span class="line">  &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<p>In this template we use the block control statement to define the place where the derived templates can insert themselves. Blocks are given a unique name, and their content can be replaced or enhanced in derived templates.</p>
<p>And now what’s left is to modify our index.html template to inherit from base.html (fileapp/templates/index.html):<br><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;% extends "base.html" %&#125;</span><br><span class="line">&#123;% block content %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">h1</span>&gt;</span>Hi, &#123;&#123; user.nickname &#125;&#125;!<span class="tag">&lt;/<span class="title">h1</span>&gt;</span></span><br><span class="line">    &#123;% for post in posts %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="title">div</span>&gt;</span><span class="tag">&lt;<span class="title">p</span>&gt;</span>&#123;&#123; post.author.nickname &#125;&#125; says: <span class="tag">&lt;<span class="title">b</span>&gt;</span>&#123;&#123; post.body &#125;&#125;<span class="tag">&lt;/<span class="title">b</span>&gt;</span><span class="tag">&lt;/<span class="title">p</span>&gt;</span><span class="tag">&lt;/<span class="title">div</span>&gt;</span></span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">&#123;% endblock %&#125;</span><br></pre></td></tr></table></figure></p>
<p>Since the base.html template will now take care of the general page structure we have removed those elements from this one and left only the content part. The extends block establishes the inheritance link between the two templates, so that Jinja2 knows that when it needs to renderindex.html it needs to include it inside base.html. The two templates have matching blockstatements with name content, and this is how Jinja2 knows how to combine the two into one. When we get to write new templates we will also create them as extensions to base.html.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>NOTE: This article was revised in September 2014 to be in sync with current versions of Python and Flask.<br>If you followed the previous]]>
    </summary>
    
      <category term="falsk, restful" scheme="http://www.notehub.cn/tags/falsk-restful/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Input mono字体]]></title>
    <link href="http://www.notehub.cn/2015/09/03/opensource/input-font-md/"/>
    <id>http://www.notehub.cn/2015/09/03/opensource/input-font-md/</id>
    <published>2015-09-03T03:20:50.000Z</published>
    <updated>2015-09-03T03:23:31.000Z</updated>
    <content type="html"><![CDATA[<p>Input Mono字体作为编程字体挺好看的, 该字体对个人非商业用户是免费的, 并且支持自定义.</p>
<p>地址: <a href="http://input.fontbureau.com" target="_blank" rel="external">http://input.fontbureau.com</a></p>
<p><img src="/images/input_mono.png" alt=""></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Input Mono字体作为编程字体挺好看的, 该字体对个人非商业用户是免费的, 并且支持自定义.</p>
<p>地址: <a href="http://input.fontbureau.com" target="_blank" rel="external">http://]]>
    </summary>
    
      <category term="font" scheme="http://www.notehub.cn/tags/font/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[机器学习中的数据清洗与特征处理综述]]></title>
    <link href="http://www.notehub.cn/2015/06/06/algo/feature_d/"/>
    <id>http://www.notehub.cn/2015/06/06/algo/feature_d/</id>
    <published>2015-06-05T16:00:00.000Z</published>
    <updated>2015-09-23T14:43:26.000Z</updated>
    <content type="html"><![CDATA[<h2 id="特征分类">特征分类</h2><hr>
<p>　　在分析完特征和标注的清洗方法之后，下面来具体介绍下特征的处理方法，先对特征进行分类，对于不同的特征应该有不同的处理方法。根据不同的分类方法，可以将特征分为</p>
<ul>
<li>Low level特征和High level特征。</li>
<li>稳定特征与动态特征。</li>
<li>二值特征、连续特征、枚举特征。</li>
</ul>
<p>　　Low level特征是较低级别的特征，主要是原始特征，不需要或者需要非常少的人工处理和干预，例如文本特征中的词向量特征，图像特征中的像素点，用户id，商品id等。Low level特征一般维度比较高，不能用过于复杂的模型。High level特征是经过较复杂的处理，结合部分业务逻辑或者规则、模型得到的特征，例如人工打分，模型打分等特征，可以用于较复杂的非线性模型。Low level 比较针对性，覆盖面小。长尾样本的预测值主要受high level特征影响。高频样本的预测值主要受low level特征影响。</p>
<p>　　稳定特征是变化频率(更新频率)较少的特征，例如评价平均分，团购单价格等，在较长的时间段内都不会发生变化。动态特征是更新变化比较频繁的特征，有些甚至是实时计算得到的特征，例如距离特征，2小时销量等特征。或者叫做实时特征和非实时特征。针对两类特征的不同可以针对性地设计特征存储和更新方式，例如对于稳定特征，可以建入索引，较长时间更新一次，如果做缓存的话，缓存的时间可以较长。对于动态特征，需要实时计算或者准实时地更新数据，如果做缓存的话，缓存过期时间需要设置的较短。</p>
<p>　　二值特征主要是0/1特征，即特征只取两种值：0或者1，例如用户id特征：目前的id是否是某个特定的id，词向量特征：某个特定的词是否在文章中出现等等。连续值特征是取值为有理数的特征，特征取值个数不定，例如距离特征，特征取值为是0~正无穷。枚举值特征主要是特征有固定个数个可能值，例如今天周几，只有7个可能值：周1，周2，…，周日。在实际的使用中，我们可能对不同类型的特征进行转换，例如将枚举特征或者连续特征处理为二值特征。枚举特征处理为二值特征技巧：将枚举特征映射为多个特征，每个特征对应一个特定枚举值，例如今天周几，可以把它转换成7个二元特征：今天是否是周一，今天是否是周二，…，今天是否是周日。连续值处理为二值特征方法：先将连续值离散化（后面会介绍如何离散化), 再将离散化后的特征切分为N个二元特征，每个特征代表是否在这个区间内。</p>
<h2 id="特征处理与分析">特征处理与分析</h2><hr>
<p>　　在对特征进行分类后，下面介绍下对特征常用的处理方法。包括1.特征归一化，离散化，缺省值处理。2.特征降维方法。3.特征选择方法等。</p>
<h3 id="归一化">归一化</h3><p>　　不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括：</p>
<ol>
<li>函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。</li>
<li>分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。</li>
<li>排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。</li>
</ol>
<h3 id="离散化">离散化</h3><p>　　在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，…，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。</p>
<h3 id="缺省值处理">缺省值处理</h3><p>　　有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等。<br>特征降维</p>
<p>　　在介绍特征降维之前，先介绍下特征升维。在机器学习中，有一个VC维理论。根据VC维理论，VC维越高，打散能力越强，可容许的模型复杂度越高。在低维不可分的数据，映射到高维是可分。可以想想，给你一堆物品，人脑是如何对这些物品进行分类，依然是找出这些物品的一些特征，例如：颜色，形状，大小，触感等等，然后根据这些特征对物品做以归类，这其实就是一个先升维，后划分的过程。比如我们人脑识别香蕉。可能首先我们发现香蕉是黄色的。这是在颜色这个维度的一个切分。但是很多东西都是黄色的啊，例如哈密瓜。那么怎么区分香蕉和哈密瓜呢？我们发现香蕉形状是弯曲的。而哈密瓜是圆形的，那么我们就可以用形状来把香蕉和哈密瓜划分开了，即引入一个新维度：形状，来区分。这就是一个从“颜色”一维特征升维到二维特征的例子。</p>
<p>　　那问题来了，既然升维后模型能力能变强，那么是不是特征维度越高越好呢？为什么要进行特征降维&amp;特征选择？主要是出于如下考虑：</p>
<ol>
<li>特征维数越高，模型越容易过拟合，此时更复杂的模型就不好用。</li>
<li>相互独立的特征维数越高，在模型不变的情况下，在测试集上达到相同的效果表现所需要的训练样本的数目就越大。 </li>
<li>特征数量增加带来的训练、测试以及存储的开销都会增大。</li>
<li>在某些模型中，例如基于距离计算的模型KMeans，KNN等模型，在进行距离计算时，维度过高会影响精度和性能。</li>
<li>可视化分析的需要。在低维的情况下，例如二维，三维，我们可以把数据绘制出来，可视化地看到数据。当维度增高时，就难以绘制出来了。在机器学习中，有一个非常经典的维度灾难的概念。用来描述当空间维度增加时，分析和组织高维空间，因体积指数增加而遇到各种问题场景。例如，100个平均分布的点能把一个单位区间以每个点距离不超过0.01采样；而当维度增加到10后，如果以相邻点距离不超过0.01小方格采样单位超一单位超正方体，则需要10^20 个采样点。</li>
</ol>
<p>　　正是由于高维特征有如上描述的各种各样的问题，所以我们需要进行特征降维和特征选择等工作。特征降维常用的算法有PCA，LDA等。特征降维的目标是将高维空间中的数据集映射到低维空间数据，同时尽可能少地丢失信息，或者降维后的数据点尽可能地容易被区分</p>
<h4 id="PCA算法">PCA算法</h4><p>　　通过协方差矩阵的特征值分解能够得到数据的主成分，以二维特征为例，两个特征之间可能存在线性关系（例如运动的时速和秒速度），这样就造成了第二维信息是冗余的。PCA的目标是发现这种特征之间的线性关系，并去除。</p>
<h4 id="LDA算法">LDA算法</h4><p>考虑label，降维后的数据点尽可能地容易被区分</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="特征分类">特征分类</h2><hr>
<p>　　在分析完特征和标注的清洗方法之后，下面来具体介绍下特征的处理方法，先对特征进行分类，对于不同的特征应该有不同的处理方法。根据不同的分类方法，可以将特征分为</p>
<ul>
<li>Low level特征和High]]>
    </summary>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[PPTP VPN搭建]]></title>
    <link href="http://www.notehub.cn/2015/05/14/system/pptp_vpn/"/>
    <id>http://www.notehub.cn/2015/05/14/system/pptp_vpn/</id>
    <published>2015-05-13T16:00:00.000Z</published>
    <updated>2015-09-23T03:53:22.000Z</updated>
    <content type="html"><![CDATA[<p>本文介绍在Linux下搭建VPN的过程<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/sh</span></span><br><span class="line"><span class="keyword">if</span> [ `id -u` <span class="operator">-ne</span> <span class="number">0</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"please run it by root"</span></span><br><span class="line">  <span class="built_in">exit</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">apt-get -y update</span><br><span class="line"></span><br><span class="line">apt-get -y install pptpd || &#123;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"could not install pptpd"</span> </span><br><span class="line">  <span class="built_in">exit</span> <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cat &gt;/etc/ppp/options.pptpd &lt;&lt;END</span><br><span class="line">name pptpd</span><br><span class="line">refuse-pap</span><br><span class="line">refuse-chap</span><br><span class="line">refuse-mschap</span><br><span class="line">require-mschap-v2</span><br><span class="line">require-mppe-<span class="number">128</span></span><br><span class="line">ms-dns <span class="number">8.8</span>.<span class="number">8.8</span></span><br><span class="line">ms-dns <span class="number">8.8</span>.<span class="number">4.4</span></span><br><span class="line">proxyarp</span><br><span class="line">lock</span><br><span class="line">nobsdcomp </span><br><span class="line">novj</span><br><span class="line">novjccomp</span><br><span class="line">nologfd</span><br><span class="line">END</span><br><span class="line"></span><br><span class="line">cat &gt;/etc/pptpd.conf &lt;&lt;END</span><br><span class="line">option /etc/ppp/options.pptpd</span><br><span class="line">logwtmp</span><br><span class="line">localip <span class="number">192.168</span>.<span class="number">2.1</span></span><br><span class="line">remoteip <span class="number">192.168</span>.<span class="number">2.10</span>-<span class="number">100</span></span><br><span class="line">END</span><br><span class="line"></span><br><span class="line">cat &gt;&gt; /etc/sysctl.conf &lt;&lt;END</span><br><span class="line">net.ipv4.ip_forward=<span class="number">1</span></span><br><span class="line">END</span><br><span class="line"></span><br><span class="line">sysctl -p</span><br><span class="line"></span><br><span class="line">iptables-save &gt; /etc/iptables.down.rules</span><br><span class="line"></span><br><span class="line">iptables -t nat -A POSTROUTING <span class="operator">-s</span> <span class="number">192.168</span>.<span class="number">2.0</span>/<span class="number">24</span> -o eth0 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">iptables -I FORWARD <span class="operator">-s</span> <span class="number">192.168</span>.<span class="number">2.0</span>/<span class="number">24</span> -p tcp --syn -i ppp+ -j TCPMSS --set-mss <span class="number">1300</span></span><br><span class="line"></span><br><span class="line">iptables-save &gt; /etc/iptables.up.rules</span><br><span class="line"></span><br><span class="line">cat &gt;&gt;/etc/ppp/pptpd-options&lt;&lt;EOF</span><br><span class="line">pre-up iptables-restore &lt; /etc/iptables.up.rules</span><br><span class="line">post-down iptables-restore &lt; /etc/iptables.down.rules</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt;/etc/ppp/chap-secrets &lt;&lt;END</span><br><span class="line"><span class="built_in">test</span> pptpd <span class="built_in">test</span> *</span><br><span class="line">END</span><br><span class="line"></span><br><span class="line">service pptpd restart</span><br><span class="line"></span><br><span class="line">netstat -lntp</span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>实际使用中需要按照需要修改本地IP地址即可，一般情况自动安装和配置是成功的，但是在我的实际使用中使用手机网络连接的时候是没问题的，但是使用电脑连接的时候还是出现无法连接的情况，查看日志如下：</p>
<p>Starting negotiation on /dev/pts/1<br>sent [LCP ConfReq id=0x1 <asyncmap 0x0=""> <auth chap="" ms-v2=""> <magic 0xc93c30c6=""> <pcomp> <accomp> <mrru 1500=""> <endpoint [mac:00:16:3e:d8:d7:39]="">]<br>sent [LCP ConfReq id=0x1 <asyncmap 0x0=""> <auth chap="" ms-v2=""> <magic 0xc93c30c6=""> <pcomp> <accomp> <mrru 1500=""><br>…<br>LCP: timeout sending Config-Requests<br>Connection terminated.<br>这个可能是学校路由器没有采用PPTP穿透吧</mrru></accomp></pcomp></magic></auth></asyncmap></endpoint></mrru></accomp></pcomp></magic></auth></asyncmap></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>本文介绍在Linux下搭建VPN的过程<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line]]>
    </summary>
    
      <category term="PPTP, vpn" scheme="http://www.notehub.cn/tags/PPTP-vpn/"/>
    
      <category term="system" scheme="http://www.notehub.cn/categories/system/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Shadowsocks 安装配置使用]]></title>
    <link href="http://www.notehub.cn/2015/05/14/system/shadowsocks/"/>
    <id>http://www.notehub.cn/2015/05/14/system/shadowsocks/</id>
    <published>2015-05-13T16:00:00.000Z</published>
    <updated>2015-09-23T03:50:47.000Z</updated>
    <content type="html"><![CDATA[<p>Debian/Ubuntu安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get install python-pip</span><br><span class="line">pip install shadowsocks</span><br></pre></td></tr></table></figure></p>
<p>配置:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"server"</span>:<span class="string">"my_server_ip"</span>,</span><br><span class="line">    <span class="string">"server_port"</span>:<span class="number">8388</span>,</span><br><span class="line">    <span class="string">"local_address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="string">"local_port"</span>:<span class="number">1080</span>,</span><br><span class="line">    <span class="string">"password"</span>:<span class="string">"mypassword"</span>,</span><br><span class="line">    <span class="string">"timeout"</span>:<span class="number">300</span>,</span><br><span class="line">    <span class="string">"method"</span>:<span class="string">"aes-256-cfb"</span>,</span><br><span class="line">    <span class="string">"fast_open"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"workers"</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>服务器端运行:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssserver -c /etc/shadowsocks/config.json</span><br></pre></td></tr></table></figure></p>
<p>后台运行:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ssserver -c /etc/shadowsocks/config.json &gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>
<p>客户端运行:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sslocal -c /etc/shadowsocks/config.json</span><br></pre></td></tr></table></figure></p>
<p>后台运行:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup sslocal -c /etc/shadowsocks/config.json &gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>
<p>浏览器配置，推荐使用SwithySharp插件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">protocol: socks5</span><br><span class="line">hostname: <span class="number">127.0</span>.<span class="number">0.1</span></span><br><span class="line">port:     your <span class="built_in">local</span>_port</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Debian/Ubuntu安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2<]]>
    </summary>
    
      <category term="Shadowsocks" scheme="http://www.notehub.cn/tags/Shadowsocks/"/>
    
      <category term="system" scheme="http://www.notehub.cn/categories/system/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[HashMap的两种排序方式]]></title>
    <link href="http://www.notehub.cn/2015/05/03/dev/hash-map-sort-md/"/>
    <id>http://www.notehub.cn/2015/05/03/dev/hash-map-sort-md/</id>
    <published>2015-05-03T04:57:56.000Z</published>
    <updated>2015-09-03T05:04:15.000Z</updated>
    <content type="html"><![CDATA[<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line">map.put(“d”, <span class="number">2</span>);</span><br><span class="line">map.put(“c”, <span class="number">1</span>);</span><br><span class="line">map.put(“b”, <span class="number">1</span>);</span><br><span class="line">map.put(“a”, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">List&lt;Map.Entry&lt;String, Integer&gt;&gt; infoIds =</span><br><span class="line"><span class="keyword">new</span> ArrayList&lt;Map.Entry&lt;String, Integer&gt;&gt;(map.entrySet());</span><br><span class="line"></span><br><span class="line"><span class="comment">//排序前</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; infoIds.size(); i++) &#123;</span><br><span class="line">String id = infoIds.get(i).toString();</span><br><span class="line">System.out.println(id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//d 2</span></span><br><span class="line"><span class="comment">//c 1</span></span><br><span class="line"><span class="comment">//b 1</span></span><br><span class="line"><span class="comment">//a 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//排序</span></span><br><span class="line">Collections.sort(infoIds, <span class="keyword">new</span> Comparator&lt;Map.Entry&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Map.Entry&lt;String, Integer&gt; o1, Map.Entry&lt;String, Integer&gt; o2)</span> </span>&#123;</span><br><span class="line"><span class="comment">//return (o2.getValue() – o1.getValue());</span></span><br><span class="line"><span class="keyword">return</span> (o1.getKey()).toString().compareTo(o2.getKey());</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//排序后</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; infoIds.size(); i++) &#123;</span><br><span class="line">String id = infoIds.get(i).toString();</span><br><span class="line">System.out.println(id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//根据key排序</span></span><br><span class="line"><span class="comment">//a 3</span></span><br><span class="line"><span class="comment">//b 1</span></span><br><span class="line"><span class="comment">//c 1</span></span><br><span class="line"><span class="comment">//d 2</span></span><br><span class="line"><span class="comment">//根据value排序</span></span><br><span class="line"><span class="comment">//a 3</span></span><br><span class="line"><span class="comment">//d 2</span></span><br><span class="line"><span class="comment">//b 1</span></span><br><span class="line"><span class="comment">//c 1</span></span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class=]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[贝叶斯理论]]></title>
    <link href="http://www.notehub.cn/2015/04/03/algo/baysian/"/>
    <id>http://www.notehub.cn/2015/04/03/algo/baysian/</id>
    <published>2015-04-02T16:00:00.000Z</published>
    <updated>2015-09-23T14:29:27.000Z</updated>
    <content type="html"><![CDATA[<h2 id="贝叶斯法则">贝叶斯法则</h2><hr>
<p>机器学习的任务：在给定训练数据D时，确定假设空间H中的最佳假设。</p>
<p>最佳假设：一种方法是把它定义为在给定数据D以及H中不同假设的先验概率的有关知识下的最可能假设。贝叶斯理论提供了一种计算假设概率的方法，基于假设的先验概率、给定假设下观察到不同数据的概率以及观察到的数据本身。</p>
<h2 id="先验概率和后验概率">先验概率和后验概率</h2><hr>
<p>用P(h)表示在没有训练数据前假设h拥有的初始概率。P(h)被称为h的先验概率。先验概率反映了关于h是一正确假设的机会的背景知识如果没有这一先验知识，可以简单地将每一候选假设赋予相同的先验概率。类似地，P(D)表示训练数据D的先验概率，P(D|h)表示假设h成立时D的概率。机器学习中，我们关心的是P(h|D)，即给定D时h的成立的概率，称为h的后验概率。</p>
<h2 id="贝叶斯公式">贝叶斯公式</h2><hr>
<p>贝叶斯公式提供了从先验概率P(h)、P(D)和P(D|h)计算后验概率P(h|D)的方法</p>
<p>p(h|D)=P(D|H)*P(H)/P(D)</p>
<p>P(h|D)随着P(h)和P(D|h)的增长而增长，随着P(D)的增长而减少，即如果D独立于h时被观察到的可能性越大，那么D对h的支持度越小。</p>
<h2 id="极大后验假设">极大后验假设</h2><hr>
<p>学习器在候选假设集合H中寻找给定数据D时可能性最大的假设h，h被称为极大后验假设（MAP）确定MAP的方法是用贝叶斯公式计算每个候选假设的后验概率，计算式如下:</p>
<p>h_map=argmax P(h|D)=argmax (P(D|h)<em>P(h))/P(D)=argmax P(D|h)</em>p(h) (h属于集合H)</p>
<p>最后一步，去掉了P(D)，因为它是不依赖于h的常量。</p>
<h2 id="极大似然假设">极大似然假设</h2><hr>
<p>在某些情况下，可假定H中每个假设有相同的先验概率，这样式子可以进一步简化，只需考虑P(D|h)来寻找极大可能假设。</p>
<p>h_ml = argmax p(D|h)  h属于集合H</p>
<p>P(D|h)常被称为给定h时数据D的似然度，而使P(D|h)最大的假设被称为极大似然假设。</p>
<h2 id="举例">举例</h2><hr>
<p>考虑一个医疗诊断问题，有两种可能的假设：（1）病人有癌症。（2）病人无癌症。样本数据来自某化验测试，它也有两种可能的结果：阳性和阴性。假设我们已经有先验知识：在所有人口中只有0.008的人患病。此外，化验测试对有病的患者有98%的可能返回阳性结果，对无病患者有97%的可能返回阴性结果。</p>
<p>上面的数据可以用以下概率式子表示：</p>
<p>P(cancer)=0.008,P(无cancer)=0.992</p>
<p>P(阳性|cancer)=0.98,P(阴性|cancer)=0.02</p>
<p>P(阳性|无cancer)=0.03，P(阴性|无cancer)=0.97</p>
<p>假设现在有一个新病人，化验测试返回阳性，是否将病人断定为有癌症呢？我们可以来计算极大后验假设：</p>
<p>P(阳性|cancer)p(cancer)=0.98*0.008 = 0.0078</p>
<p>P(阳性|无cancer)<em>p(无cancer)=0.03</em>0.992 = 0.0298</p>
<p>因此，应该判断为无癌症。</p>
<p>贝叶斯推理的结果很大程度上依赖于先验概率，另外不是完全接受或拒绝假设，只是在观察到较多的数据后增大或减小了假设的可能性。</p>
<h2 id="贝叶斯分类具有如下特点：">贝叶斯分类具有如下特点：</h2><hr>
<ol>
<li><p>贝叶斯分类并不把一个对象绝对地指派给某一类，而是通过计算得出属于某一类的概率，具有最大概率的类便是该对象所属的类；</p>
</li>
<li><p>一般情况下在贝叶斯分类中所有的属性都潜在地起作用，即并不是一个或几个属性决定分类，而是所有的属性都参与分类；</p>
</li>
<li><p>贝叶斯分类对象的属性可以是离散的、连续的，也可以是混合的。</p>
</li>
</ol>
<p>贝叶斯定理给出了最小化误差的最优解决方法，可用于分类和预测。理论上，它看起来很完美，但在实际中，它并不能直接利用，它需要知道证据的确切分布概率，而实际上我们并不能确切的给出证据的分布概率。因此我们在很多分类方法中都会作出某种假设以逼近贝叶斯定理的要求。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="贝叶斯法则">贝叶斯法则</h2><hr>
<p>机器学习的任务：在给定训练数据D时，确定假设空间H中的最佳假设。</p>
<p>最佳假设：一种方法是把它定义为在给定数据D以及H中不同假设的先验概率的有关知识下的最可能假设。贝叶斯理论提供了一种计算假设概率的方法，]]>
    </summary>
    
      <category term="贝叶斯" scheme="http://www.notehub.cn/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[MapReduce 计数器简介]]></title>
    <link href="http://www.notehub.cn/2015/03/03/algo/mapreduce/mapreduce_counters/"/>
    <id>http://www.notehub.cn/2015/03/03/algo/mapreduce/mapreduce_counters/</id>
    <published>2015-03-02T16:00:00.000Z</published>
    <updated>2015-09-23T14:24:56.000Z</updated>
    <content type="html"><![CDATA[<h2 id="1、计数器_简介">1、计数器 简介</h2><hr>
<p>在许多情况下，一个用户需要了解待分析的数据，尽管这并非所要执行的分析任务 的核心内容。以统计数据集中无效记录数目的任务为例，如果发现无效记录的比例 相当高，那么就需要认真思考为何存在如此多无效记录。是所采用的检测程序存在 缺陷，还是数据集质量确实很低，包含大量无效记录？如果确定是数据集的质量问 题，则可能需要扩大数据集的规模，以增大有效记录的比例，从而进行有意义的分析。</p>
<p>计数器是一种收集作业统计信息的有效手段，用于质量控制或应用级统计。计数器 还可辅助诊断系统故障。如果需要将日志信息传输到map或reduce任务，更好的 方法通常是尝试传输计数器值以监测某一特定事件是否发生。对于大型分布式作业 而言，使用计数器更为方便。首先，获取计数器值比输出日志更方便，其次，根据 计数器值统计特定事件的发生次数要比分析一堆日志文件容易得多。</p>
<h2 id="2_、内置计数器">2 、内置计数器</h2><hr>
<p>Hadoop为每个作业维护若干内置计数器, 以描述该作业的各项指标。例如，某些计数器记录已处理的字节数和记录数，使用户可监控已处理的输入数据量和已产生的输出数据量，并以此对 job 做适当的优化。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">14/06/08 15:13:35 INFO mapreduce.Job: Counters: 46</span><br><span class="line">  File System Counters</span><br><span class="line">  FILE: Number of bytes read=159</span><br><span class="line">  FILE: Number of bytes written=159447</span><br><span class="line">  FILE: Number of read operations=<span class="operator">0</span><br><span class="line">  <span class="keyword">FILE</span>: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">large</span> <span class="keyword">read</span> <span class="keyword">operations</span>=<span class="number">0</span></span><br><span class="line">  <span class="keyword">FILE</span>: <span class="built_in">Number</span> <span class="keyword">of</span> write <span class="keyword">operations</span>=<span class="number">0</span></span><br><span class="line">  HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">bytes</span> <span class="keyword">read</span>=<span class="number">198</span></span><br><span class="line">  HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">bytes</span> written=<span class="number">35</span></span><br><span class="line">  HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">read</span> <span class="keyword">operations</span>=<span class="number">6</span></span><br><span class="line">  HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">large</span> <span class="keyword">read</span> <span class="keyword">operations</span>=<span class="number">0</span></span><br><span class="line">  HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> write <span class="keyword">operations</span>=<span class="number">2</span></span><br><span class="line">  Job Counters </span><br><span class="line">  Launched <span class="keyword">map</span> tasks=<span class="number">1</span></span><br><span class="line">  Launched reduce tasks=<span class="number">1</span></span><br><span class="line">  Rack-<span class="keyword">local</span> <span class="keyword">map</span> tasks=<span class="number">1</span></span><br><span class="line">  Total <span class="keyword">time</span> spent <span class="keyword">by</span> all maps <span class="keyword">in</span> occupied slots (ms)=<span class="number">3896</span></span><br><span class="line">  Total <span class="keyword">time</span> spent <span class="keyword">by</span> all reduces <span class="keyword">in</span> occupied slots (ms)=<span class="number">9006</span></span><br><span class="line">  <span class="keyword">Map</span>-Reduce Framework</span><br><span class="line">  <span class="keyword">Map</span> <span class="keyword">input</span> <span class="keyword">records</span>=<span class="number">3</span></span><br><span class="line">  <span class="keyword">Map</span> <span class="keyword">output</span> <span class="keyword">records</span>=<span class="number">12</span></span><br><span class="line">  <span class="keyword">Map</span> <span class="keyword">output</span> <span class="keyword">bytes</span>=<span class="number">129</span></span><br><span class="line">  <span class="keyword">Map</span> <span class="keyword">output</span> <span class="keyword">materialized</span> <span class="keyword">bytes</span>=<span class="number">159</span></span><br><span class="line">  <span class="keyword">Input</span> <span class="keyword">split</span> <span class="keyword">bytes</span>=<span class="number">117</span></span><br><span class="line">  Combine <span class="keyword">input</span> <span class="keyword">records</span>=<span class="number">0</span></span><br><span class="line">  Combine <span class="keyword">output</span> <span class="keyword">records</span>=<span class="number">0</span></span><br><span class="line">  Reduce <span class="keyword">input</span> <span class="keyword">groups</span>=<span class="number">4</span></span><br><span class="line">  Reduce shuffle <span class="keyword">bytes</span>=<span class="number">159</span></span><br><span class="line">  Reduce <span class="keyword">input</span> <span class="keyword">records</span>=<span class="number">12</span></span><br><span class="line">  Reduce <span class="keyword">output</span> <span class="keyword">records</span>=<span class="number">4</span></span><br><span class="line">  Spilled <span class="keyword">Records</span>=<span class="number">24</span></span><br><span class="line">  Shuffled Maps =<span class="number">1</span></span><br><span class="line">  <span class="keyword">Failed</span> Shuffles=<span class="number">0</span></span><br><span class="line">  Merged <span class="keyword">Map</span> outputs=<span class="number">1</span></span><br><span class="line">  GC <span class="keyword">time</span> elapsed (ms)=<span class="number">13</span></span><br><span class="line">  CPU <span class="keyword">time</span> spent (ms)=<span class="number">3830</span></span><br><span class="line">  <span class="keyword">Physical</span> <span class="keyword">memory</span> (<span class="keyword">bytes</span>) <span class="keyword">snapshot</span>=<span class="number">537718784</span></span><br><span class="line">  <span class="keyword">Virtual</span> <span class="keyword">memory</span> (<span class="keyword">bytes</span>) <span class="keyword">snapshot</span>=<span class="number">7365263360</span></span><br><span class="line">  Total committed <span class="keyword">heap</span> <span class="keyword">usage</span> (<span class="keyword">bytes</span>)=<span class="number">2022309888</span></span><br><span class="line">  Shuffle <span class="keyword">Errors</span></span><br><span class="line">  BAD_ID=<span class="number">0</span></span><br><span class="line">  <span class="keyword">CONNECTION</span>=<span class="number">0</span></span><br><span class="line">  IO_ERROR=<span class="number">0</span></span><br><span class="line">  WRONG_LENGTH=<span class="number">0</span></span><br><span class="line">  WRONG_MAP=<span class="number">0</span></span><br><span class="line">  WRONG_REDUCE=<span class="number">0</span></span><br><span class="line">  <span class="keyword">File</span> <span class="keyword">Input</span> <span class="keyword">Format</span> Counters </span><br><span class="line">  <span class="keyword">Bytes</span> <span class="keyword">Read</span>=<span class="number">81</span></span><br><span class="line">  <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Format</span> Counters </span><br><span class="line">  <span class="keyword">Bytes</span> Written=<span class="number">35</span></span></span><br></pre></td></tr></table></figure></p>
<p>计数器由其关联任务维护，并定期传到tasktracker，再由tasktracker传给 jobtracker.因此，计数器能够被全局地聚集。详见第 hadoop 权威指南第170页的“进度和状态的更新”小节。与其他计数器（包括用户定义的计数器）不同，内置的作业计数器实际上 由jobtracker维护，不必在整个网络中发送。<br>一个任务的计数器值每次都是完整传输的，而非自上次传输之后再继续数未完成的传输，以避免由于消息丢失而引发的错误。另外，如果一个任务在作业执行期间失 败，则相关计数器值会减小。仅当一个作业执行成功之后，计数器的值才是完整可 靠的。</p>
<h2 id="3、用户定义的Java计数器">3、用户定义的Java计数器</h2><p>MapReduce允许用户编写程序来定义计数器，计数器的值可在mapper或reducer 中增加。多个计数器由一个Java枚举(enum)类型来定义，以便对计数器分组。一 个作业可以定义的枚举类型数量不限，各个枚举类型所包含的字段数量也不限。枚 举类型的名称即为组的名称，枚举类型的字段就是计数器名称。计数器是全局的。 换言之，MapReduce框架将跨所有map和reduce聚集这些计数器，并在作业结束 时产生一个最终结果。</p>
<p>Note1： 需要说明的是，不同的 hadoop 版本定义的方式会有些许差异。</p>
<p>（1）在0.20.x版本中使用counter很简单,直接定义即可，如无此counter，hadoop会自动添加此counter.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Counter ct = context.getCounter(“INPUT_WORDS”, “count”);</span><br><span class="line">ct.increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure></p>
<p>（2）在0.19.x版本中,需要定义enum<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> MyCounter &#123;INPUT_WORDS &#125;;</span><br><span class="line">reporter.incrCounter(MyCounter.INPUT_WORDS, <span class="number">1</span>);</span><br><span class="line">RunningJob job = JobClient.runJob(conf);</span><br><span class="line">Counters c = job.getCounters();</span><br><span class="line"><span class="keyword">long</span> cnt = c.getCounter(MyCounter.INPUT_WORDS);</span><br></pre></td></tr></table></figure></p>
<p>Notice2： 使用计数器需要清楚的是它们都存储在jobTracker的内存里。 Mapper/Reducer 任务序列化它们，连同更新状态被发送。为了运行正常且jobTracker不会出问题，计数器的数量应该在10-100个，计数器不仅仅只用来聚合MapReduce job的统计值。新版本的hadoop限制了计数器的数量，以防给jobTracker带来损害。你最不想看到的事情就是由于定义上百个计数器而使jobTracker宕机。</p>
<p>下面咱们来看一个计数器的实例（以下代码请运行在 0.20.1 版本以上）：</p>
<p>3.1 测试数据：</p>
<p>hello world 2013 mapreduce<br>hello world 2013 mapreduce<br>hello world 2013 mapreduce</p>
<p>3.2 代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line"> * Project Name:CDHJobs</span><br><span class="line"> * File Name:MapredCounter.java</span><br><span class="line"> * Package Name:tmp</span><br><span class="line"> * Date:2014-6-8下午2:12:48</span><br><span class="line"> * Copyright (c) 2014, decli#qq.com All Rights Reserved.</span><br><span class="line"> *</span><br><span class="line"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> tmp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Counter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.CounterGroup;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Counters;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountWithCounter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">enum</span> WordsNature &#123;</span><br><span class="line">    STARTS_WITH_DIGIT, STARTS_WITH_LETTER, ALL</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span><br><span class="line">   * The map class of WordCount.</span><br><span class="line">   */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenCounterMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</span><br><span class="line">      <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">        word.set(itr.nextToken());</span><br><span class="line">        context.write(word, one);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span><br><span class="line">   * The reducer class of WordCount</span><br><span class="line">   */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenCounterReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException,</span><br><span class="line">        InterruptedException </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">      String token = key.toString();</span><br><span class="line">      <span class="keyword">if</span> (StringUtils.isNumeric(token)) &#123;</span><br><span class="line">        context.getCounter(WordsNature.STARTS_WITH_DIGIT).increment(<span class="number">1</span>);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (StringUtils.isAlpha(token)) &#123;</span><br><span class="line">        context.getCounter(WordsNature.STARTS_WITH_LETTER).increment(<span class="number">1</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      context.getCounter(WordsNature.ALL).increment(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">        sum += value.get();</span><br><span class="line">      &#125;</span><br><span class="line">      context.write(key, <span class="keyword">new</span> IntWritable(sum));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span><br><span class="line">   * The main entry point.</span><br><span class="line">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    Job job = <span class="keyword">new</span> Job(conf, <span class="string">"WordCountWithCounter"</span>);</span><br><span class="line">    job.setJarByClass(WordCountWithCounter.class);</span><br><span class="line">    job.setMapperClass(TokenCounterMapper.class);</span><br><span class="line">    job.setReducerClass(TokenCounterReducer.class);</span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(<span class="string">"/tmp/dsap/rawdata/june/a.txt"</span>));</span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"/tmp/dsap/rawdata/june/a_result"</span>));</span><br><span class="line">    <span class="keyword">int</span> exitCode = job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    Counters counters = job.getCounters();</span><br><span class="line">    Counter c1 = counters.findCounter(WordsNature.STARTS_WITH_DIGIT);</span><br><span class="line">    System.out.println(<span class="string">"--------------&gt;&gt;&gt;&gt;: "</span> + c1.getDisplayName() + <span class="string">": "</span> + c1.getValue());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The below example shows how to get built-in counter groups that Hadoop provides basically.</span></span><br><span class="line">    <span class="keyword">for</span> (CounterGroup group : counters) &#123;</span><br><span class="line">      System.out.println(<span class="string">"=========================================================="</span>);</span><br><span class="line">      System.out.println(<span class="string">"* Counter Group: "</span> + group.getDisplayName() + <span class="string">" ("</span> + group.getName() + <span class="string">")"</span>);</span><br><span class="line">      System.out.println(<span class="string">"  number of counters in this group: "</span> + group.size());</span><br><span class="line">      <span class="keyword">for</span> (Counter counter : group) &#123;</span><br><span class="line">        System.out.println(<span class="string">"  ++++ "</span> + counter.getDisplayName() + <span class="string">": "</span> + counter.getName() + <span class="string">": "</span></span><br><span class="line">            + counter.getValue());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    System.exit(exitCode);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3.3 结果与计数器详解</p>
<p>运行结果下面会一并给出。Counter有”组group”的概念，用于表示逻辑上相同范围的所有数值。MapReduce job提供的默认Counter分为7个组，下面逐一介绍。这里也拿上面的测试数据来做详细比对，我将会针对具体的计数器，挑选一些主要的简述一下。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line">... 前面省略 job 运行信息 xx 字 ...</span><br><span class="line">  ALL=4</span><br><span class="line">  STARTS_WITH_DIGIT=1</span><br><span class="line">  STARTS_WITH_LETTER=3</span><br><span class="line"><span class="comment">--------------&gt;&gt;&gt;&gt;: STARTS_WITH_DIGIT: 1</span></span><br><span class="line">==========================================================</span><br><span class="line">#MapReduce job执行所依赖的数据来自于不同的文件系统，这个group表示job与文件系统交互的读写统计 </span><br><span class="line">* Counter Group: File System Counters (org.apache.hadoop.mapreduce.FileSystemCounter)</span><br><span class="line"> number of counters in this group: 10</span><br><span class="line"> #job读取本地文件系统的文件字节数。假定我们当前map的输入数据都来自于HDFS，那么在map阶段，这个数据应该是<span class="operator">0。但reduce在执行前，它 的输入数据是经过shuffle的<span class="keyword">merge</span>后存储在reduce端本地磁盘中，所以这个数据就是所有reduce的总输入字节数。</span><br><span class="line"> ++++ <span class="keyword">FILE</span>: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">bytes</span> <span class="keyword">read</span>: FILE_BYTES_READ: <span class="number">159</span></span><br><span class="line"> #<span class="keyword">map</span>的中间结果都会spill到本地磁盘中，在<span class="keyword">map</span>执行完后，形成最终的spill文件。所以<span class="keyword">map</span>端这里的数据就表示<span class="keyword">map</span> task往本地磁盘中总共写了多少字节。与<span class="keyword">map</span>端相对应的是，reduce端在shuffle时，会不断地拉取<span class="keyword">map</span>端的中间结果，然后做<span class="keyword">merge</span>并 不断spill到自己的本地磁盘中。最终形成一个单独文件，这个文件就是reduce的输入文件。 </span><br><span class="line"> ++++ <span class="keyword">FILE</span>: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">bytes</span> written: FILE_BYTES_WRITTEN: <span class="number">159447</span></span><br><span class="line"> ++++ <span class="keyword">FILE</span>: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">read</span> <span class="keyword">operations</span>: FILE_READ_OPS: <span class="number">0</span></span><br><span class="line"> ++++ <span class="keyword">FILE</span>: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">large</span> <span class="keyword">read</span> <span class="keyword">operations</span>: FILE_LARGE_READ_OPS: <span class="number">0</span></span><br><span class="line"> ++++ <span class="keyword">FILE</span>: <span class="built_in">Number</span> <span class="keyword">of</span> write <span class="keyword">operations</span>: FILE_WRITE_OPS: <span class="number">0</span></span><br><span class="line"> # 整个job执行过程中，只有<span class="keyword">map</span>端运行时，才从HDFS读取数据，这些数据不限于源文件内容，还包括所有<span class="keyword">map</span>的<span class="keyword">split</span>元数据。所以这个值应该比FileInputFormatCounters.BYTES_READ 要略大些。 </span><br><span class="line"> ++++ HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">bytes</span> <span class="keyword">read</span>: HDFS_BYTES_READ: <span class="number">198</span></span><br><span class="line"> #Reduce的最终结果都会写入HDFS，就是一个job执行结果的总量。 </span><br><span class="line"> ++++ HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">bytes</span> written: HDFS_BYTES_WRITTEN: <span class="number">35</span></span><br><span class="line"> ++++ HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">read</span> <span class="keyword">operations</span>: HDFS_READ_OPS: <span class="number">6</span></span><br><span class="line"> ++++ HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">large</span> <span class="keyword">read</span> <span class="keyword">operations</span>: HDFS_LARGE_READ_OPS: <span class="number">0</span></span><br><span class="line"> ++++ HDFS: <span class="built_in">Number</span> <span class="keyword">of</span> write <span class="keyword">operations</span>: HDFS_WRITE_OPS: <span class="number">2</span></span><br><span class="line">==========================================================</span><br><span class="line">#这个<span class="keyword">group</span>描述与job调度相关的统计 </span><br><span class="line">* Counter <span class="keyword">Group</span>: Job Counters (org.apache.hadoop.mapreduce.JobCounter)</span><br><span class="line"> <span class="built_in">number</span> <span class="keyword">of</span> counters <span class="keyword">in</span> this <span class="keyword">group</span>: <span class="number">5</span></span><br><span class="line"> #Job在被调度时，如果启动了一个<span class="keyword">data</span>-<span class="keyword">local</span>(源文件的幅本在执行<span class="keyword">map</span> task的taskTracker本地) </span><br><span class="line"> ++++ <span class="keyword">Data</span>-<span class="keyword">local</span> <span class="keyword">map</span> tasks </span><br><span class="line"> #当前job为某些<span class="keyword">map</span> task的执行保留了slot，总共保留的时间是多少 </span><br><span class="line"> ++++ FALLOW_SLOTS_MILLIS_MAPS/REDUCES</span><br><span class="line"> #所有<span class="keyword">map</span> task占用slot的总时间，包含执行时间和创建/销毁子JVM的时间</span><br><span class="line"> ++++ SLOTS_MILLIS_MAPS/REDUCES</span><br><span class="line"> # 此job启动了多少个<span class="keyword">map</span> task </span><br><span class="line"> ++++ Launched <span class="keyword">map</span> tasks: TOTAL_LAUNCHED_MAPS: <span class="number">1</span></span><br><span class="line"> # 此job启动了多少个reduce task </span><br><span class="line"> ++++ Launched reduce tasks: TOTAL_LAUNCHED_REDUCES: <span class="number">1</span></span><br><span class="line"> ++++ Rack-<span class="keyword">local</span> <span class="keyword">map</span> tasks: RACK_LOCAL_MAPS: <span class="number">1</span></span><br><span class="line"> ++++ Total <span class="keyword">time</span> spent <span class="keyword">by</span> all maps <span class="keyword">in</span> occupied slots (ms): SLOTS_MILLIS_MAPS: <span class="number">3896</span></span><br><span class="line"> ++++ Total <span class="keyword">time</span> spent <span class="keyword">by</span> all reduces <span class="keyword">in</span> occupied slots (ms): SLOTS_MILLIS_REDUCES: <span class="number">9006</span></span><br><span class="line">==========================================================</span><br><span class="line">#这个Counter <span class="keyword">group</span>包含了相当多地job执行细节数据。这里需要有个概念认识是：一般情况下，<span class="built_in">record</span>就表示一行数据，而相对地<span class="keyword">byte</span>表示这行数据的大小是 多少，这里的<span class="keyword">group</span>表示经过reduce <span class="keyword">merge</span>后像这样的输入形式&#123;<span class="string">"aaa"</span>, [<span class="number">5</span>, <span class="number">8</span>, <span class="number">2</span>, …]&#125;。 </span><br><span class="line">* Counter <span class="keyword">Group</span>: <span class="keyword">Map</span>-Reduce Framework (org.apache.hadoop.mapreduce.TaskCounter)</span><br><span class="line"> <span class="built_in">number</span> <span class="keyword">of</span> counters <span class="keyword">in</span> this <span class="keyword">group</span>: <span class="number">20</span></span><br><span class="line"> #所有<span class="keyword">map</span> task从HDFS读取的文件总行数 </span><br><span class="line"> ++++ <span class="keyword">Map</span> <span class="keyword">input</span> <span class="keyword">records</span>: MAP_INPUT_RECORDS: <span class="number">3</span></span><br><span class="line"> #<span class="keyword">map</span> task的直接输出<span class="built_in">record</span>是多少，就是在<span class="keyword">map</span>方法中调用<span class="keyword">context</span>.write的次数，也就是未经过Combine时的原生输出条数 </span><br><span class="line"> ++++ <span class="keyword">Map</span> <span class="keyword">output</span> <span class="keyword">records</span>: MAP_OUTPUT_RECORDS: <span class="number">12</span></span><br><span class="line"> # <span class="keyword">Map</span>的输出结果<span class="keyword">key</span>/<span class="keyword">value</span>都会被序列化到内存缓冲区中，所以这里的<span class="keyword">bytes</span>指序列化后的最终字节之和 </span><br><span class="line"> ++++ <span class="keyword">Map</span> <span class="keyword">output</span> <span class="keyword">bytes</span>: MAP_OUTPUT_BYTES: <span class="number">129</span></span><br><span class="line"> ++++ <span class="keyword">Map</span> <span class="keyword">output</span> <span class="keyword">materialized</span> <span class="keyword">bytes</span>: MAP_OUTPUT_MATERIALIZED_BYTES: <span class="number">159</span></span><br><span class="line"> # #与<span class="keyword">map</span> task 的<span class="keyword">split</span>相关的数据都会保存于HDFS中，而在保存时元数据也相应地存储着数据是以怎样的压缩方式放入的，它的具体类型是什么，这些额外的数据是 MapReduce框架加入的，与job无关，这里记录的大小就是表示额外信息的字节大小</span><br><span class="line"> ++++ <span class="keyword">Input</span> <span class="keyword">split</span> <span class="keyword">bytes</span>: SPLIT_RAW_BYTES: <span class="number">117</span></span><br><span class="line"> #Combiner是为了减少尽量减少需要拉取和移动的数据，所以combine输入条数与<span class="keyword">map</span>的输出条数是一致的。</span><br><span class="line"> ++++ Combine <span class="keyword">input</span> <span class="keyword">records</span>: COMBINE_INPUT_RECORDS: <span class="number">0</span></span><br><span class="line"> # 经过Combiner后，相同<span class="keyword">key</span>的数据经过压缩，在<span class="keyword">map</span>端自己解决了很多重复数据，表示最终在<span class="keyword">map</span>端中间文件中的所有条目数 </span><br><span class="line"> ++++ Combine <span class="keyword">output</span> <span class="keyword">records</span>: COMBINE_OUTPUT_RECORDS: <span class="number">0</span></span><br><span class="line"> #Reduce总共读取了多少个这样的<span class="keyword">groups</span> </span><br><span class="line"> ++++ Reduce <span class="keyword">input</span> <span class="keyword">groups</span>: REDUCE_INPUT_GROUPS: <span class="number">4</span></span><br><span class="line"> #Reduce端的copy线程总共从<span class="keyword">map</span>端抓取了多少的中间数据，表示各个<span class="keyword">map</span> task最终的中间文件总和 </span><br><span class="line"> ++++ Reduce shuffle <span class="keyword">bytes</span>: REDUCE_SHUFFLE_BYTES: <span class="number">159</span></span><br><span class="line"> #如果有Combiner的话，那么这里的数值就等于<span class="keyword">map</span>端Combiner运算后的最后条数，如果没有，那么就应该等于<span class="keyword">map</span>的输出条数 </span><br><span class="line"> ++++ Reduce <span class="keyword">input</span> <span class="keyword">records</span>: REDUCE_INPUT_RECORDS: <span class="number">12</span></span><br><span class="line"> #所有reduce执行后输出的总条目数 </span><br><span class="line"> ++++ Reduce <span class="keyword">output</span> <span class="keyword">records</span>: REDUCE_OUTPUT_RECORDS: <span class="number">4</span></span><br><span class="line"> #spill过程在<span class="keyword">map</span>和reduce端都会发生，这里统计在总共从内存往磁盘中spill了多少条数据 </span><br><span class="line"> ++++ Spilled <span class="keyword">Records</span>: SPILLED_RECORDS: <span class="number">24</span></span><br><span class="line"> #每个reduce几乎都得从所有<span class="keyword">map</span>端拉取数据，每个copy线程拉取成功一个<span class="keyword">map</span>的数据，那么增<span class="number">1</span>，所以它的总数基本等于 reduce <span class="built_in">number</span> * <span class="keyword">map</span> <span class="built_in">number</span> </span><br><span class="line"> ++++ Shuffled Maps : SHUFFLED_MAPS: <span class="number">1</span></span><br><span class="line"> # copy线程在抓取<span class="keyword">map</span>端中间数据时，如果因为网络连接异常或是IO异常，所引起的shuffle错误次数 </span><br><span class="line"> ++++ <span class="keyword">Failed</span> Shuffles: FAILED_SHUFFLE: <span class="number">0</span></span><br><span class="line"> #记录着shuffle过程中总共经历了多少次<span class="keyword">merge</span>动作 </span><br><span class="line"> ++++ Merged <span class="keyword">Map</span> outputs: MERGED_MAP_OUTPUTS: <span class="number">1</span></span><br><span class="line"> #通过JMX获取到执行<span class="keyword">map</span>与reduce的子JVM总共的GC时间消耗 </span><br><span class="line"> ++++ GC <span class="keyword">time</span> elapsed (ms): GC_TIME_MILLIS: <span class="number">13</span></span><br><span class="line"> ++++ CPU <span class="keyword">time</span> spent (ms): CPU_MILLISECONDS: <span class="number">3830</span></span><br><span class="line"> ++++ <span class="keyword">Physical</span> <span class="keyword">memory</span> (<span class="keyword">bytes</span>) <span class="keyword">snapshot</span>: PHYSICAL_MEMORY_BYTES: <span class="number">537718784</span></span><br><span class="line"> ++++ <span class="keyword">Virtual</span> <span class="keyword">memory</span> (<span class="keyword">bytes</span>) <span class="keyword">snapshot</span>: VIRTUAL_MEMORY_BYTES: <span class="number">7365263360</span></span><br><span class="line"> ++++ Total committed <span class="keyword">heap</span> <span class="keyword">usage</span> (<span class="keyword">bytes</span>): COMMITTED_HEAP_BYTES: <span class="number">2022309888</span></span><br><span class="line">==========================================================</span><br><span class="line">#这组内描述Shuffle过程中的各种错误情况发生次数，基本定位于Shuffle阶段copy线程抓取<span class="keyword">map</span>端中间数据时的各种错误。</span><br><span class="line">* Counter <span class="keyword">Group</span>: Shuffle <span class="keyword">Errors</span> (Shuffle <span class="keyword">Errors</span>)</span><br><span class="line"> <span class="built_in">number</span> <span class="keyword">of</span> counters <span class="keyword">in</span> this <span class="keyword">group</span>: <span class="number">6</span></span><br><span class="line"> #每个<span class="keyword">map</span>都有一个<span class="keyword">ID</span>，如attempt_201109020150_0254_m_000000_0，如果reduce的copy线程抓取过来的元数据中这个<span class="keyword">ID</span>不是标准格式，那么此Counter增加 </span><br><span class="line"> ++++ BAD_ID: BAD_ID: <span class="number">0</span></span><br><span class="line"> #表示copy线程建立到<span class="keyword">map</span>端的连接有误 </span><br><span class="line"> ++++ <span class="keyword">CONNECTION</span>: <span class="keyword">CONNECTION</span>: <span class="number">0</span></span><br><span class="line"> #Reduce的copy线程如果在抓取<span class="keyword">map</span>端数据时出现IOException，那么这个值相应增加 </span><br><span class="line"> ++++ IO_ERROR: IO_ERROR: <span class="number">0</span></span><br><span class="line"> #<span class="keyword">map</span>端的那个中间结果是有压缩好的有格式数据，所有它有两个<span class="keyword">length</span>信息：源数据大小与压缩后数据大小。如果这两个<span class="keyword">length</span>信息传输的有误(负值)，那么此Counter增加</span><br><span class="line"> ++++ WRONG_LENGTH: WRONG_LENGTH: <span class="number">0</span></span><br><span class="line"> #每个copy线程当然是有目的:为某个reduce抓取某些<span class="keyword">map</span>的中间结果，如果当前抓取的<span class="keyword">map</span>数据不是copy线程之前定义好的<span class="keyword">map</span>，那么就表示把数据拉错了</span><br><span class="line"> ++++ WRONG_MAP: WRONG_MAP: <span class="number">0</span></span><br><span class="line"> #与上面描述一致，如果抓取的数据表示它不是为此reduce而准备的，那还是拉错数据了。 </span><br><span class="line"> ++++ WRONG_REDUCE: WRONG_REDUCE: <span class="number">0</span></span><br><span class="line">==========================================================</span><br><span class="line">#这个<span class="keyword">group</span>表示<span class="keyword">map</span> task读取文件内容(总输入数据)的统计 </span><br><span class="line">* Counter <span class="keyword">Group</span>: <span class="keyword">File</span> <span class="keyword">Input</span> <span class="keyword">Format</span> Counters (org.apache.hadoop.mapreduce.lib.<span class="keyword">input</span>.FileInputFormatCounter)</span><br><span class="line"> <span class="built_in">number</span> <span class="keyword">of</span> counters <span class="keyword">in</span> this <span class="keyword">group</span>: <span class="number">1</span></span><br><span class="line"># <span class="keyword">Map</span> task的所有输入数据(字节)，等于各个<span class="keyword">map</span> task的<span class="keyword">map</span>方法传入的所有<span class="keyword">value</span>值字节之和。 </span><br><span class="line"> ++++ <span class="keyword">Bytes</span> <span class="keyword">Read</span>: BYTES_READ: <span class="number">81</span></span><br><span class="line">==========================================================</span><br><span class="line">##这个<span class="keyword">group</span>表示reduce task输出文件内容(总输出数据)的统计 </span><br><span class="line">* Counter <span class="keyword">Group</span>: <span class="keyword">File</span> <span class="keyword">Output</span> <span class="keyword">Format</span> Counters (org.apache.hadoop.mapreduce.lib.<span class="keyword">output</span>.FileOutputFormatCounter)</span><br><span class="line"> <span class="built_in">number</span> <span class="keyword">of</span> counters <span class="keyword">in</span> this <span class="keyword">group</span>: <span class="number">1</span></span><br><span class="line"> ++++ <span class="keyword">Bytes</span> Written: BYTES_WRITTEN: <span class="number">35</span></span><br><span class="line">==========================================================</span><br><span class="line"># 自定义计数器的统计</span><br><span class="line">* Counter <span class="keyword">Group</span>: tmp.WordCountWithCounter$WordsNature (tmp.WordCountWithCounter$WordsNature)</span><br><span class="line"> <span class="built_in">number</span> <span class="keyword">of</span> counters <span class="keyword">in</span> this <span class="keyword">group</span>: <span class="number">3</span></span><br><span class="line"> ++++ ALL: ALL: <span class="number">4</span></span><br><span class="line"> ++++ STARTS_WITH_DIGIT: STARTS_WITH_DIGIT: <span class="number">1</span></span><br><span class="line"> ++++ STARTS_WITH_LETTER: STARTS_WITH_LETTER: <span class="number">3</span></span></span><br></pre></td></tr></table></figure></p>
<p>4、最后的问题：</p>
<p>如果想要在 MapReduce 中实现一个类似计数器的“全局变量”，可以在 map、reduce 中以任意数据类型、任意修改变量值，并在 main 函数中回调获取该怎么办呢？</p>
<p>5、 Refer:</p>
<p>（1）An Example of Hadoop MapReduce Counter</p>
<p><a href="http://diveintodata.org/2011/03/15/an-example-of-hadoop-mapreduce-counter/" target="_blank" rel="external">http://diveintodata.org/2011/03/15/an-example-of-hadoop-mapreduce-counter/</a></p>
<p>（2）Hadoop Tutorial Series, Issue #3: Counters In Action</p>
<p><a href="http://www.philippeadjiman.com/blog/2010/01/07/hadoop-tutorial-series-issue-3-counters-in-action/" target="_blank" rel="external">http://www.philippeadjiman.com/blog/2010/01/07/hadoop-tutorial-series-issue-3-counters-in-action/</a></p>
<p>（3）Controlling Hadoop MapReduce Job recursion</p>
<p><a href="http://codingwiththomas.blogspot.com/2011/04/controlling-hadoop-job-recursion.html" target="_blank" rel="external">http://codingwiththomas.blogspot.com/2011/04/controlling-hadoop-job-recursion.html</a></p>
<p>（4）MapReduce Design Patterns（chapter 2 （part 3））（四）</p>
<p><a href="http://blog.csdn.net/cuirong1986/article/details/8456923" target="_blank" rel="external">http://blog.csdn.net/cuirong1986/article/details/8456923</a></p>
<p>（5）[hadoop源码阅读][5]-counter的使用和默认counter的含义</p>
<p><a href="http://www.cnblogs.com/xuxm2007/archive/2012/06/15/2551030.html" target="_blank" rel="external">http://www.cnblogs.com/xuxm2007/archive/2012/06/15/2551030.html</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="1、计数器_简介">1、计数器 简介</h2><hr>
<p>在许多情况下，一个用户需要了解待分析的数据，尽管这并非所要执行的分析任务 的核心内容。以统计数据集中无效记录数目的任务为例，如果发现无效记录的比例 相当高，那么就需要认真思考为何存在如此多无效记录。是所]]>
    </summary>
    
      <category term="MapReduce" scheme="http://www.notehub.cn/tags/MapReduce/"/>
    
      <category term="machine learning" scheme="http://www.notehub.cn/categories/machine-learning/"/>
    
  </entry>
  
</feed>
