<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Frank</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="计算机 网络 互联网">
<meta property="og:type" content="website">
<meta property="og:title" content="Frank">
<meta property="og:url" content="http://www.notehub.cn/page/3/index.html">
<meta property="og:site_name" content="Frank">
<meta property="og:description" content="计算机 网络 互联网">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Frank">
<meta name="twitter:description" content="计算机 网络 互联网">
  
  
    <link rel="icon" href="favicon.png">
  
  <link href='//fonts.useso.com/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
  <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css" type="text/css">
  

  
</head>
<body>
  <div id="container">
    <header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="/" id="logo"><i class="logo" style="background-image: url(/css/images/logo.jpg)"></i><span class="site-title">Frank</span></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/.">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      
        <nav id="sub-nav">
          <div class="profile" id="profile-nav">
            <a id="profile-anchor" href="javascript:;"><img class="avatar" src="/css/images/logo.png"><i class="fa fa-caret-down"></i></a>
          </div>
        </nav>
      
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"> </button><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
      </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tr>
        
          <td><a class="main-nav-link" href="/.">Home</a></td>
        
          <td><a class="main-nav-link" href="/archives">Archives</a></td>
        
          <td><a class="main-nav-link" href="/categories">Categories</a></td>
        
          <td><a class="main-nav-link" href="/tags">Tags</a></td>
        
          <td><a class="main-nav-link" href="/about">About</a></td>
        
        <td>
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
        </td>
      </tr>
    </table>
  </div>
</header>

    <div class="outer">
      
        <aside id="profile">
  <div class="inner profile-inner">
    <div class="base-info profile-block">
      <img id="avatar" src="/css/images/logo.png">
      <h2 id="name">Li Jingpeng</h2>
      <!-- <h3 id="title">undefined</h3> -->
      <span id="location"><i class="fa fa-map-marker"></i>Hangzhou, China</span>
      <a id="follow" href="Https://weibo.com/329299516">关注我</a>
    </div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        82
        <span>文章</span>
      </div>
      <div class="article-info-block">
        37
        <span>标签</span>
      </div>
    </div>
    
    <div class="contact-info profile-block">
      <table class="contact-list">
        <tr>
          
          <td><a href="https://github.com/lijingpeng" target="_blank" title="github"><i class="fa fa-github"></i></a></td>
          
          <td><a href="/#" target="_blank" title="twitter"><i class="fa fa-twitter"></i></a></td>
          
          <td><a href="/#" target="_blank" title="facebook"><i class="fa fa-facebook"></i></a></td>
          
          <td><a href="/me@lijingpeng.org" target="_blank" title="email"><i class="fa fa-email"></i></a></td>
          
          <td><a href="/atom.xml" target="_blank" title="rss"><i class="fa fa-rss"></i></a></td>
          
        </tr>
      </table>
    </div>
    
    
  </div>
</aside>

      
      <section id="main">
      <article id="post-algo/lib/big_data_lib2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/05/algo/lib/big_data_lib2/">开源大数据处理工具汇总（下）</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/01/05/algo/lib/big_data_lib2/">
      <time datetime="2016-01-05T08:38:12.000Z" itemprop="datePublished">2016-01-05</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1321.jpg" alt="大数据"></p>
<p>接上一部分：<a href="http://www.36dsj.com/archives/24852" title="一共81个，开源大数据处理工具汇总（上） | 36大数据" target="_blank" rel="external">一共81个，开源大数据处理工具汇总（上）</a>，第二部分主要收集整理的内容主要有日志收集系统、消息系统、分布式服务、集群管理、RPC、基础设施、搜索引擎、Iaas和监控管理等大数据开源工具。</p>
<h1 id="u65E5_u5FD7_u6536_u96C6_u7CFB_u7EDF"><a href="#u65E5_u5FD7_u6536_u96C6_u7CFB_u7EDF" class="headerlink" title="<strong>日志收集系统</strong>"></a><strong>日志收集系统</strong></h1><p><span style="color: #f73100;"><strong>一、Facebook Scribe</strong></span></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1107.jpg" alt="scribe"></p>
<p><strong>贡献者</strong>：Facebook</p>
<p><strong>简介</strong>：Scribe是Facebook开源的日志收集系统，在Facebook内部已经得到大量的应用。它能够从各种日志源上收集日志，存储到一个中央存储系统（可以是NFS，分布式文件系统等）上，以便于进行集中统计分析处理。它为日志的“分布式收集，统一处理”提供了一个可扩展的，高容错的方案。当中央存储系统的网络或者机器出现故障时，scribe会将日志转存到本地或者另一个位置，当中央存储系统恢复后，scribe会将转存的日志重新传输给中央存储系统。其通常与Hadoop结合使用，scribe用于向HDFS中push日志，而Hadoop通过MapReduce作业进行定期处理。</p>
<p><strong>Scribe的系统架构</strong></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/298-600x234.jpg" alt="scribe"></p>
<p><strong>代码托管</strong>：<a href="https://github.com/facebook/scribe" target="_blank" rel="external">https://github.com/facebook/scribe</a></p>
<p><strong><span style="color: #f73100;">二、Cloudera Flume</span></strong><img src="http://www.36dsj.com/wp-content/uploads/2015/03/348.jpg" alt="Cloudera Flume"></p>
<p><strong>贡献者</strong>：<a href="http://www.36dsj.com/archives/tag/cloudera" target="_blank" rel="external">Cloudera</a></p>
<p><strong>简介：</strong>Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p>
<p>Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。</p>
<p>当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。</p>
<p><strong>Cloudera Flume构架</strong>：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/427-414x429.jpg" alt="Cloudera Flume"></p>
<p><strong>官网</strong>：<a href="http://flume.apache.org/" target="_blank" rel="external">http://flume.apache.org/</a></p>
<p><strong><span style="color: #f73100;">三、logstash</span></strong></p>
<p><strong>简介</strong>：logstash 是一个应用程序日志、事件的传输、处理、管理和搜索的平台。你可以用它来统一对应用程序日志进行收集管理，提供 Web 接口用于查询和统计。他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/527-600x265.jpg" alt="logstash"></p>
<p><strong>官网</strong>：<a href="http://www.logstash.net/" target="_blank" rel="external">http://www.logstash.net/</a></p>
<p><span style="color: #f73100;"><strong>四、kibana</strong></span></p>
<p><strong>简介</strong>：Kibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面。</p>
<p><strong>主页</strong>： <a href="http://kibana.org/" target="_blank" rel="external">http://kibana.org/</a></p>
<p><strong>代码托管</strong>： <a href="https://github.com/rashidkpc/Kibana/downloads" target="_blank" rel="external">https://github.com/rashidkpc/Kibana/downloads</a></p>
<h1 id="u6D88_u606F_u7CFB_u7EDF"><a href="#u6D88_u606F_u7CFB_u7EDF" class="headerlink" title="<strong>消息系统</strong>"></a><strong>消息系统</strong></h1><p><strong><span style="color: #f75402;">一、StormMQ</span></strong></p>
<p><strong>简介</strong>：MQMessageQueue消息队列产品 StormMQ，是一种服务程序。</p>
<p><strong>官网</strong>：<a href="http://stormmq.com/" target="_blank" rel="external">http://stormmq.com/</a></p>
<p><span style="color: #f75402;"><strong>二、ZeroMQ</strong></span></p>
<p><strong>简介</strong>：这是个类似于Socket的一系列接口，他跟Socket的区别是：普通的socket是端到端的（1:1的关系），而ZMQ却是可以N：M 的关系，人们对BSD套接字的了解较多的是点对点的连接，点对点连接需要显式地建立连接、销毁连接、选择协议（TCP/UDP）和处理错误等，而ZMQ屏蔽了这些细节，让你的网络编程更为简单。ZMQ用于node与node间的通信，node可以是主机或者是进程。</p>
<p>引用官方的说法： “ZMQ(以下ZeroMQ简称ZMQ)是一个简单好用的传输层，像框架一样的一个socket library，他使得Socket编程更加简单、简洁和性能更高。是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。ZMQ的明确目标是“成为标准网络协议栈的一部分，之后进入Linux内核”。现在还未看到它们的成功。但是，它无疑是极具前景的、并且是人们更加需要的“传统”BSD套接字之上的一 层封装。ZMQ让编写高性能网络应用程序极为简单和有趣。”</p>
<p><strong>官网</strong>：<a href="http://zeromq.org/" target="_blank" rel="external">http://zeromq.org/</a></p>
<p><strong><span style="color: #f75402;">三、RabbitMQ</span></strong></p>
<p><strong>简介：</strong>RabbitMQ是一个受欢迎的消息代理，通常用于应用程序之间或者程序的不同组件之间通过消息来进行集成。本文简单介绍了如何使用 RabbitMQ，假定你已经配置好了rabbitmq服务器。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/624.jpg" alt="RabbitMQ"></p>
<p>RabbitMQ是用Erlang，对于主要的编程语言都有驱动或者客户端。我们这里要用的是Java，所以先要获得Java客户端。</p>
<p>像RabbitMQ这样的消息代理可用来模拟不同的场景，例如点对点的消息分发或者订阅/推送。我们的程序足够简单，有两个基本的组件，一个生产者用于产生消息，还有一个消费者用来使用产生的消息。</p>
<p><strong>官网</strong>：<a href="https://www.rabbitmq.com/" target="_blank" rel="external">https://www.rabbitmq.com/</a></p>
<p><strong><span style="color: #f75402;">四、Apache ActiveMQ</span></strong></p>
<p><strong>简介：</strong>ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/726.jpg" alt="Apache ActiveMQ"></p>
<p><strong>特性：</strong></p>
<p>⒈ 多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP</p>
<p>⒉ 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)</p>
<p>⒊ 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性</p>
<p>⒋ 通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上</p>
<p>⒌ 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA</p>
<p>⒍ 支持通过JDBC和journal提供高速的消息持久化</p>
<p>⒎ 从设计上保证了高性能的集群，客户端-服务器，点对点</p>
<p>⒏ 支持Ajax</p>
<p>⒐ 支持与Axis的整合</p>
<p>⒑ 可以很容易得调用内嵌JMS provider，进行测试</p>
<p><strong>官网</strong>：<a href="http://activemq.apache.org/" target="_blank" rel="external">http://activemq.apache.org/</a></p>
<p><strong><span style="color: #f75402;">五、Jafka</span></strong></p>
<p><strong>贡献者</strong>：LinkedIn</p>
<p><span style="color: #f75402;"><strong>简介：</strong></span>Jafka 是一个开源的、高性能的、跨语言分布式消息系统，使用GitHub托管。Jafka 最早是由Apache孵化的Kafka（由LinkedIn捐助给Apache）克隆而来。由于是一个开放式的数据传输协议，因此除了Java开发语言受到支持，Python、Ruby、C、C++等其他语言也能够很好的得到支持。</p>
<p><strong>特性：</strong></p>
<p>1、消息持久化非常快，服务端存储消息的开销为O(1)，并且基于文件系统，能够持久化TB级的消息而不损失性能。</p>
<p>2、吞吐量取决于网络带宽。</p>
<p>3、完全的分布式系统，broker、producer、consumer都原生自动支持分布式。自动实现复杂均衡。</p>
<p>4、内核非常小，整个系统（包括服务端和客户端）只有一个272KB的jar包，内部机制也不复杂，适合进行内嵌或者二次开发 。整个服务端加上依赖组件共3.5MB。</p>
<p>5、消息格式以及通信机制非常简单，适合进行跨语言开发。目前自带的Python3.x的客户端支持发送消息和接收消息。</p>
<p><strong>官网</strong>：<a href="http://kafka.apache.org/" target="_blank" rel="external">http://kafka.apache.org/</a></p>
<p><strong><span style="color: #f75402;">六、Apache Kafka</span></strong></p>
<p><strong>贡献者</strong>：LinkedIn</p>
<p><strong>简介</strong>：Apache Kafka是由Apache软件基金会开发的一个开源消息系统项目，由Scala写成。Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。</p>
<p>Kafka是一个分布式的、分区的、多复本的日志提交服务。它通过一种独一无二的设计提供了一个消息系统的功能。</p>
<p>Kafka集群可以在一个指定的时间内保持所有发布上来的消息，不管这些消息有没有被消费。打个比方，如果这个时间设置为两天，那么在消息发布的两天以内，这条消息都是可以被消费的，但是在两天后，这条消息就会被系统丢弃以释放空间。Kafka的性能不会受数据量的大小影响，因此保持大量的数据不是一个问题。</p>
<p><strong>官网</strong>：<a href="http://kafka.apache.org/" target="_blank" rel="external">http://kafka.apache.org/</a></p>
<h1 id="u5206_u5E03_u5F0F_u670D_u52A1"><a href="#u5206_u5E03_u5F0F_u670D_u52A1" class="headerlink" title="<strong>分布式服务</strong>"></a><strong>分布式服务</strong></h1><p><strong><span style="color: #f75402;">一、ZooKeeper</span></strong></p>
<p><strong>贡献者：</strong>Google</p>
<p><strong>简介：</strong>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</p>
<p>ZooKeeper是以Fast Paxos算法为基础的，paxos算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fast Paxos作了一些优化，通过选举产生一个leader，只有leader才能提交propose，具体算法可见Fast Paxos。因此，要想弄懂ZooKeeper首先得对Fast Paxos有所了解。</p>
<p>架构：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/824-600x244.jpg" alt="zookeeper"></p>
<p>官网：<a href="http://zookeeper.apache.org/" target="_blank" rel="external">http://zookeeper.apache.org/</a></p>
<p>&nbsp;</p>
<h1 id="RPC"><a href="#RPC" class="headerlink" title="<strong>RPC</strong>"></a><strong>RPC</strong></h1><p>（Remote Procedure Call Protocol）——远程过程调用协议</p>
<p>一、Apache Avro</p>
<p>简介：Apache Avro是Hadoop下的一个子项目。它本身既是一个序列化框架，同时也实现了RPC的功能。Avro官网描述Avro的特性和功能如下：</p>
<ul>
<li>丰富的数据结构类型；</li>
<li>快速可压缩的二进制数据形式；</li>
<li>存储持久数据的文件容器；</li>
<li>提供远程过程调用RPC；</li>
<li>简单的动态语言结合功能。</li>
</ul>
<p>相比于Apache Thrift 和Google的Protocol Buffers，Apache Avro具有以下特点：</p>
<ul>
<li>支持动态模式。Avro不需要生成代码，这有利于搭建通用的数据处理系统，同时避免了代码入侵。</li>
<li>数据无须加标签。读取数据前，Avro能够获取模式定义，这使得Avro在数据编码时只需要保留更少的类型信息，有利于减少序列化后的数据大小。</li>
</ul>
<p>官网：<a href="http://avro.apache.org/" target="_blank" rel="external">http://avro.apache.org/</a></p>
<p>二、Facebook Thrift</p>
<p>贡献者：Facebook</p>
<p>简介：Thrift源于大名鼎鼎的facebook之手，在2007年facebook提交Apache基金会将Thrift作为一个开源项目，对于当时的facebook来说创造thrift是为了解决facebook系统中各系统间大数据量的传输通信以及系统之间语言环境不同需要跨平台的特性。</p>
<p>thrift可以支持多种程序语言，例如: C++, C#, Cocoa, Erlang, Haskell, Java, Ocami, Perl, PHP, Python, Ruby, Smalltalk. 在多种不同的语言之间通信thrift可以作为二进制的高性能的通讯中间件，支持数据(对象)序列化和多种类型的RPC服务。</p>
<p>Thrift适用于程序对程 序静态的数据交换，需要先确定好他的数据结构，他是完全静态化的，当数据结构发生变化时，必须重新编辑IDL文件，代码生成，再编译载入的流程，跟其他IDL工具相比较可以视为是Thrift的弱项，Thrift适用于搭建大型数据交换及存储的通用工具，对于大型系统中的内部数据传输相对于JSON和xml无论在性能、传输大小上有明显的优势。</p>
<p>Thrift 主要由5个部分组成：</p>
<p>· 类型系统以及 IDL 编译器：负责由用户给定的 IDL 文件生成相应语言的接口代码</p>
<p>· TProtocol：实现 RPC 的协议层，可以选择多种不同的对象串行化方式，如 JSON, Binary。</p>
<p>· TTransport：实现 RPC 的传输层，同样可以选择不同的传输层实现，如socket, 非阻塞的 socket, MemoryBuffer 等。</p>
<p>· TProcessor：作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口。</p>
<p>· TServer：聚合 TProtocol, TTransport 和 TProcessor 几个对象。</p>
<p>上述的这5个部件都是在 Thrift 的源代码中通过为不同语言提供库来实现的，这些库的代码在 Thrift 源码目录的 lib 目录下面，在使用 Thrift 之前需要先熟悉与自己的语言对应的库提供的接口。</p>
<p>Facebook Thrift构架：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/921.jpg" alt="Thrift"></p>
<p>官网：<a href="http://thrift.apache.org/" target="_blank" rel="external">http://thrift.apache.org/</a></p>
<h1 id="u96C6_u7FA4_u7BA1_u7406"><a href="#u96C6_u7FA4_u7BA1_u7406" class="headerlink" title="<strong>集群管理</strong>"></a><strong>集群管理</strong></h1><p><strong><span style="color: #f75402;">一、Nagios</span></strong></p>
<p><strong>简介：</strong>Nagios是一款开源的免费网络监视工具，能有效监控Windows、Linux和Unix的主机状态，交换机路由器等网络设置，打印机等。在系统或服务状态异常时发出邮件或短信报警第一时间通知网站运维人员，在状态恢复后发出正常的邮件或短信通知。</p>
<p>Nagios可运行在Linux/Unix平台之上，同时提供一个可选的基于浏览器的WEB界面以方便系统管理人员查看网络状态，各种系统问题，以及日志等等。</p>
<p><strong>官网：</strong><a href="http://www.nagios.org/" target="_blank" rel="external">http://www.nagios.org/</a></p>
<p><span style="color: #f75402;"><strong>二、Ganglia</strong></span></p>
<p><strong>简介：</strong>Ganglia是UC Berkeley发起的一个开源集群监视项目，设计用于测量数以千计的节点。Ganglia的核心包含gmond、gmetad以及一个Web前端。主要是用来监控系统性能，如：cpu 、mem、硬盘利用率， I/O负载、网络流量情况等，通过曲线很容易见到每个节点的工作状态，对合理调整、分配系统资源，提高系统整体性能起到重要作用。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1130-600x417.jpg" alt="Ganglia"></p>
<p><strong>官网：</strong><a href="http://ganglia.sourceforge.net/" target="_blank" rel="external">http://ganglia.sourceforge.net/</a></p>
<p><span style="color: #f75402;"><strong>三、Apache Ambari</strong></span></p>
<p><strong>简介：</strong>Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari目前已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。</p>
<p>Apache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalog等的集中管理。也是5个顶级hadoop管理工具之一。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1223.jpg" alt="Apache Ambari"></p>
<p><strong>Ambari主要取得了以下成绩：</strong></p>
<ul>
<li>通过一步一步的安装向导简化了集群供应。</li>
<li>预先配置好关键的运维指标（metrics），可以直接查看Hadoop Core（HDFS和MapReduce）及相关项目（如HBase、Hive和HCatalog）是否健康。</li>
<li>支持作业与任务执行的可视化与分析，能够更好地查看依赖和性能。</li>
<li>通过一个完整的RESTful API把监控信息暴露出来，集成了现有的运维工具。</li>
<li>用户界面非常直观，用户可以轻松有效地查看信息并控制集群。</li>
</ul>
<p>Ambari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时（比如，节点停机或磁盘剩余空间不足等问题），系统将向其发送邮件。</p>
<p>此外，Ambari能够安装安全的（基于Kerberos）Hadoop集群，以此实现了对Hadoop 安全的支持，提供了基于角色的用户认证、授权和审计功能，并为用户管理集成了LDAP和Active Directory。</p>
<p><strong>官网</strong>：<a href="http://ambari.apache.org/" target="_blank" rel="external">http://ambari.apache.org/</a></p>
<p>&nbsp;</p>
<h1 id="u57FA_u7840_u8BBE_u65BD"><a href="#u57FA_u7840_u8BBE_u65BD" class="headerlink" title="<strong>基础设施</strong>"></a><strong>基础设施</strong></h1><p><strong><span style="color: #f75402;">一、LevelDB</span></strong></p>
<p><strong>贡献者</strong>：Jeff Dean和Sanjay Ghemawat</p>
<p><strong>简介：</strong>Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。LevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。</p>
<p><strong>Leveldb框架</strong>：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1322-468x429.jpg" alt="Leveldb"></p>
<p><strong>官网</strong>：<a href="http://code.google.com/p/leveldb/" target="_blank" rel="external">http://code.google.com/p/leveldb/</a></p>
<p><strong><span style="color: #f75402;">二、SSTable</span></strong></p>
<p><strong>简介</strong>：如果说Protocol Buffer是谷歌独立数据记录的通用语言 ，那么有序字符串表（SSTable，Sorted String Table）则是用于存储，处理和数据集交换的最流行​​的数据输出格式。正如它的名字本身，SSTable是有效存储大量键-值对的简单抽象，对高吞吐量顺序读/写进行了优化。</p>
<p>SSTable是Bigtable中至关重要的一块，对于LevelDB来说也是如此。</p>
<p><strong><span style="color: #f75402;">三、RecordIO</span></strong></p>
<p><strong>贡献者</strong>：Google</p>
<p><strong>简介：</strong>我们大家都在用文件来存储数据。文件是存储在磁盘上的。如果在一些不稳定的介质上，文件很容损坏。即时文件某个位置出现一点小小的问题，整个文件就废了。</p>
<p>下面我来介绍Google的一个做法，可以比较好的解决这个问题。那就是recordio文件格式。recoidio的存储单元是一个一个record。这个record可以根据业务的需要自行定义。但Google有一种建议的处理方式就是使用protobuf。</p>
<p>reocordio底层的格式其实很简单。一个record由四部分组成：</p>
<ul>
<li>MagicNumber (32 bits)</li>
<li>Uncompressed data payload size (64 bits)</li>
<li>Compressed data payload size (64 bits), or 0 if the data is not compressed</li>
<li>Payload, possibly compressed.</li>
</ul>
<p><strong>详细格式如下图所示：</strong></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/recordio_thumb-600x76.png" alt="RecordIO"></p>
<p>到这里，大家可能已经知道，recordio之所以能对付坏数据，其实就是在这个MagicNumber（校验值）。</p>
<p><strong><span style="color: #f75402;">四、Flat Buffers</span></strong></p>
<p><strong>贡献者</strong>：Google</p>
<p><strong>简介</strong>：谷歌开源高效、跨平台的序列化库FlatBuffers。</p>
<p>该库的构建是专门为游戏开发人员的性能需求提供支持，它将序列化数据存储在缓存中，这些数据既可以存储在文件中，又可以通过网络原样传输，而不需要任何解析开销。</p>
<p><strong>FlatBuffers有如下一些关键特性—</strong>—</p>
<ul>
<li>访问序列化数据不需要打包/拆包</li>
<li>节省内存而且访问速度快——缓存只占用访问数据所需要的内存；不需要任何额外的内存。</li>
<li>灵活性——通过可选字段向前向后兼容</li>
<li>代码规模小</li>
<li>强类型——错误在编译时捕获，而不是在运行时</li>
<li>便利性——生成的C++头文件代码简洁。如果需要，有一项可选功能可以用来在运行时高效解析Schema和JSON-like格式的文本。</li>
<li>跨平台——使用C++编写，不依赖STL之外的库，因此可以用于任何有C++编辑器的平台。当前，该项目包含构建方法和在Android、Linux、Windows和OSX等操作系统上使用该库的示例。</li>
</ul>
<p>与Protocol Buffers或JSON Parsing这样的可选方案相比，FlatBuffers的优势在于开销更小，这主要是由于它没有解析过程。</p>
<p><strong>代码托管</strong>：<a href="https://github.com/google/flatbuffers" target="_blank" rel="external">https://github.com/google/flatbuffers</a></p>
<p><strong><span style="color: #f75402;">五、Protocol Buffers</span></strong></p>
<p><strong>贡献者：</strong>Google</p>
<p><strong>简介</strong>：Protocol Buffers是Google公司开发的一种数据描述语言，类似于XML能够将结构化数据序列化，可用于数据存储、通信协议等方面。它不依赖于语言和平台并且可扩展性极强。现阶段官方支持C++、JAVA、Python等三种编程语言，但可以找到大量的几乎涵盖所有语言的第三方拓展包。</p>
<p>通过它，你可以定义你的数据的结构，并生成基于各种语言的代码。这些你定义的数据流可以轻松地在传递并不破坏你已有的程序。并且你也可以更新这些数据而现有的程序也不会受到任何的影响。</p>
<p>Protocol Buffers经常被简称为protobuf。</p>
<p><strong>官网</strong>：<a href="http://code.google.com/p/protobuf/" target="_blank" rel="external">http://code.google.com/p/protobuf/</a></p>
<p><strong><span style="color: #f75402;">六、Consistent Hashing（哈希算法）</span></strong></p>
<p><strong>简介：</strong>一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1420.jpg" alt="Consistent Hashing"></p>
<p>一致性hash算法提出了在动态变化的Cache环境中，<strong>判定哈希算法好坏的四个定义：</strong></p>
<p>1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</p>
<p>2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。</p>
<p>3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。</p>
<p>4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</p>
<p>在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。</p>
<p><strong><span style="color: #f75402;">七、Netty</span></strong></p>
<p><strong>贡献者</strong>：JBOSS</p>
<p><strong>简介：</strong>Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1518.jpg" alt="Netty"></p>
<p>也就是说，Netty 是一个基于NIO的客户，服务器端编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty相当简化和流线化了网络应用的编程开发过程，例如，TCP和UDP的socket服务开发。</p>
<p>“快速”和“简单”并不意味着会让你的最终应用产生维护性或性能上的问题。Netty 是一个吸收了多种协议的实现经验，这些协议包括FTP,SMTP,HTTP，各种二进制，文本协议，并经过相当精心设计的项目，最终，Netty 成功的找到了一种方式，在保证易于开发的同时还保证了其应用的性能，稳定性和伸缩性。</p>
<p><strong>官网</strong>：<a href="http://netty.io/" target="_blank" rel="external">http://netty.io/</a></p>
<p><span style="color: #f75402;"><strong>八、BloomFilter</strong></span></p>
<p><strong>简介：</strong>Bloom filter 是由 Howard Bloom 在 1970 年提出的二进制向量数据结构，它具有很好的空间和时间效率，被用来检测一个元素是不是集合中的一个成员。如果检测结果为是，该元素不一定在集合中；但如果检测结果为否，该元素一定不在集合中。因此Bloom filter具有100%的召回率。这样每个检测请求返回有“在集合内（可能错误）”和“不在集合内（绝对不在集合内）”两种情况，可见 Bloom filter 是牺牲了正确率和时间以节省空间。</p>
<p>Bloom filter 优点就是它的插入和查询时间都是常数，另外它查询元素却不保存元素本身，具有良好的安全性。</p>
<h1 id="u641C_u7D22_u5F15_u64CE"><a href="#u641C_u7D22_u5F15_u64CE" class="headerlink" title="搜索引擎"></a>搜索引擎</h1><p><strong><span style="color: #f74802;">一、Nutch</span></strong></p>
<p><strong>简介：</strong>Nutch 是一个开源Java 实现的搜索引擎。它提供了我们运行自己的搜索引擎所需的全部工具。包括全文搜索和Web爬虫。</p>
<p>尽管Web搜索是漫游Internet的基本要求, 但是现有web搜索引擎的数目却在下降. 并且这很有可能进一步演变成为一个公司垄断了几乎所有的web搜索为其谋取商业利益.这显然 不利于广大Internet用户.</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1615.jpg" alt="Nutch"></p>
<p>Nutch为我们提供了这样一个不同的选择. 相对于那些商用的搜索引擎, Nutch作为开放源代码 搜索引擎将会更加透明, 从而更值得大家信赖. 现在所有主要的搜索引擎都采用私有的排序算法, 而不会解释为什么一个网页会排在一个特定的位置. 除此之外, 有的搜索引擎依照网站所付的 费用, 而不是根据它们本身的价值进行排序. 与它们不同, Nucth没有什么需要隐瞒, 也没有 动机去扭曲搜索的结果. Nutch将尽自己最大的努力为用户提供最好的搜索结果.</p>
<p>Nutch目前最新的版本为version v2.2.1。</p>
<p>官网：<a href="https://nutch.apache.org/" target="_blank" rel="external">https://nutch.apache.org/</a></p>
<p><strong><span style="color: #f74802;">二、Lucene</span></strong></p>
<p><strong>开发者</strong>：Doug Cutting（Hadoop之父，你懂的）</p>
<p><strong>简介：</strong>Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，即它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1717-556x429.jpg" alt="Lucene"></p>
<p>官网：<a href="http://lucene.apache.org/" target="_blank" rel="external">http://lucene.apache.org/</a></p>
<p><strong><span style="color: #f74802;">三、SolrCloud</span></strong></p>
<p><strong>简介</strong>：SolrCloud是Solr4.0版本以后基于Solr和Zookeeper的分布式搜索方案。SolrCloud是Solr的基于Zookeeper一种部署方式。Solr可以以多种方式部署，例如单机方式，多机Master-Slaver方式。</p>
<p><strong>原理图</strong>：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1813-583x429.jpg" alt="SolrCloud"></p>
<p><strong>SolrCloud有几个特色功能：</strong></p>
<p>集中式的配置信息使用ZK进行集中配置。启动时可以指定把Solr的相关配置文件上传</p>
<p>Zookeeper，多机器共用。这些ZK中的配置不会再拿到本地缓存，Solr直接读取ZK中的配置信息。配置文件的变动，所有机器都可以感知到。另外，Solr的一些任务也是通过ZK作为媒介发布的。目的是为了容错。接收到任务，但在执行任务时崩溃的机器，在重启后，或者集群选出候选者时，可以再次执行这个未完成的任务。</p>
<p>自动容错SolrCloud对索引分片，并对每个分片创建多个Replication。每个Replication都可以对外提供服务。一个Replication挂掉不会影响索引服务。更强大的是，它还能自动的在其它机器上帮你把失败机器上的索引Replication重建并投入使用。</p>
<p>近实时搜索立即推送式的replication（也支持慢推送）。可以在秒内检索到新加入索引。</p>
<p>查询时自动负载均衡SolrCloud索引的多个Replication可以分布在多台机器上，均衡查询压力。如果查询压力大，可以通过扩展机器，增加Replication来减缓。</p>
<p>自动分发的索引和索引分片发送文档到任何节点，它都会转发到正确节点。</p>
<p>事务日志事务日志确保更新无丢失，即使文档没有索引到磁盘。</p>
<p><span style="color: #f74802;"><strong>四、Solr</strong></span></p>
<p><strong>简介：</strong>Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。用户可以通过http请求，向搜索引擎服务器提交一定格式的XML文件，生成索引；也可以通过Http Get操作提出查找请求，并得到XML格式的返回结果。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1913-593x429.jpg" alt="Solr"></p>
<p>Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。</p>
<p><strong>官网：</strong><a href="https://lucene.apache.org/solr/" target="_blank" rel="external">https://lucene.apache.org/solr/</a></p>
<p><strong><span style="color: #f74802;">五、ElasticSearch</span></strong></p>
<p><strong>简介</strong>：ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是第二最流行的企业搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。</p>
<p><strong>官网：</strong><a href="http://www.elasticsearch.org/http://www.elasticsearch.cn/" target="_blank" rel="external">http://www.elasticsearch.org/</a></p>
<p><strong><span style="color: #f74802;">六、Sphinx</span></strong></p>
<p><strong>简介</strong>：Sphinx是一个基于SQL的全文检索引擎，可以结合MySQL,PostgreSQL做全文搜索，它可以提供比数据库本身更专业的搜索功能，使得应用程序更容易实现专业化的全文检索。Sphinx特别为一些脚本语言设计搜索API接口，如PHP,Python,Perl,Ruby等，同时为MySQL也设计了一个存储引擎插件。</p>
<p>Sphinx单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒。</p>
<p><strong>官网</strong>：<a href="http://sphinxsearch.com/" target="_blank" rel="external">http://sphinxsearch.com</a></p>
<p><strong><span style="color: #f74802;">七、SenseiDB</span></strong></p>
<p><strong>贡献者</strong>：linkedin</p>
<p><strong>简介</strong>：SenseiDB是一个NoSQL数据库，它专注于高更新率以及复杂半结构化搜索查询。熟悉Lucene和Solor的用户会发现，SenseiDB背后有许多似曾相识的概念。SenseiDB部署在多节点集群中，其中每个节点可以包括N块数据片。Apache Zookeeper用于管理节点，它能够保持现有配置，并可以将任意改动（如拓扑修改）传输到整个节点群中。SenseiDB集群还需要一种模式用于定义将要使用的数据模型。</p>
<p>从SenseiDB集群中获取数据的唯一方法是通过Gateways（它 没有“INSERT”方法）。每个集群都连接到一个单一gateway。你需要了解很重要的一点是，由于SenseiDB本身没法处理原子性 （Atomicity）和隔离性（Isolation），因此只能通过外部在gateway层进行限制。另外，gateway必须确保数据流按照预期的方 式运作。内置的gateway有以下几种形式：</p>
<ul>
<li>来自文件</li>
<li>来自JMS队列</li>
<li>通过JDBC</li>
<li>来自Apache Kafka</li>
</ul>
<p><strong>官网</strong>：<a href="http://senseidb.com/" target="_blank" rel="external">http://senseidb.com</a></p>
<h1 id="u6570_u636E_u6316_u6398"><a href="#u6570_u636E_u6316_u6398" class="headerlink" title="<strong>数据挖掘</strong>"></a><strong>数据挖掘</strong></h1><p><strong><span style="color: #f74802;">一、Mahout</span></strong></p>
<p><a href="http://www.36dsj.com/wp-content/uploads/2015/03/2012.jpg" target="_blank" rel="external"><img src="http://www.36dsj.com/wp-content/uploads/2015/03/2012.jpg" alt="Mahout"></a></p>
<p><strong>简介</strong>：Apache Mahout 是 Apache Software Foundation (ASF) 开发的一个全新的开源项目，其主要目标是创建一些可伸缩的机器学习算法，供开发人员在 Apache 在许可下免费使用。该项目已经发展到了它的最二个年头，目前只有一个公共发行版。Mahout 包含许多实现，包括集群、分类、CP 和进化程序。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。</p>
<p>虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和 CF 方面。<strong>Mahout 的主要特性包括：</strong></p>
<ol>
<li>Taste CF。Taste 是 Sean Owen 在 SourceForge 上发起的一个针对 CF 的开源项目，并在 2008 年被赠予 Mahout。</li>
<li>一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift。</li>
<li>Distributed Naive Bayes 和 Complementary Naive Bayes 分类实现。</li>
<li>针对进化编程的分布式适用性功能。</li>
<li>Matrix 和矢量库。</li>
<li>上述算法的示例。</li>
</ol>
<p><strong>官网</strong>：<a href="http://mahout.apache.org/" target="_blank" rel="external">http://mahout.apache.org/</a></p>
<h1 id="Iaas"><a href="#Iaas" class="headerlink" title="<strong>Iaas</strong>"></a><strong>Iaas</strong></h1><p>IaaS（Infrastructure as a Service），即基础设施即服务。</p>
<p><strong><span style="color: #f74802;">一、OpenStack</span></strong></p>
<p><strong>简介：</strong>OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。</p>
<p>OpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2014/12/1148-599x429.jpg" alt="OpenStack"></p>
<p>6个核心项目：Nova（计算，Compute），Swift（对象存储，Object），Glance（镜像，Image），Keystone（身份，Identity），Horizon（自助门户，Dashboard），Quantum &amp; Melange（网络&amp;地址管理），另外还有若干社区项目，如Rackspace（负载均衡）、Rackspace（关系型数据库）。</p>
<p><strong>相关阅读：</strong></p>
<p><a href="http://www.36dsj.com/archives/19596" title="什么是OpenStack？ | 36大数据" target="_blank" rel="external">什么是OpenStack？</a></p>
<p><a href="http://www.36dsj.com/archives/22179" title="成功部署OpenStack的十大要点 | 36大数据" target="_blank" rel="external">成功部署OpenStack的十大要点</a></p>
<p><strong> 官网</strong>：<a href="https://www.openstack.org/" target="_blank" rel="external">https://www.openstack.org/</a></p>
<p><strong><span style="color: #f74802;">二、Docker</span></strong></p>
<p><strong>贡献者</strong>：dotCloud</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/2215.jpg" alt="Docker"></p>
<p><strong>简介</strong>：Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）。几乎没有性能开销,可以很容易地在机器和数据中心中运行。最重要的是,他们不依赖于任何语言、框架或包括系统。</p>
<p><strong>官网</strong>：<a href="http://www.docker.io/" target="_blank" rel="external">http://www.docker.io/</a></p>
<p><strong><span style="color: #f74802;">三、Kubernetes</span></strong></p>
<p><strong>贡献者</strong>：Google</p>
<p><strong>简介</strong>：Kubernetes是Google开源的容器集群管理系统。它构建Ddocker技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，本质上可看作是基于容器技术的mini-PaaS平台。</p>
<p>Kubernetes从另一个角度对资源进行抽象，它让开发人员和管理人员共同着眼于服务的行为和性能的提升，而不是仅仅关注对单一的组件或者是基础资源。</p>
<p>那么Kubernetes集群到底提供了哪些单一容器所没有功能?它主要关注的是对服务级别的控制而并非仅仅是对容器级别的控制，Kubernetes提供了一种“机智”的管理方式，它将服务看成一个整体。在Kubernete的解决方案中，一个服务甚至可以自我扩展，自我诊断，并且容易升级。例如，在Google中，我们使用机器学习技术来保证每个运行的服务的当前状态都是最高效的。</p>
<p>代码托管：<a href="https://github.com/GoogleCloudPlatform/kubernetes/" target="_blank" rel="external">https://github.com/GoogleCloudPlatform/kubernetes/</a></p>
<p><strong><span style="color: #f74802;">四、Imctfy</span></strong></p>
<p><strong>贡献者</strong>：Google</p>
<p><strong>简介</strong>：Google开源了自己所用Linux容器系统的开源版本lmctfy，读音为lem-kut-fee。包括一个C++库（使用了C++11，文档可以参考头文件）和命令行界面。目前的版本是0.1，只提供了CPU与内存隔离。项目还在密集开发中。</p>
<p>mctfy本身是针对某些特定使用场景设计和实现的，目前拥有一台机器上所有容器时运行情况最好，不推荐与LXC和其他容器系统一起使用（虽然也可行）。已在Ubuntu 12.04+和Ubuntu 3.3与3.8内核上测试。</p>
<p><strong>代码托管</strong>：<a href="https://github.com/google/Imctfy/" target="_blank" rel="external">https://github.com/google/Imctfy/</a></p>
<p>&nbsp;</p>
<h1 id="u76D1_u63A7_u7BA1_u7406"><a href="#u76D1_u63A7_u7BA1_u7406" class="headerlink" title="<strong>监控管理</strong>"></a><strong>监控管理</strong></h1><p><strong><span style="color: #f74802;">一、Dapper</span></strong></p>
<p><strong>贡献者：</strong>Google</p>
<p><strong>简介：</strong>Dapper是一个轻量的ORM(对象关系映射（英语：Object Relational Mapping，简称ORM，或O/RM，或O/R mapping）。并不单纯的是一个DBHelper.因为在Dapper中数据其实就是一个对象。Dapper扩展与IDbConnection上，所以事实上它的倾入性很低。我用了StructureMap。如果不喜欢可以自己更换，或者自己实现下。</p>
<p>代码就一个SqlMapper.cs文件,主要是IDbConnection的扩展方法，编译后就40K的一个很小的dll。</p>
<p><strong>特性：</strong></p>
<ol>
<li>Dapper很快。Dapper的速度接近与IDataReader。</li>
<li>Dapper支持主流数据库 Mysql,SqlLite,Mssql2000,Mssql2005,Oracle等一系列的数据库</li>
<li>支持多表并联的对象。支持一对多 多对多的关系，并且没侵入性。</li>
<li>原理通过Emit反射IDataReader的序列队列，来快速的得到和产生对象</li>
<li>Dapper语法十分简单。并且无须迁就数据库的设计</li>
</ol>
<p><strong>官方站点</strong> <a href="http://code.google.com/p/dapper-dot-net/" target="_blank" rel="external">http://code.google.com/p/dapper-dot-net/</a></p>
<p><strong>代码托管</strong>：<a href="http://bigbully.github.io/Dapper-translation/" target="_blank" rel="external">http://bigbully.github.io/Dapper-translation/</a></p>
<p><span style="color: #f74802;"><strong>二、Zipkin</strong></span></p>
<p><strong>贡献者：</strong>Twitter</p>
<p><strong>简介：</strong>Zipkin （分布式跟踪系统）是 Twitter 的一个开源项目，允许开发者收集 Twitter 各个服务上的监控数据，并提供查询接口。该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/2313-535x429.jpg" alt="Zipkin"></p>
<p><strong>官方网站</strong>：<a href="http://twitter.github.io/zipkin/" target="_blank" rel="external">http://twitter.github.io/zipkin/</a></p>
<p><strong>代码托管</strong>：<a href="https://github.com/twitter/zipkin/" target="_blank" rel="external">https://github.com/twitter/zipkin/</a></p>
<p>End.</p>
<p><a href="http://www.36dsj.com/archives/25042" target="_blank" rel="external">http://www.36dsj.com/archives/25042</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/01/05/algo/lib/big_data_lib2/" data-id="cilxtsd50006iwfjii3m62l6c" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/01/05/algo/lib/big_data_lib2/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-algo/lib/big_data_lib" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/05/algo/lib/big_data_lib/">开源大数据处理工具汇总（上）</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/01/05/algo/lib/big_data_lib/">
      <time datetime="2016-01-05T08:07:12.000Z" itemprop="datePublished">2016-01-05</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1321.jpg" alt="大数据"></p>
<p>本文一共分为上下两部分。我们将针对大数据开源工具不同的用处来进行分类，并且附上了官网和部分下载链接，希望能给做大数据的朋友做个参考。下面是第一部分。</p>
<hr>
<h1 id="u67E5_u8BE2_u5F15_u64CE"><a href="#u67E5_u8BE2_u5F15_u64CE" class="headerlink" title="<strong>查询引擎</strong>"></a><strong>查询引擎</strong></h1><p><strong><span style="color: #fc4903;">一、Phoenix</span></strong></p>
<p>贡献者：：<a href="http://www.36dsj.com/archives/tag/salesforce" target="_blank" rel="external">Salesforce</a></p>
<p>简介：这是一个Java中间层，可以让开发者在Apache HBase上执行SQL查询。Phoenix完全使用Java编写，代码位于<a href="https://github.com/forcedotcom/phoenix" target="_blank" rel="external">GitHub</a>上，并且提供了一个客户端可嵌入的JDBC驱动。</p>
<p>Phoenix查询引擎会将SQL查询转换为一个或多个HBase scan，并编排执行以生成标准的JDBC结果集。直接使用HBase API、协同处理器与自定义过滤器，对于简单查询来说，其性能量级是毫秒，对于百万级别的行数来说，其性能量级是秒。</p>
<p>Phoenix<strong>最值得关注的一些特性有：</strong></p>
<p>❶嵌入式的JDBC驱动，实现了大部分的java.sql接口，包括元数据API</p>
<p>❷可以通过多部行键或是键/值单元对列进行建模</p>
<p>❸完善的查询支持，可以使用多个谓词以及优化的扫描键</p>
<p>❹DDL支持：通过CREATE TABLE、DROP TABLE及ALTER TABLE来添加/删除列</p>
<p>❺版本化的模式仓库：当写入数据时，快照查询会使用恰当的模式</p>
<p>❻DML支持：用于逐行插入的UPSERT VALUES、用于相同或不同表之间大量数据传输的UPSERT ❼SELECT、用于删除行的DELETE</p>
<p>❽通过客户端的批处理实现的有限的事务支持</p>
<p>❾单表——还没有连接，同时二级索引也在开发当中</p>
<p>➓紧跟ANSI SQL标准</p>
<p><a href="http://phoenix.incubator.apache.org/" target="_blank" rel="external">Phoenix官方网站&gt;&gt;&gt;</a></p>
<p><strong><span style="color: #fc4903;">二、Stinger</span></strong></p>
<p>贡献者：：<a href="http://www.36dsj.com/archives/tag/hortonworks" target="_blank" rel="external">Hortonworks</a></p>
<p>简介：原叫Tez，下一代Hive,Hortonworks主导开发，运行在YARN上的DAG计算框架。</p>
<p>某些测试下，Stinger能提升10倍左右的性能，同时会让Hive支持更多的SQL，<strong>其主要优点包括：</strong></p>
<p>❶让用户在Hadoop获得更多的查询匹配。其中包括类似OVER的字句分析功能，支持WHERE查询，让Hive的样式系统更符合SQL模型。</p>
<p>❷优化了Hive请求执行计划，优化后请求时间减少90%。改动了Hive执行引擎，增加单Hive任务的被秒处理记录数。</p>
<p>❸在Hive社区中引入了新的列式文件格式（如ORC文件），提供一种更现代、高效和高性能的方式来储存Hive数据。</p>
<p>❹引入了新的运行时框架——Tez，旨在消除Hive的延时和吞吐量限制。Tez通过消除不必要的task、障碍同步和对HDFS的读写作业来优化Hive job。这将优化Hadoop内部的执行链，彻底加速Hive负载处理。</p>
<p><a href="http://hortonworks.com/labs/stinger/" target="_blank" rel="external">Stinger官方网站&gt;&gt;&gt;</a></p>
<p><span style="color: #fc4903;"><strong>三、Presto</strong></span></p>
<p>贡献者：：Facebook</p>
<p>简介：Facebook开源的数据查询引擎Presto ，可对250PB以上的数据进行快速地交互式分析。该项目始于 2012 年秋季开始开发，目前该项目已经在超过 1000 名 Facebook 雇员中使用，运行超过 30000 个查询，每日数据在 1PB 级别。Facebook 称 Presto 的性能比诸如 Hive 和 Map*Reduce 要好上 10 倍有多。</p>
<p>Presto 当前支持 ANSI SQL 的大多数特效，包括联合查询、左右联接、子查询以及一些聚合和计算函数；支持近似截然不同的计数(DISTINCT COUNT)等。</p>
<p><a href="https://github.com/facebook/presto" target="_blank" rel="external">github源代码下载&gt;&gt;&gt;</a></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1105.jpg" alt="36大数据"></p>
<p><strong><span style="color: #fc4903;">四、Shark</span></strong></p>
<p><strong>简介</strong>：Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。Shark的特点就是快，完全兼容Hive，且可以在shell模式下使用rdd2sql()这样的API，把HQL得到的结果集，继续在scala环境下运算，支持自己编写简单的机器学习或简单分析处理函数，对HQL结果进一步分析计算。</p>
<p>❶Shark速度快的原因除了Spark平台提供的基于内存迭代计算外，在设计上还存在对Spark上进行了一定的改造，主要有</p>
<p>❷partial DAG execution：对join优化，调节并行粒度，因为Spark本身的宽依赖和窄依赖会影响并行计算和速度</p>
<p>基于列的压缩和存储：把HQL表数据按列存，每列是一个array，存在JVM上，避免了JVM GC低效，而压缩和解压相关的技术是Yahoo!提供的。</p>
<p>结来说，Shark是一个插件式的东西，在我现有的Spark和Hive及hadoop-client之间，在这两套都可用的情况下，Shark只要获取Hive的配置（还有metastore和exec等关键包），Spark的路径，Shark就能利用Hive和Spark，把HQL解析成RDD的转换，把数据取到Spark上运算和分析。在SQL on Hadoop这块，Shark有别于Impala，Stringer，而这些系统各有自己的设计思路，相对于对MR进行优化和改进的思路，Shark的思路更加简单明了些。</p>
<p><a href="http://shark.cs.berkeley.edu/" target="_blank" rel="external"><strong>Shark官方网站&gt;&gt;&gt;</strong></a></p>
<p><strong><span style="color: #fc4903;">五、Pig</span></strong></p>
<p><strong>简介：</strong>Pig是一种编程语言，它简化了Hadoop常见的工作任务。Pig可加载数据、表达转换数据以及存储最终结果。Pig内置的操作使得半结构化数据变得有意义（如日志文件）。同时Pig可扩展使用Java中添加的自定义数据类型并支持数据转换。</p>
<p>Pig最大的作用就是对mapreduce算法(框架)实现了一套shell脚本 ，类似我们通常熟悉的SQL语句，在Pig中称之为Pig Latin，在这套脚本中我们可以对加载出来的数据进行排序、过滤、求和、分组(group by)、关联(Joining)，Pig也可以由用户自定义一些函数对数据集进行操作，也就是传说中的UDF(user-defined functions)。</p>
<p><a href="http://pig.apache.org/" target="_blank" rel="external">Pig官方网站&gt;&gt;&gt;</a></p>
<p><strong><span style="color: #fc4903;">六、Cloudera <span class="font2">Impala</span></span></strong></p>
<p><strong>贡献者：:</strong><a href="http://www.36dsj.com/archives/tag/cloudera" target="_blank" rel="external">Cloudera</a></p>
<p><strong>简介：</strong>Cloudera Impala 可以直接为存储在HDFS或HBase中的Hadoop数据提供快速，交互式的SQL查询。除了使用相同的存储平台外， Impala和Apache Hive一样也使用了相同的元数据，SQL语法（Hive SQL），ODBC驱动和用户接口（Hue Beeswax），这就很方便的为用户提供了一个相似并且统一的平台来进行批量或实时查询。</p>
<p>Cloudera Impala 是用来进行大数据查询的补充工具。 Impala 并没有取代像Hive这样基于MapReduce的分布式处理框架。Hive和其它基于MapReduce的计算框架非常适合长时间运行的批处理作业，例如那些涉及到批量 Extract、Transform、Load ，即需要进行ETL作业。</p>
<p><strong>Impala 提供了</strong>：</p>
<p>❶数据科学家或数据分析师已经熟知的SQL接口</p>
<p>❷能够在Apache Hadoop 的大数据中进行交互式数据查询</p>
<p>❸ Single system for big data processing and analytics so customers can avoid costly modeling and ETL just for analytics</p>
<p><a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html" target="_blank" rel="external">Cloudera <span class="font2">Impala官方网站&gt;&gt;&gt;</span></a></p>
<p><strong><span style="color: #f74e05;">七、Apache <span class="font2">Drill</span></span></strong></p>
<p>贡献者：：<a href="http://www.36dsj.com/archives/tag/mapr" target="_blank" rel="external">MapR</a></p>
<p>简介：Apache Drill是是一个能够对大数据进行交互分析、开源的分布式系统，且基于Google Dremel实现，它能够运行在上千个节点的服务器集群上，且能在几秒内处理PB级或者万亿条的数据记录。Drill能够帮助企业用户快速、高效地进行Hadoop数据查询和企业级大数据分析。Drill于2012年8月份由Apache推出。</p>
<p>从Drill官方对其架构的介绍中得知，其具有适于实时的分析和快速的应用开发、适于半结构化/嵌套数据的分析、兼容现有的SQL环境和Apache Hive等特征。另外，Drill的核心模块是Drillbit服务，该服务模块包括远程访问子模块、SQL解析器、查询优化器、任务计划执行引擎、存储插件接口（DFS、HBase、Hive等的接口）、分布式缓存模块等几部分，如下图所示：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/346.jpg" alt="36大数据"></p>
<p><a href="http://incubator.apache.org/drill/" target="_blank" rel="external">Apache <span class="font2">Drill官方网站&gt;&gt;&gt;</span></a></p>
<p><strong><span style="color: #fc4903;">八、Apache Tajo</span></strong></p>
<p><strong>简介：</strong>Apache Tajo项目的目的是在HDFS之上构建一个先进的数据仓库系统。Tajo将自己标榜为一个“大数据仓库”，但是它好像和之前介绍的那些低延迟查询引擎类似。虽然它支持外部表和Hive数据集（通过HCatalog），但是它的重点是数据管理，提供低延迟的数据访问，以及为更传统的ETL提供工具。它也需要在数据节点上部署Tajo特定的工作进程。</p>
<p>Tajo的功能包括：</p>
<p>❶ANSI SQL兼容</p>
<p>❷JDBC 驱动</p>
<p>❸集成Hive metastore能够访问Hive数据集</p>
<p>❹一个命令行客户端</p>
<p>❺一个自定义函数API</p>
<p><a href="http://tajo.incubator.apache.org/" target="_blank" rel="external">Apache Tajo官方网站&gt;&gt;&gt;</a></p>
<p><strong><span style="color: #fc4903;">九、Hive</span></strong></p>
<p><strong>简介：</strong>hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p>
<p><a href="http://hive.apache.org/" target="_blank" rel="external">Hive官方网站&gt;&gt;&gt;</a></p>
<h1 id="u6D41_u5F0F_u8BA1_u7B97"><a href="#u6D41_u5F0F_u8BA1_u7B97" class="headerlink" title="<strong>流式计算</strong>"></a><strong>流式计算</strong></h1><p><strong><span style="color: #fc4903;">一、Facebook Puma</span></strong></p>
<p><strong>贡献者：</strong>Facebook</p>
<p>简介：实时数据流分析</p>
<p><strong><span style="color: #fc4903;">二、Twitter Rainbird</span></strong></p>
<p><strong>贡献者</strong>：Twitter</p>
<p><strong>简介</strong>：Rainbird一款基于Zookeeper, Cassandra, Scribe, Thrift的分布式实时统计系统，这些基础组件的基本功能如下：</p>
<p>❶ Zookeeper，Hadoop子项目中的一款分布式协调系统，用于控制分布式系统中各个组件中的一致性。</p>
<p>❷Cassandra，NoSQL中一款非常出色的产品，集合了Dynamo和Bigtable特性的分布式存储系统，用于存储需要进行统计的数据，统计数据，并且提供客户端进行统计数据的查询。（需要使用分布式Counter补丁CASSANDRA-1072）</p>
<p>❸ Scribe，Facebook开源的一款分布式日志收集系统，用于在系统中将各个需要统计的数据源收集到Cassandra中。</p>
<p>❹ Thrift，Facebook开源的一款跨语言C/S网络通信框架，开发人员基于这个框架可以轻易地开发C/S应用。</p>
<p><strong>用处</strong></p>
<p>Rainbird可以用于实时数据的统计：</p>
<p>❶统计网站中每一个页面，域名的点击次数</p>
<p>❷内部系统的运行监控（统计被监控服务器的运行状态）</p>
<p>❸记录最大值和最小值</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/280.jpg" alt="36大数据"></p>
<p><span style="color: #fc4903;"><strong>三、Yahoo S4</strong></span></p>
<p><strong>贡献者：</strong>Yahoo</p>
<p><strong>简介</strong>：S4（Simple Scalable Streaming System）最初是Yahoo!为提高搜索广告有效点击率的问题而开发的一个平台，通过统计分析用户对广告的点击率，排除相关度低的广告，提升点击率。目前该项目刚启动不久，所以也可以理解为是他们提出的一个分布式流计算（Distributed Stream Computing）的模型。</p>
<p><strong>S4的设计目标是：</strong></p>
<p>·提供一种简单的编程接口来处理数据流</p>
<p>·设计一个可以在普通硬件之上可扩展的高可用集群。</p>
<p>·通过在每个处理节点使用本地内存，避免磁盘I/O瓶颈达到最小化延迟</p>
<p>·使用一个去中心的，对等架构；所有节点提供相同的功能和职责。没有担负特殊责任的中心节点。这大大简化了部署和维护。</p>
<p>·使用可插拔的架构，使设计尽可能的即通用又可定制化。</p>
<p>·友好的设计理念，易于编程，具有灵活的弹性</p>
<p><a href="http://incubator.apache.org/s4/" target="_blank" rel="external">Yahoo S4官方网站&gt;&gt;&gt;</a></p>
<p><strong><span style="color: #fc4903;">四、Twitter <span class="font2">Storm</span></span></strong></p>
<p><strong>贡献者：</strong>Twitter</p>
<p><strong>简介：</strong>Storm是Twitter开源的一个类似于Hadoop的实时数据处理框架，它原来是由BackType开发，后BackType被Twitter收购，将Storm作为Twitter的实时数据分析系统。</p>
<p>实时数据处理的应用场景很广泛，例如商品推荐，广告投放，它能根据当前情景上下文（用户偏好，地理位置，已发生的查询和点击等）来估计用户点击的可能性并实时做出调整。</p>
<p><strong>storm的三大作用领域：</strong></p>
<p><strong>1.信息流处理（Stream Processing）</strong></p>
<p>Storm可以用来实时处理新数据和更新数据库，兼具容错性和可扩展性,它 可以用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。</p>
<p><strong>2.连续计算（Continuous Computation）</strong></p>
<p>Storm可以进行连续查询并把结果即时反馈给客户，比如将Twitter上的热门话题发送到客户端。</p>
<p><strong>3.分布式远程过程调用（Distributed RPC）</strong></p>
<p>除此之外，Storm也被广泛用于以下方面：</p>
<ul>
<li>精确的广告推送</li>
<li>实时日志的处理</li>
</ul>
<p><strong><a href="http://storm.incubator.apache.org/" target="_blank" rel="external">Twitter <span class="font2">Storm官方网站&gt;&gt;&gt;</span></a></strong></p>
<h1 id="u8FED_u4EE3_u8BA1_u7B97"><a href="#u8FED_u4EE3_u8BA1_u7B97" class="headerlink" title="<strong>迭代计算</strong>"></a><strong>迭代计算</strong></h1><p><span style="color: #fc4903;"><strong>一、Apache Hama</strong></span></p>
<p><strong>简介：</strong>Apache Hama是一个纯BSP（Bulk Synchronous Parallel）计算框架，模仿了Google的Pregel。用来处理大规模的科学计算，特别是矩阵和图计算。</p>
<p>❶建立在Hadoop上的分布式并行计算模型。</p>
<p>❷基于 Map/Reduce 和 Bulk Synchronous 的实现框架。</p>
<p>❸运行环境需要关联 Zookeeper、HBase、HDFS 组件。</p>
<p><strong>Hama中有2个主要的模型:</strong></p>
<p>– 矩阵计算(Matrix package)</p>
<p>– 面向图计算(Graph package)</p>
<p><a href="https://hama.apache.org/" target="_blank" rel="external">Apache Hama官方网站&gt;&gt;&gt;</a></p>
<p><span style="color: #fc4903;"><strong>二、Apache Giraph</strong></span></p>
<p><strong>代码托管地址</strong>： <a href="https://github.com/apache/giraph" target="_blank" rel="external">GitHub</a></p>
<p><strong>简介：</strong>Apache Giraph是一个可伸缩的分布式迭代图处理系统，灵感来自BSP（bulk synchronous parallel）和Google的Pregel，与它们 区别于则是是开源、基于 Hadoop 的架构等。</p>
<p>Giraph处理平台适用于运行大规模的逻辑计算，比如页面排行、共享链接、基于个性化排行等。Giraph专注于社交图计算，被Facebook作为其Open Graph工具的核心，几分钟内处理数万亿次用户及其行为之间的连接。</p>
<p><strong><span style="color: #fc4903;">三、HaLoop</span></strong></p>
<p><strong>简介</strong>：迭代的MapReduce，HaLoop——适用于迭代计算的Hadoop 。</p>
<p>&nbsp;</p>
<div id="attachment_24877" style="width: 541px" class="wp-caption aligncenter"><img src="http://www.36dsj.com/wp-content/uploads/2015/03/425.jpg" alt="Hadoop与HaLoop的不同"><br><br>Hadoop与HaLoop的不同<br></div>

<p>与Hadoop比较的四点改变：</p>
<p>1.提供了一套新的编程接口，更加适用于迭代计算；</p>
<p>HaLoop给迭代计算一个抽象的递归公式：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/403.jpg" alt="大数据"></p>
<p>2.HaLoop的master进行job内的循环控制，直到迭代计算结束；</p>
<p>3.Task Scheduler也进行了修改，使得任务能够尽量满足data locality</p>
<p>4.slave nodes对数据进行cache并index索引，索引也以文件的形式保存在本地磁盘。</p>
<p><a href="https://code.google.com/p/haloop/" target="_blank" rel="external">HaLoop官网&gt;&gt;&gt;</a></p>
<p><span style="color: #fc4903;"><strong>四、Twister</strong></span></p>
<p>简介：Twister， 迭代式MapReduce框架，Twister是由一个印度人开发的，其架构如下：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/524.jpg" alt="Twister"></p>
<p>在Twister中，大文件不会自动被切割成一个一个block，因而用户需提前把文件分成一个一个小文件，以供每个task处理。在map阶段，经过map（）处理完的结果被放在分布式内存中，然后通过一个broker network（NaradaBroking系统）将数据push给各个reduce task（Twister假设内存足够大，中间数据可以全部放在内存中）；在reduce阶段，所有reduce task产生的结果通过一个combine操作进行归并，此时，用户可以进行条件判定， 确定迭代是否结束。combine后的数据直接被送给map task，开始新一轮的迭代。为了提高容错性，Twister每隔一段时间会将map task和reduce task产生的结果写到磁盘上，这样，一旦某个task失败，它可以从最近的备份中获取输入，重新计算。</p>
<p>为了避免每次迭代重新创建task，Twister维护了一个task pool，每次需要task时直接从pool中取。在Twister中，所有消息和数据都是通过broker network传递的，该broker network是一个独立的模块，目前支持NaradaBroking和ActiveMQ。</p>
<h1 id="u79BB_u7EBF_u8BA1_u7B97"><a href="#u79BB_u7EBF_u8BA1_u7B97" class="headerlink" title="<strong>离线计算</strong>"></a><strong>离线计算</strong></h1><p><strong><span style="color: #fc4903;">一、Hadoop <span class="font2">MapReduce</span></span></strong></p>
<p><strong>简介</strong>：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念&#8221;Map（映射）&#8221;和&#8221;Reduce（归约）&#8221;，和它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。 当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。</p>
<p><a href="http://hadoop.apache.org/" target="_blank" rel="external"><strong>Hadoop <span class="font2">MapReduce官方网站&gt;&gt;&gt;</span></strong></a></p>
<p><strong><span style="color: #fc4903;">二、Berkeley Spark</span></strong></p>
<p><strong>简介</strong>：Spark是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。</p>
<p><strong><span style="color: #fc4903;">三、DataTorrent</span></strong></p>
<p><strong>简介</strong>：DataTorrent基于Hadoop 2.x构建，是一个实时的、有容错能力的数据流式处理和分析平台，它使用本地Hadoop应用程序，而这些应用程序可以与执行其它任务，如批处理，的应用程序共存。该平台的架构如下图所示：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/621.jpg" alt="DataTorrent"></p>
<p>相关文章：<a href="http://www.36dsj.com/archives/20163" title="DataTorrent 1.0每秒处理超过10亿个实时事件 | 36大数据" target="_blank" rel="external">DataTorrent 1.0每秒处理超过10亿个实时事件</a></p>
<p><a href="http://www.36dsj.com/archives/1596" title="DataTorrent 将数据分析速度从“实时”提升至“现在时” | 36大数据" target="_blank" rel="external">DataTorrent 将数据分析速度从“实时”提升至“现在时”</a></p>
<p># </p>
<h1 id="u952E_u503C_u5B58_u50A8"><a href="#u952E_u503C_u5B58_u50A8" class="headerlink" title="<strong>键值存储</strong>"></a><strong>键值存储</strong></h1><p><span style="color: #fc4903;"><strong>一、LevelDB</strong></span></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/723.jpg" alt="LevelDB"></p>
<p>贡献者：Google</p>
<p>简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。</p>
<p>LevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。</p>
<p>此处随机读是完全命中内存的速度，如果是不命中 速度大大下降。</p>
<p><a href="https://code.google.com/p/leveldb/" target="_blank" rel="external">LevelDB官方网站&gt;&gt;&gt;</a></p>
<p><strong><span style="color: #fc4903;">二、RocksDB</span></strong></p>
<p><strong>贡献者</strong>：facebook</p>
<p><strong>简介</strong>：RocksDB虽然在代码层面上是在LevelDB原有的代码上进行开发的，但却借鉴了Apache HBase的一些好的idea。在云计算横行的年代，开口不离Hadoop，RocksDB也开始支持HDFS，允许从HDFS读取数据。RocksDB支持一次获取多个K-V，还支持Key范围查找。LevelDB只能获取单个Key。</p>
<p>RocksDB除了简单的Put、Delete操作，还提供了一个Merge操作，说是为了对多个Put操作进行合并。</p>
<p>RocksDB提供一些方便的工具，这些工具包含解析sst文件中的K-V记录、解析MANIFEST文件的内容等。RocksDB支持多线程合并，而LevelDB是单线程合并的。</p>
<p><a href="http://rocksdb.org/" target="_blank" rel="external">RocksDB官方网站&gt;&gt;&gt;</a></p>
<p><strong><span style="color: #fc4903;">三、HyperDex</span></strong></p>
<p>贡献者：Facebook</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/821.jpg" alt=" HyperDex "></p>
<p>HyperDex是一个分布式、可搜索的键值存储系统，特性如下：</p>
<ul>
<li>分布式KV存储，系统性能能够随节点数目线性扩展</li>
<li>吞吐和延时都能秒杀现在风头正劲的MonogDB，吞吐甚至强于Redis</li>
<li>使用了hyperspace hashing技术，使得对存储的K-V的任意属性进行查询成为可能</li>
</ul>
<p>官网：<a href="http://hyperdex.org/" target="_blank" rel="external">http://hyperdex.org/</a></p>
<p><strong><span style="color: #fc4903;">四、TokyoCabinet</span></strong></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/104.png" alt="大数据"></p>
<div class="para">日本人Mikio Hirabayashi（平林干雄）开发的一款DBM数据库。Tokyo Cabinet 是一个DBM的实现。这里的数据库由一系列key-value对的记录构成。key和value都可以是任意长度的字节序列,既可以是二进制也可以是字符串。这里没有数据类型和数据表的概念。</div><br><div class="para"></div><br><div class="para">当 做为Hash表数据库使用时，每个key必须是不同的,因此无法存储两个key相同的值。提供了以下访问方法:提供key,value参数来存储，按 key删除记录，按key来读取记录，另外，遍历key也被支持，虽然顺序是任意的不能被保证。这些方法跟Unix标准的DBM,例如GDBM,NDBM 等等是相同的，但是比它们的性能要好得多（因此可以替代它们) 。下一代KV存储系统，支持strings、integers、floats、lists、maps和sets等丰富的数据类型。</div><br><div class="para"></div><br><div class="para"><a href="http://fallabs.com/tokyocabinet/" target="_blank" rel="external">TokyoCabinet官方网站&gt;&gt;&gt;</a></div><br><div class="para"></div><br><div class="para"><span style="color: #fc4903;"><strong>五、Voldemort</strong></span></div><br><div class="para"><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1127.jpg" alt="大数据"></div><br><div class="para">Voldemort是一个分布式键值存储系统，是Amazon&#8217;s Dynamo的一个开源克隆。特性如下：</div>

<ul>
<li>支持自动复制数据到多个服务器上。</li>
<li>支持数据自动分割所以每个服务器只包含总数据的一个子集。</li>
<li>提供服务器故障透明处理功能。</li>
<li>支持可拨插的序化支持，以实现复杂的键-值存储，它能够很好的5.集成常用的序化框架如：Protocol Buffers、Thrift、Avro和Java Serialization。</li>
<li>数据项都被标识版本能够在发生故障时尽量保持数据的完整性而不会影响系统的可用性。</li>
<li>每个节点相互独立，互不影响。</li>
<li>支持可插拔的数据放置策略</li>
</ul>
<p>官网：<a href="http://project-voldemort.com/" target="_blank" rel="external">http://project-voldemort.com/</a></p>
<div class="para"></div><br><div class="para"><strong><span style="color: #fc4903;">六、Amazon Dynamo</span></strong></div><br><div class="para"></div><br><div class="para">贡献者：亚马逊</div><br><div class="para"></div><br><div class="para">简介：Amazon Dynamo 是一个经典的分布式Key-Value 存储系统，具备去中心化，高可用性，高扩展性的特点，但是为了达到这个目标在很多场景中牺牲了一致性。Dynamo在Amazon中得到了成功的应用，能够跨数据中心部署于上万个结点上提供服务，它的设计思想也被后续的许多分布式系统借鉴。如近来火热的Cassandra，实际上就是基本照搬了Dynamo的P2P架构，同时融合了BigTable的数据模型及存储算法。</div><br><div class="para"></div><br><div class="para"><a href="https://github.com/dynamo/dynamo" target="_blank" rel="external">Amazon Dynamo官方网站&gt;&gt;&gt;</a></div><br><div class="para"></div><br><div class="para"><strong><span style="color: #fc4903;">七、Tair</span></strong></div><br><div class="para"></div><br><div class="para"><strong>贡献者：</strong>淘宝</div><br><div class="para"></div><br><div class="para"><strong>简介</strong>：tair 是淘宝自己开发的一个分布式 key/value 存储引擎. tair 分为持久化和非持久化两种使用方式. 非持久化的 tair 可以看成是一个分布式缓存. 持久化的 tair 将数据存放于磁盘中. 为了解决磁盘损坏导致数据丢失, tair 可以配置数据的备份数目, tair 自动将一份数据的不同备份放到不同的主机上, 当有主机发生异常, 无法正常提供服务的时候, 其于的备份会继续提供服务.<strong>tair 的总体结构</strong></div><br><div class="para"><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1220.jpg" alt="Tair">tair 作为一个分布式系统, 是由一个中心控制节点和一系列的服务节点组成. 我们称中心控制节点为config server. 服务节点是data server. config server 负责管理所有的data server, 维护data server的状态信息. data server 对外提供各种数据服务, 并以心跳的形式将自身状况汇报给config server. config server是控制点, 而且是单点, 目前采用一主一备的形式来保证其可靠性. 所有的 data server 地位都是等价的.</div><br><div class="para"></div><br><div class="para"><strong><span style="color: #fc4903;">八、Apache Accumulo</span></strong></div><br><div class="para"><img src="http://www.36dsj.com/wp-content/uploads/2015/03/8c2532b6-0c16-3879-9600-2a263d923934.png" alt="Apache Accumulo"></div><br><div class="para">Apache Accumulo 是一个可靠的、可伸缩的、高性能的排序分布式的 Key-Value 存储解决方案，基于单元访问控制以及可定制的服务器端处理。Accumulo使用 Google BigTable 设计思路，基于 Apache Hadoop、Zookeeper 和 Thrift 构建。</div><br><div class="para"><strong> </strong></div><br><div class="para"><strong>官网</strong>：<a href="http://accumulo.apache.org/" target="_blank" rel="external">http://accumulo.apache.org/</a></div>

<p><strong><span style="color: #fc4903;">九、Redis</span></strong></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1320.jpg" alt="Redis"></p>
<p>Redis是一个高性能的key-value存储系统，和Memcached类似，它支持存储的value类型相对更多，包括string（字符串）、list（链表）、set（集合）和zset（有序集合）。与memcached一样，为了保证效率，数据都是缓存在内存中，区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了主从同步。</p>
<p>Redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Python、Ruby、Erlang、PHP客户端，使用很方便。</p>
<p><strong>官网</strong>：<a href="http://redis.io/" target="_blank" rel="external">http://redis.io/</a></p>
<p>&nbsp;</p>
<h1 id="u8868_u683C_u5B58_u50A8"><a href="#u8868_u683C_u5B58_u50A8" class="headerlink" title="<strong>表格存储</strong>"></a><strong>表格存储</strong></h1><p><span style="color: #f74e05;"><strong> 一、OceanBase</strong></span></p>
<p><strong>贡献者</strong>：阿里巴巴</p>
<p><strong>相关文章</strong>：<a href="http://www.36dsj.com/archives/20317" title="26页PPT解密支撑支付宝交易的分布式数据库系统——OceanBase | 36大数据" target="_blank" rel="external">26页PPT解密支撑支付宝交易的分布式数据库系统——OceanBase</a></p>
<p><strong>简介</strong>：OceanBase是一个支持海量数据的高性能分布式数据库系统，实现了数千亿条记录、数百TB数据上的跨行跨表事务，由淘宝核心系统研发部、运维、DBA、广告、应用研发等部门共同完成。在设计和实现OceanBase的时候暂时摒弃了不紧急的DBMS的功能，例如临时表，视图(view)，研发团队把有限的资源集中到关键点上，当前 OceanBase主要解决数据更新一致性、高性能的跨表读事务、范围查询、join、数据全量及增量dump、批量数据导入。</p>
<p>目前OceanBase已经应用于淘宝收藏夹，用于存储淘宝用户收藏条目和具体的商品、店铺信息，每天支持4～5千万的更新操作。等待上线的应用还包括CTU、SNS等，每天更新超过20亿，更新数据量超过2.5TB，并会逐步在淘宝内部推广。</p>
<p>OceanBase 0.3.1在Github开源，开源版本为Revision:12336。</p>
<p><strong>官网</strong>：<a href="http://alibaba.github.io/oceanbase/" target="_blank" rel="external">http://alibaba.github.io/oceanbase/</a></p>
<p><strong><span style="color: #f74e05;">二、Amazon SimpleDB</span></strong></p>
<p><strong>贡献者</strong>：亚马逊</p>
<p>Amazon SimpleDB是一个分散式数据库，以Erlang撰写。同与Amazon EC2和亚马逊的S3一样作为一项Web 服务，属于亚马逊网络服务的一部分。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1106.jpg" alt="Amazon SimpleDB"></p>
<p>正如EC2和S3，SimpleDB的按照存储量，在互联网上的传输量和吞吐量收取费用。 在2008年12月1日，亚马逊推出了新的定价策略，提供了免费1 GB的数据和25机器小时的自由层(Free Tire)。 将其中的数据转移到其他亚马逊网络服务是免费的。</p>
<p>它是一个可大规模伸缩、用 Erlang 编写的高可用数据存储。</p>
<p><strong>官网</strong>：<a href="http://aws.amazon.com/cn/simpledb/" target="_blank" rel="external">http://aws.amazon.com/cn/simpledb/</a></p>
<p><strong><span style="color: #f74e05;">三、Vertica</span></strong></p>
<p><strong>贡献者：</strong>惠普</p>
<p><strong>简介：</strong>惠普2011年2月份起始3月21号完成收购Vertica。Vertica基于列存储。基于列存储的设计相比传统面向行存储的数据库具有巨大的优势。同时Vertica支持MPP（massively parallel processing）等技术，查询数据时Vertica只需取得需要的列，而不是被选择行的所有数据，其平均性能可提高50x-1000x倍。（查询性能高速度快）</p>
<p>Vertica的设计者多次表示他们的产品围绕着高性能和高可用性设计。由于对MPP技术的支持，可提供对粒度，可伸缩性和可用性的优势。每个节点完全独立运作，完全无共享架构，降低对共享资源的系统竞争。</p>
<p>Vertica的数据库使用标准的SQL查询，同时Vertica的架构非常适合云计算，包括虚拟化，分布式多节点运行等，并且可以和Hadoop/MapReduce进行集成。</p>
<p><strong>Vertica官网</strong>：<a href="http://www.vertica.com/" target="_blank" rel="external">http://www.vertica.com/</a></p>
<p><span style="color: #f74e05;"><strong>四、Cassandra</strong></span></p>
<p><strong>贡献者</strong>：facebook</p>
<p><strong>相关文章</strong>：<a href="http://www.36dsj.com/archives/20079" title="开源分布式NoSQL数据库系统——Cassandra | 36大数据" target="_blank" rel="external">开源分布式NoSQL数据库系统——Cassandra</a>   <a href="http://www.36dsj.com/archives/7179" title="Cassandra与HBase的大数据对决 谁是胜者？ | 36大数据" target="_blank" rel="external">Cassandra与HBase的大数据对决 谁是胜者？</a></p>
<p><strong>简介</strong>：Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，集GoogleBigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身Facebook于2008将 Cassandra 开源，此后，由于Cassandra良好的可扩放性，被Digg、Twitter等知名Web 2.0网站所采纳，成为了一种流行的分布式结构化数据存储方案。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/290.jpg" alt="Cassandra"></p>
<p>Cassandra是一个混合型的非关系的数据库，类似于Google的BigTable。其主要功能比Dynamo （分布式的Key-Value存储系统）更丰富，但支持度却不如文档存储MongoDB（介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富，最像关系数据库的。支持的数据结构非常松散，是类似json的bjson格式，因此可以存储比较复杂的数据类型）。Cassandra最初由Facebook开发，后转变成了开源项目。它是一个网络社交云计算方面理想的数据库。以Amazon专有的完全分布式的Dynamo为基础，结合了Google BigTable基于列族（Column Family）的数据模型。P2P去中心化的存储。很多方面都可以称之为Dynamo 2.0。</p>
<p><strong>Cassandra官网</strong>：<a href="http://cassandra.apache.org/" target="_blank" rel="external">http://cassandra.apache.org/</a></p>
<p><strong><span style="color: #f74e05;"> 五、HyperTable</span></strong></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/347.jpg" alt="Hypertable"></p>
<p>简介：Hypertable是一个开源、高性能、可伸缩的数据库，它采用与Google的Bigtable相似的模型。在过去数年中，Google为在PC集群 上运行的可伸缩计算基础设施设计建造了三个关键部分。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/426.jpg" alt="Hypertable"></p>
<p>第一个关键的基础设施是Google File System（GFS），这是一个高可用的文件系统，提供了一个全局的命名空间。它通过跨机器（和跨机架）的文件数据复制来达到高可用性，并因此免受传统 文件存储系统无法避免的许多失败的影响，比如电源、内存和网络端口等失败。第二个基础设施是名为Map-Reduce的计算框架，它与GFS紧密协作，帮 助处理收集到的海量数据。第三个基础设施是Bigtable，它是传统数据库的替代。Bigtable让你可以通过一些主键来组织海量数据，并实现高效的 查询。Hypertable是Bigtable的一个开源实现，并且根据我们的想法进行了一些改进。</p>
<p><strong>HyperTable官网</strong>：<a href="http://hypertable.org/" target="_blank" rel="external">http://hypertable.org/</a></p>
<p><strong><span style="color: #f74e05;">六、FoundationDB</span></strong></p>
<p><strong>简介：</strong>支持ACID事务处理的NoSQL数据库，提供非常好的性能、数据一致性和操作弹性。</p>
<p>2015年1月2日，FoundationDB已经发布了其key-value数据库的3.0版本，主要专注于可伸缩性和性能上的改善。FoundationDB的CEO David Rosenthal在一篇博客上宣布了新的版本，其中展示了FoundationDB 3.0在可伸缩性方面的数据，它可以在一个32位的c3.8xlarge EC2实例上每秒写入1440万次；这在性能上是之前版本的36倍。</p>
<p>除了性能和可伸缩性的改善之外，FoundationDB 3.0还包含了对监控支持的改善。这种监控机制不仅仅是简单的机器检查，它添加了对多种潜在的硬件瓶颈的诊断，并且把那些高层级的信息整合到现有监控基础架构中。</p>
<p><strong>官网</strong>：<a href="https://foundationdb.com/" target="_blank" rel="external">https://foundationdb.com/</a></p>
<p><span style="color: #f74e05;"><strong>七：HBase</strong></span></p>
<p><strong>贡献者</strong>： Fay Chang 所撰写的“Bigtable</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/526.jpg" alt="HBase"></p>
<p><strong>简介</strong>：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。</p>
<p><strong>官网</strong>：<a href="http://hbase.apache.org/" target="_blank" rel="external">http://hbase.apache.org/</a></p>
<h1 id="u6587_u4EF6_u5B58_u50A8"><a href="#u6587_u4EF6_u5B58_u50A8" class="headerlink" title="<strong>文件存储</strong>"></a><strong>文件存储</strong></h1><p><strong><span style="color: #f75200;">一、CouchDB</span></strong></p>
<p>简介：CouchDB是用Erlang开发的面向文档的数据库系统，最近刚刚发布了1.0版本（2010年7月14日）。CouchDB不是一个传统的关系数据库，而是面向文档的数据库，其数据存储方式有点类似lucene的index文件格式，CouchDB最大的意义在于它是一个面向web应用的新一代存储系统，事实上，CouchDB的口号就是：下一代的Web应用存储系统。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/623.jpg" alt="CouchDB"></p>
<p><strong>特点：</strong></p>
<p>一、CouchDB是分布式的数据库，他可以把存储系统分布到n台物理的节点上面，并且很好的协调和同步节点之间的数据读写一致性。这当然也得靠Erlang无与伦比的并发特性才能做到。对于基于web的大规模应用文档应用，分布式可以让它不必像传统的关系数据库那样分库拆表，在应用代码层进行大量的改动。</p>
<p>二、CouchDB是面向文档的数据库，存储半结构化的数据，比较类似lucene的index结构，特别适合存储文档，因此很适合CMS，电话本，地址本等应用，在这些应用场合，文档数据库要比关系数据库更加方便，性能更好。</p>
<p>三、CouchDB支持REST API，可以让用户使用JavaScript来操作CouchDB数据库，也可以用JavaScript编写查询语句，我们可以想像一下，用AJAX技术结合CouchDB开发出来的CMS系统会是多么的简单和方便。</p>
<p>其实CouchDB只是Erlang应用的冰山一角，在最近几年，基于Erlang的应用也得到的蓬勃的发展，特别是在基于web的大规模，分布式应用领域，几乎都是Erlang的优势项目。</p>
<p><strong>官网</strong>：<a href="http://couchdb.apache.org/" target="_blank" rel="external">http://couchdb.apache.org/</a></p>
<p><span style="color: #f75200;"><strong>二、MongoDB</strong></span></p>
<p><strong>简介</strong>：MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。</p>
<p>MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。</p>
<p><strong>相关文章</strong>：<a href="http://www.36dsj.com/archives/22965" title="MongoDB的基本特性与内部构造 | 36大数据" target="_blank" rel="external">MongoDB的基本特性与内部构造</a>  <a href="http://www.36dsj.com/archives/21104" title="大数据吃香 创业公司MongoDB估值达16亿美元 | 36大数据" target="_blank" rel="external">大数据吃香 创业公司MongoDB估值达16亿美元</a></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/01/2710.jpg" alt="mongodb"></p>
<p><strong>特点</strong></p>
<p>它的特点是高性能、易部署、易使用，存储数据非常方便。主要功能特性有：</p>
<p>*面向集合存储，易存储对象类型的数据。</p>
<p>mongodb集群参考</p>
<p>mongodb集群参考</p>
<p>*模式自由。</p>
<p>*支持动态查询。</p>
<p>*支持完全索引，包含内部对象。</p>
<p>*支持查询。</p>
<p>*支持复制和故障恢复。</p>
<p>*使用高效的二进制数据存储，包括大型对象（如视频等）。</p>
<p>*自动处理碎片，以支持云计算层次的扩展性。</p>
<p>*支持RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。</p>
<p>*文件存储格式为BSON（一种JSON的扩展）。</p>
<p>*可通过网络访问。</p>
<p><strong>官网</strong>：<a href="https://www.mongodb.org/" target="_blank" rel="external">https://www.mongodb.org/</a></p>
<p><span style="color: #f75200;"><strong>三、Tachyon</strong></span></p>
<p><strong>贡献者</strong>：Haoyuan Li（李浩源）</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/725-220x150.jpg" alt="李浩源"></p>
<p><strong>简介</strong>：Tachyon是一个分布式内存文件系统，可以在集群里以访问内存的速度来访问存在tachyon里的文件。把Tachyon是架构在最底层的分布式文件存储和上层的各种计算框架之间的一种中间件。主要职责是将那些不需要落地到DFS里的文件，落地到分布式内存文件系统中，来达到共享内存，从而提高效率。同时可以减少内存冗余，GC时间等。</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/823.jpg" alt="Tachyon"></p>
<p><strong>Tachyon架构</strong></p>
<p>Tachyon的架构是传统的Master—slave架构，这里和Hadoop类似，TachyonMaster里WorkflowManager是 Master进程，因为是为了防止单点问题，通过Zookeeper做了HA，可以部署多台Standby Master。Slave是由Worker Daemon和Ramdisk构成。这里个人理解只有Worker Daemon是基于JVM的，Ramdisk是一个off heap memory。Master和Worker直接的通讯协议是Thrift。</p>
<p>下图来自Tachyon的作者Haoyuan Li：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/920.jpg" alt="Tachyon"></p>
<p><strong>下载地址</strong>：<a href="http://tachyon-project.org/https://github.com/amplab/tachyon" target="_blank" rel="external">https://github.com/amplab/tachyon</a></p>
<p><strong><span style="color: #f75200;">四、KFS</span></strong></p>
<p><strong>简介：</strong>GFS的C++开源版本，Kosmos distributed file system (KFS)是一个专门为数据密集型应用（搜索引擎，数据挖掘等）而设计的存储系统，类似于Google的GFS和Hadoop的HDFS分布式文件系统。 KFS使用C++实现，支持的客户端包括C++，Java和Python。KFS系统由三部分组成，分别是metaserver、chunkserver和client library。</p>
<p><strong>官网：</strong><a href="http://code.google.com/p/kosmosfs/" target="_blank" rel="external">http://code.google.com/p/kosmosfs/</a></p>
<p><strong><span style="color: #f75200;">五、HDFS</span></strong></p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1022.jpg" alt="大数据"></p>
<p><strong>简介</strong>：Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。它和现有的分布式文件系统有很多共同点。但同时，它和其他的分布式文件系统的区别也是很明显的。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。HDFS放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。HDFS在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。HDFS是Apache Hadoop Core项目的一部分。</p>
<p><strong>官网</strong>：<a href="http://hadoop.apache.org/" target="_blank" rel="external">http://hadoop.apache.org/</a></p>
<h1 id="u8D44_u6E90_u7BA1_u7406"><a href="#u8D44_u6E90_u7BA1_u7406" class="headerlink" title="<strong>资源管理</strong>"></a><strong>资源管理</strong></h1><p><strong><span style="color: #f75200;">一、Twitter <span class="font2">Mesos</span></span></strong></p>
<p><strong>开发者：</strong>Twitter研发人员John Oskasson</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1129.jpg" alt="Twitter Mesos"></p>
<p><strong>简介</strong>：Apache Mesos是由加州大学伯克利分校的AMPLab首先开发的一款开源群集管理软件，支持Hadoop、ElasticSearch、Spark、Storm 和Kafka等架构，由于其开源性质越来越受到一些大型云计算公司的青睐，例如Twitter、Facebook等。</p>
<p><strong>参考文章</strong>：<a href="http://www.csdn.net/article/2014-02-24/2818520-Cloud-Mesosphere-Mesos-Hadoop-Spark" target="_blank" rel="external">Mesos渐入主流,Twitter模式有望“无限复制”-CSDN.NET</a></p>
<p><strong>官网</strong>：<a href="http://mesos.apache.org/" target="_blank" rel="external">http://mesos.apache.org/</a></p>
<p><span style="color: #f75200;"><strong>二、Hadoop Yarn</strong></span></p>
<p>Hadoop 新 MapReduce 框架 Yarn。为从根本上解决旧 MapReduce 框架的性能瓶颈，促进 Hadoop 框架的更长远发展，从 0.23.0 版本开始，Hadoop 的 MapReduce 框架完全重构，发生了根本的变化。新的 Hadoop MapReduce 框架命名为 MapReduceV2 或者叫 Yarn，其架构图如下图所示：</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/1222.jpg" alt="Hadoop Yarn"></p>
<p>Yarn 框架相对于老的 MapReduce 框架什么优势呢？我们可以看到：</p>
<p>1、这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。</p>
<p>2、在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。</p>
<p>3、对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。</p>
<p>4、老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的行状况，如果出问题，会将其在其他机器上重启。</p>
<p>5、Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。</p>
<p>官网：<a href="http://hadoop.apache.org/" target="_blank" rel="external">http://hadoop.apache.org/</a></p>
<hr>
<p>第二部分将整合大数据日志收集系统、消息系统、集群管理、基础设施、监控管理等开源工具。并将于3月12日发布，尽请期待。</p>
<p><a href="http://www.36dsj.com/archives/24852" target="_blank" rel="external">http://www.36dsj.com/archives/24852</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/01/05/algo/lib/big_data_lib/" data-id="cilxtsd51006kwfjiz5xss1t6" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/01/05/algo/lib/big_data_lib/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-algo/lib/java_ml_lib" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/05/algo/lib/java_ml_lib/">25个Java机器学习工具&amp;库</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/01/05/algo/lib/java_ml_lib/">
      <time datetime="2016-01-05T07:07:12.000Z" itemprop="datePublished">2016-01-05</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <ol>
<li><p>Weka集成了数据挖掘工作的机器学习算法。这些算法可以直接应用于一个数据集上或者你可以自己编写代码来调用。Weka包括一系列的工具，如数据预处理、分类、回归、聚类、关联规则以及可视化。</p>
</li>
<li><p>Massive Online Analysis（MOA）是一个面向数据流挖掘的流行开源框架，有着非常活跃的成长社区。它包括一系列的机器学习算法（分类、回归、聚类、异常检测、概念漂移检测和推荐系统）和评估工具。关联了WEKA项目，MOA也是用Java编写的，其扩展性更强。</p>
</li>
<li><p>MEKA项目提供了一个面向多标签学习和评价方法的开源实现。在多标签分类中，我们要预测每个输入实例的多个输出变量。这与“普通”情况下只涉及一个单一目标变量的情形不同。此外，MEKA基于WEKA的机器学习工具包。</p>
</li>
<li><p>Advanced Data mining And Machine learning System（ADAMS）是一种新型的柔性工作流引擎，旨在迅速建立并保持真实世界的复杂知识流，它是基于GPLv3发行的。</p>
</li>
<li><p>Environment for Developing KDD-Applications Supported by Index-Structure（ELKI）是一款基于Java的开源（AGPLv3）数据挖掘软件。ELKI主要集中于算法研究，重点研究聚类分析中的无监督方法和异常检测。</p>
</li>
<li><p>Mallet是一个基于Java的面向文本文件的机器学习工具包。Mallet支持分类算法，如最大熵、朴素贝叶斯和决策树分类。</p>
</li>
<li><p>Encog是一个先进的机器学习框架，集成了支持向量机（SVM）、人工神经网络、遗传算法、贝叶斯网络、隐马尔可夫模型（HMM）、遗传编程和遗传算法。</p>
</li>
<li><p>Datumbox机器学习框架是一个用Java编写的开源框架，允许快速地开发机器学习和统计应用。该框架的核心重点包括大量的机器学习算法以及统计测试，能够处理中等规模的数据集。</p>
</li>
<li><p>Deeplearning4j是使用Java和Scala编写的第一个商业级的、开源的、分布式深入学习库。其设计的目的是用于商业环境中，而不是作为一个研究工具。</p>
</li>
<li><p>Mahout是一个内置算法的机器学习框架。Mahout-Samsara帮助人们创建他们自己的数学，并提供了一些现成的算法实现。</p>
</li>
<li><p>Rapid Miner是德国多特蒙特技术大学开发的。它为开发者开发应用程序提供了一个GUI（图形用户界面）和Java API。它还提供了一些机器学习算法，用来做数据处理、可视化以及建模。</p>
</li>
<li><p>Apache SAMOA是一个机器学习（ML）框架，内嵌面向分布式流ML算法的编程抽象，并且允许在没有直接处理底层分布式流处理引擎（DSPEe，如Apache Storm、Apache S4和Apache samza）复杂性的情况下，开发新的ML算法。用户可以开发分布式流ML算法，而且可以在多个DSPEs上执行。</p>
</li>
<li><p>Neuroph通过提供支持创建、训练和保存神经网络的Java网络库和GUI工具，简化了神经网络开发。</p>
</li>
<li><p>Oryx 2是一个建立在Apache Spark和Apache Kafka的Lambda架构实现，但随着实时大规模机器学习而逐渐开始专业化。这是一个用于构建应用程序的框架，但也包括打包，以及面向协同过滤、分类、回归和聚类的端到端的应用程序。</p>
</li>
<li><p>Stanford Classifier是一个机器学习工具，它可以将数据项归置到一个类别。一个概率分类器，比如这个，它可以对一个数据项给出类分配的概率分布。该软件是最大熵分类器的一个Java实现。</p>
</li>
<li><p>io是一个Retina API，有着快速精确的类似大脑的自然语言处理算法。</p>
</li>
<li><p>JSAT是一个快速入门的机器学习库。该库是我在业余时间开发的，基于GPL3发行的。库中的一部分内容可自主学习，例如所有的代码都是独立的。JSAT没有外部依赖，而且是纯Java编写的。</p>
</li>
<li><p>N-Dimensional Arrays for Java(ND4J)是一个用于JVM的科学计算库。它们是用来在生产环境中使用的，这表明例程的设计是以最小的内存需求来运行的。</p>
</li>
<li><p>Java Machine Learning Library（Java机器学习库）是一系列机器学习算法的相关实现。这些算法，无论是源代码还是文档，都编写的很出色。其主要语言是Java。</p>
</li>
<li><p>Java-ML是一个使用Java编写的一系列机器学习算法的Java API。它只提供了一个标准的算法接口。</p>
</li>
<li><p>MLlib (Spark)是Apache Spark的可扩展机器学习库。虽然是Java，但该库与平台还支持Java，Scala和Python绑定。此库是最新的，并且算法很多。</p>
</li>
<li><p>H2O是用于智能应用的机器学习API。它在大数据上对统计学、机器学习和数学进行了规模化。H2O可扩展，开发者可以在核心部分使用简单的数学知识。</p>
</li>
<li><p>WalnutiQ是人脑部分面向对象模型，有着理论常用的学习算法（正在向简单强烈的情感人工智能模型方向研究）。</p>
</li>
<li><p>RankLib是一个排名学习算法库。目前已经实现八种流行的算法。</p>
</li>
<li><p>htm.java（基于Java的Hierarchical Temporal Memory算法实现）是一个面向智能计算的Numenta平台的Java接口。源码</p>
</li>
</ol>
<p>原文： <a href="http://bigdataanalyticsnews.com/25-java-machine-learning-tools-libraries/" target="_blank" rel="external">http://bigdataanalyticsnews.com/25-java-machine-learning-tools-libraries/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/01/05/algo/lib/java_ml_lib/" data-id="cilxtsd4v006cwfjipr5gjttr" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/01/05/algo/lib/java_ml_lib/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-algo/graph/textrank" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/05/algo/graph/textrank/">使用TextRank算法为文本生成关键字和摘要</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/01/05/algo/graph/textrank/">
      <time datetime="2016-01-05T06:33:26.000Z" itemprop="datePublished">2016-01-05</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>TextRank算法基于PageRank，用于为文本生成关键字和摘要。其论文是：<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mihalcea R, Tarau P. TextRank: Bringing <span class="keyword">order</span> <span class="title">into</span> texts[C]. Association for Computational Linguistics, <span class="number">2004</span>.</span><br></pre></td></tr></table></figure></p>
<h3 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h3><hr>
<p>PageRank最开始用来计算网页的重要性。整个www可以看作一张有向图图，节点是网页。如果网页A存在到网页B的链接，那么有一条从网页A指向网页B的有向边。</p>
<p>构造完图后，使用下面的公式：<br><img src="/images/algo/pagerank.png" alt=""><br>S(Vi)是网页i的中重要性（PR值）。d是阻尼系数，一般设置为0.85。In(Vi)是存在指向网页i的链接的网页集合。Out(Vj)是网页j中的链接存在的链接指向的网页的集合。|Out(Vj)|是集合中元素的个数。</p>
<p>PageRank需要使用上面的公式多次迭代才能得到结果。初始时，可以设置每个网页的重要性为1。上面公式等号左边计算的结果是迭代后网页i的PR值，等号右边用到的PR值全是迭代前的。</p>
<p>举个例子：<br><img src="/images/algo/pagerank1.png" alt=""><br>上图表示了三张网页之间的链接关系，直觉上网页A最重要。可以得到下面的表：</p>
<p>结束\起始   A   B   C<br>A           0   1   1<br>B           0   0   0<br>C           0   0   0</p>
<p>横栏代表其实的节点，纵栏代表结束的节点。若两个节点间有链接关系，对应的值为1。 </p>
<p>根据公式，需要将每一竖栏归一化（每个元素/元素之和），归一化的结果是： </p>
<p>结束\起始   A   B   C<br>A           0   1   1<br>B           0   0   0<br>C           0   0   0</p>
<p>上面的结果构成矩阵M。我们用matlab迭代100次看看最后每个网页的重要性：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">M = <span class="matrix">[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> </span><br><span class="line">    <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">    <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span>;</span><br><span class="line">PR = <span class="matrix">[<span class="number">1</span>; <span class="number">1</span> ; <span class="number">1</span>]</span>;</span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:<span class="number">100</span></span><br><span class="line">    PR = <span class="number">0.15</span> + <span class="number">0.85</span>*M*PR;</span><br><span class="line">    <span class="built_in">disp</span>(iter);</span><br><span class="line">    <span class="built_in">disp</span>(PR);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<p>运行结果（省略部分）：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">95</span></span><br><span class="line"> <span class="number">0.4050</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">96</span></span><br><span class="line"> <span class="number">0.4050</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">97</span></span><br><span class="line"> <span class="number">0.4050</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">98</span></span><br><span class="line"> <span class="number">0.4050</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">99</span></span><br><span class="line"> <span class="number">0.4050</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"><span class="number">100</span></span><br><span class="line"> <span class="number">0.4050</span></span><br><span class="line"> <span class="number">0.1500</span></span><br><span class="line"> <span class="number">0.1500</span></span><br></pre></td></tr></table></figure></p>
<p>最终A的PR值为0.4050，B和C的PR值为0.1500。 </p>
<p>如果把上面的有向边看作无向的（其实就是双向的），那么：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">M = <span class="matrix">[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> </span><br><span class="line">    <span class="number">0.5</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">    <span class="number">0.5</span> <span class="number">0</span> <span class="number">0</span>]</span>;</span><br><span class="line">PR = <span class="matrix">[<span class="number">1</span>; <span class="number">1</span> ; <span class="number">1</span>]</span>;</span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:<span class="number">100</span></span><br><span class="line">    PR = <span class="number">0.15</span> + <span class="number">0.85</span>*M*PR;</span><br><span class="line">    <span class="built_in">disp</span>(iter);</span><br><span class="line">    <span class="built_in">disp</span>(PR);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<p>运行结果（省略部分）：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">.....</span><br><span class="line">    <span class="number">98</span></span><br><span class="line">    <span class="number">1.4595</span></span><br><span class="line">    <span class="number">0.7703</span></span><br><span class="line">    <span class="number">0.7703</span></span><br><span class="line">    <span class="number">99</span></span><br><span class="line">    <span class="number">1.4595</span></span><br><span class="line">    <span class="number">0.7703</span></span><br><span class="line">    <span class="number">0.7703</span></span><br><span class="line">   <span class="number">100</span></span><br><span class="line">    <span class="number">1.4595</span></span><br><span class="line">    <span class="number">0.7703</span></span><br><span class="line">    <span class="number">0.7703</span></span><br></pre></td></tr></table></figure></p>
<p>依然能判断出A、B、C的重要性。 </p>
<h3 id="u4F7F_u7528TextRank_u63D0_u53D6_u5173_u952E_u5B57"><a href="#u4F7F_u7528TextRank_u63D0_u53D6_u5173_u952E_u5B57" class="headerlink" title="使用TextRank提取关键字"></a>使用TextRank提取关键字</h3><hr>
<p>将原文本拆分为句子，在每个句子中过滤掉停用词（可选），并只保留指定词性的单词（可选）。由此可以得到句子的集合和单词的集合。</p>
<p>每个单词作为pagerank中的一个节点。设定窗口大小为k，假设一个句子依次由下面的单词组成：</p>
<p>w1, w2, w3, w4, w5, …, wn<br>w1, w2, …, wk、w2, w3, …,wk+1、w3, w4, …,wk+2等都是一个窗口。在一个窗口中的任两个单词对应的节点之间存在一个无向无权的边。</p>
<p>基于上面构成图，可以计算出每个单词节点的重要性。最重要的若干单词可以作为关键词。</p>
<h3 id="u4F7F_u7528TextRank_u63D0_u53D6_u5173_u952E_u77ED_u8BED"><a href="#u4F7F_u7528TextRank_u63D0_u53D6_u5173_u952E_u77ED_u8BED" class="headerlink" title="使用TextRank提取关键短语"></a>使用TextRank提取关键短语</h3><hr>
<p>参照“使用TextRank提取关键词”提取出若干关键词。若原文本中存在若干个关键词相邻的情况，那么这些关键词可以构成一个关键短语。</p>
<p>例如，在一篇介绍“支持向量机”的文章中，可以找到三个关键词支持、向量、机，通过关键短语提取，可以得到支持向量机。</p>
<h3 id="u4F7F_u7528TextRank_u63D0_u53D6_u6458_u8981"><a href="#u4F7F_u7528TextRank_u63D0_u53D6_u6458_u8981" class="headerlink" title="使用TextRank提取摘要"></a>使用TextRank提取摘要</h3><hr>
<p>将每个句子看成图中的一个节点，若两个句子之间有相似性，认为对应的两个节点之间有一个无向有权边，权值是相似度。</p>
<p>通过pagerank算法计算得到的重要性最高的若干句子可以当作摘要。</p>
<p>论文中使用下面的公式计算两个句子Si和Sj的相似度：<br><img src="/images/algo/textrank.png" alt=""><br>分子是在两个句子中都出现的单词的数量。|Si|是句子i的单词数。</p>
<p>由于是有权图，PageRank公式略做修改：<br><img src="/images/algo/textrank2.png" alt=""></p>
<h3 id="u5B9E_u73B0TextRank"><a href="#u5B9E_u73B0TextRank" class="headerlink" title="实现TextRank"></a>实现TextRank</h3><hr>
<p>因为要用测试多种情况，所以自己实现了一个基于Python2.7的TextRank针对中文文本的库TextRank4ZH。位于：</p>
<p><a href="https://github.com/someus/TextRank4ZH" target="_blank" rel="external">https://github.com/someus/TextRank4ZH</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/01/05/algo/graph/textrank/" data-id="cilxtsd54006owfjivx5s0f4y" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/01/05/algo/graph/textrank/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pagerank/">pagerank</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-dev/python/python_tools" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/28/dev/python/python_tools/">Python 工具</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/12/28/dev/python/python_tools/">
      <time datetime="2015-12-28T02:19:56.000Z" itemprop="datePublished">2015-12-28</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/dev/">dev</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="u5305_u7BA1_u7406"><a href="#u5305_u7BA1_u7406" class="headerlink" title="包管理"></a>包管理</h2><hr>
<p>Python世界最棒的地方之一，就是大量的第三方程序包。同样，管理这些包也非常容易。按照惯例，会在 requirements.txt 文件中列出项目所需要的包。每个包占一行，通常还包含版本号。这里有一个例子，本博客使用Pelican：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pelican==<span class="number">3.3</span></span><br><span class="line">Markdown</span><br><span class="line">pelican-extended-sitemap==<span class="number">1.0</span><span class="number">.0</span></span><br></pre></td></tr></table></figure></p>
<p>Python 程序包有一个缺陷是，它们默认会进行全局安装。我们将要使用一个工具，使我们每个项目都有一个独立的环境，这个工具叫virtualenv。我们同样要安装一个更高级的包管理工具，叫做pip，他可以和virtualenv配合工作。</p>
<p>首先，我们需要安装pip。大多数python安装程序已经内置了easy_install（python默认的包管理工具），所以我们就使用easy_install pip来安装pip。这应该是你最后一次使用easy_install 了。如果你并没有安装easy_install ，在linux系统中，貌似从python-setuptools 包中可以获得。</p>
<p>如果你使用的Python版本高于等于3.3， 那么Virtualenv 已经是标准库的一部分了，所以没有必要再去安装它了。</p>
<p>下一步，你希望安装virtualenv和virtualenvwrapper。Virtualenv使你能够为每个项目创造一个独立的环境。尤其是当你的不同项目使用不同版本的包时，这一点特别有用。Virtualenv wrapper 提供了一些不错的脚本，可以让一些事情变得容易。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install virtualenvwrapper</span><br></pre></td></tr></table></figure>
<p>当virtualenvwrapper安装后，它会把virtualenv列为依赖包，所以会自动安装。</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">打开一个新的<span class="keyword">shell</span>，输入mkvirtualenv <span class="keyword">test</span> 。如果你打开另外一个<span class="keyword">shell</span>，则你就不在这个virtualenv中了，你可以通过workon <span class="keyword">test</span> 来启动。如果你的工作完成了，可以使用deactivate 来停用。</span><br></pre></td></tr></table></figure>
<h2 id="IPython"><a href="#IPython" class="headerlink" title="IPython"></a>IPython</h2><hr>
<p>IPython是标准Python交互式的编程环境的一个替代品，支持自动补全，文档快速访问，以及标准交互式编程环境本应该具备的很多其他功能。</p>
<p>当你处在一个虚拟环境中的时候，可以很简单的使用pip install ipython 来进行安装，在命令行中使用ipython 来启动</p>
<h2 id="u6D4B_u8BD5"><a href="#u6D4B_u8BD5" class="headerlink" title="测试"></a>测试</h2><hr>
<p>我推荐使用nose或是py.test。我大部分情况下用nose。它们基本上是类似的。我将讲解nose的一些细节。</p>
<p>这里有一个人为创建的可笑的使用nose进行测试的例子。在一个以test<em>开头的文件中的所有以test</em>开头的函数，都会被调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_equality</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="keyword">True</span> == <span class="keyword">False</span></span><br></pre></td></tr></table></figure>
<p>不出所料，当运行nose的时候，我们的测试没有通过。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(test)jhaddad@jons-mac-pro ~VIRTUAL_ENV/src$ nosetests              </span><br><span class="line">F</span><br><span class="line">======================================================================</span><br><span class="line">FAIL: test_nose_example.test_equality</span><br><span class="line"><span class="comment">----------------------------------------------------------------------</span></span><br><span class="line">Traceback (most recent <span class="operator"><span class="keyword">call</span> <span class="keyword">last</span>):</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/Users/jhaddad/.virtualenvs/test/lib/python2.7/site-packages/nose/case.py"</span>, line <span class="number">197</span>, <span class="keyword">in</span> runTest</span><br><span class="line">    <span class="keyword">self</span>.<span class="keyword">test</span>(*<span class="keyword">self</span>.arg)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/Users/jhaddad/.virtualenvs/test/src/test_nose_example.py"</span>, line <span class="number">3</span>, <span class="keyword">in</span> test_equality</span><br><span class="line">    assert <span class="literal">True</span> == <span class="literal">False</span></span><br><span class="line">AssertionError</span><br><span class="line"> </span><br><span class="line"><span class="comment">----------------------------------------------------------------------</span></span></span><br></pre></td></tr></table></figure>
<p>nose.tools中同样也有一些便捷的方法可以调用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nose.tools <span class="keyword">import</span> assert_true</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_equality</span><span class="params">()</span>:</span></span><br><span class="line">    assert_true(<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>如果你想使用更加类似JUnit的方法，也是可以的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nose.tools <span class="keyword">import</span> assert_true</span><br><span class="line"><span class="keyword">from</span> unittest <span class="keyword">import</span> TestCase</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExampleTest</span><span class="params">(TestCase)</span>:</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUp</span><span class="params">(self)</span>:</span> </span><br><span class="line"><span class="comment"># setUp &amp; tearDown are both available</span></span><br><span class="line">        self.blah = <span class="keyword">False</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_blah</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.assertTrue(self.blah)</span><br></pre></td></tr></table></figure>
<p>开始测试：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(test)jhaddad@jons-mac-pro ~VIRTUAL_ENV/src$ nosetests                            </span><br><span class="line">F</span><br><span class="line">======================================================================</span><br><span class="line">FAIL: test_blah (test_nose_example.ExampleTest)</span><br><span class="line"><span class="comment">----------------------------------------------------------------------</span></span><br><span class="line">Traceback (most recent <span class="operator"><span class="keyword">call</span> <span class="keyword">last</span>):</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"/Users/jhaddad/.virtualenvs/test/src/test_nose_example.py"</span>, line <span class="number">11</span>, <span class="keyword">in</span> test_blah</span><br><span class="line">    <span class="keyword">self</span>.assertTrue(<span class="keyword">self</span>.blah)</span><br><span class="line">AssertionError: <span class="literal">False</span> <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">true</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">----------------------------------------------------------------------</span></span><br><span class="line">Ran <span class="number">1</span> <span class="keyword">test</span> <span class="keyword">in</span> <span class="number">0.003</span>s</span><br><span class="line"> </span><br><span class="line"><span class="keyword">FAILED</span> (failures=<span class="number">1</span>)</span></span><br></pre></td></tr></table></figure>
<p>卓越的Mock库包含在Python 3 中，但是如果你在使用Python 2，可以使用pypi来获取。这个测试将进行一个远程调用，但是这次调用将耗时10s。这个例子显然是人为捏造的。我们使用mock来返回样本数据而不是真正的进行调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> mock</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> mock <span class="keyword">import</span> patch</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sweetness</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">slow_remote_call</span><span class="params">(self)</span>:</span></span><br><span class="line">        sleep(<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"some_data"</span> </span><br><span class="line"><span class="comment"># lets pretend we get this back from our remote api call</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_long_call</span><span class="params">()</span>:</span></span><br><span class="line">    s = Sweetness()</span><br><span class="line">    result = s.slow_remote_call()</span><br><span class="line">    <span class="keyword">assert</span> result == <span class="string">"some_data"</span></span><br></pre></td></tr></table></figure>
<p>当然，我们的测试需要很长的时间。</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">test</span>)jhaddad@jons-<span class="keyword">mac</span>-<span class="keyword">pro</span> ~VIRTUAL_ENV/src$ nosetests test_mock.py            </span><br><span class="line">Ran 1 <span class="keyword">test</span> <span class="keyword">in</span> 10.001s</span><br><span class="line"> </span><br><span class="line">OK</span><br></pre></td></tr></table></figure>
<p>太慢了！因此我们会问自己，我们在测试什么？我们需要测试远程调用是否有用，还是我们要测试当我们获得数据后要做什么？大多数情况下是后者。让我们摆脱这个愚蠢的远程调用吧：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> mock</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> mock <span class="keyword">import</span> patch</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sweetness</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">slow_remote_call</span><span class="params">(self)</span>:</span></span><br><span class="line">        sleep(<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"some_data"</span> </span><br><span class="line"><span class="comment"># lets pretend we get this back from our remote api call</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_long_call</span><span class="params">()</span>:</span></span><br><span class="line">    s = Sweetness()</span><br><span class="line">    <span class="keyword">with</span> patch.object(s, <span class="string">"slow_remote_call"</span>, return_value=<span class="string">"some_data"</span>):</span><br><span class="line">        result = s.slow_remote_call()</span><br><span class="line">    <span class="keyword">assert</span> result == <span class="string">"some_data"</span></span><br></pre></td></tr></table></figure>
<p>好吧，让我们再试一次：</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(test)jhaddad@jons-mac-pro ~VIRTUAL<span class="emphasis">_ENV/src$ nosetests test_</span>mock.py                     </span><br><span class="line"><span class="header">.</span><br><span class="line">----------------------------------------------------------------------</span></span><br><span class="line">Ran 1 test in 0.001s</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>
<p>好多了。记住，这个例子进行了荒唐的简化。就我个人来讲，我仅仅会忽略从远程系统的调用，而不是我的数据库调用。</p>
<p>nose-progressive是一个很好的模块，它可以改善nose的输出，让错误在发生时就显示出来，而不是留到最后。如果你的测试需要花费一定的时间，那么这是件好事。<br>pip install nose-progressive 并且在你的nosetests中添加–with-progressive</p>
<h2 id="u8C03_u8BD5"><a href="#u8C03_u8BD5" class="headerlink" title="调试"></a>调试</h2><hr>
<p>iPDB是一个极好的工具，我已经用它查出了很多匪夷所思的bug。pip install ipdb 安装该工具，然后在你的代码中import ipdb; ipdb.set_trace()，然后你会在你的程序运行<br>时，获得一个很好的交互式提示。它每次执行程序的一行并且检查变量。</p>
<h2 id="Gevent"><a href="#Gevent" class="headerlink" title="Gevent"></a>Gevent</h2><hr>
<p>Gevent 是一个很好的库，封装了Greenlets，使得Python具备了异步调用的功能。是的，非常棒。我最爱的功能是Pool，它抽象了异步调用部分，给我们提供了可以简单使用的途径，一个异步的map()函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gevent <span class="keyword">import</span> monkey</span><br><span class="line">monkey.patch_all()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep, time</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch_url</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Fetching %s"</span> % url</span><br><span class="line">    sleep(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Done fetching %s"</span> % url</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> gevent.pool <span class="keyword">import</span> Pool</span><br><span class="line"> </span><br><span class="line">urls = [<span class="string">"http://test.com"</span>, <span class="string">"http://bacon.com"</span>, <span class="string">"http://eggs.com"</span>]</span><br><span class="line"> </span><br><span class="line">p = Pool(<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">start = time()</span><br><span class="line">p.map(fetch_url, urls)</span><br><span class="line"><span class="keyword">print</span> time() - start</span><br></pre></td></tr></table></figure>
<p>非常重要的是，需要注意这段代码顶部对gevent monkey进行的补丁，如果没有它的话，就不能正确的运行。如果我们让Python连续调用 fetch_url 3次，通常我们期望这个过程花费30秒时间。使用gevent：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(test)jhaddad<span class="annotation">@jons</span>-mac-pro ~VIRTUAL_ENV/src$ python g.py                                                                                                                                    </span><br><span class="line">Fetching <span class="string">http:</span><span class="comment">//test.com</span></span><br><span class="line">Fetching <span class="string">http:</span><span class="comment">//bacon.com</span></span><br><span class="line">Fetching <span class="string">http:</span><span class="comment">//eggs.com</span></span><br><span class="line">Done fetching <span class="string">http:</span><span class="comment">//test.com</span></span><br><span class="line">Done fetching <span class="string">http:</span><span class="comment">//bacon.com</span></span><br><span class="line">Done fetching <span class="string">http:</span><span class="comment">//eggs.com</span></span><br><span class="line"><span class="number">10.001791954</span></span><br></pre></td></tr></table></figure></p>
<p>如果你有很多数据库调用或是从远程URLs获取，这是非常有用的。我并不是很喜欢回调函数，所以这一抽象对我来说效果很好。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/12/28/dev/python/python_tools/" data-id="cilxtsd2w0039wfjirmw0zwe3" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/12/28/dev/python/python_tools/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/2/">&laquo; 上一页</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/4/">下一页 &raquo;</a>
      </nav>
    </section>
      
        <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul id="recent-post" class="">
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/03/18/dev/web/python_mysql_code/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/03/18/dev/web/python_mysql_code/" class="title">Python mysql 编码问题</a></p>
              <p class="item-date"><time datetime="2016-03-18T04:19:56.000Z" itemprop="datePublished">2016-03-18</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/03/18/dev/python/python_mysql/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/03/18/dev/python/python_mysql/" class="title">Python MySQLdb</a></p>
              <p class="item-date"><time datetime="2016-03-18T02:19:56.000Z" itemprop="datePublished">2016-03-18</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/03/10/dev/python/python_logging/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/03/10/dev/python/python_logging/" class="title">Python日志输出——logging模块</a></p>
              <p class="item-date"><time datetime="2016-03-10T02:19:56.000Z" itemprop="datePublished">2016-03-10</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/03/01/algo/ml/18/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
              <p class="item-title"><a href="/2016/03/01/algo/ml/18/" class="title">18大经典数据挖掘算法小结</a></p>
              <p class="item-date"><time datetime="2016-02-29T16:00:00.000Z" itemprop="datePublished">2016-03-01</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/02/24/dev/web/fcgi/" class="thumbnail">
  
    <span style="background-image:url(/images/other/fcgi.png
)" alt="FastCGI 工作原理分析" class="thumbnail-image"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/web/">web</a></p>
              <p class="item-title"><a href="/2016/02/24/dev/web/fcgi/" class="title">FastCGI 工作原理分析</a></p>
              <p class="item-date"><time datetime="2016-02-24T05:19:56.000Z" itemprop="datePublished">2016-02-24</time></p>
            </div>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hash/">Hash</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Photo/">Photo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SQL/">SQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ads/">ads</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c++</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/dev/">dev</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/github/">github</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/internet/">internet</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/system/">system</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/travel/">travel</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apache/">Apache</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bandits/">Bandits</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FlatBuffers/">FlatBuffers</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Google/">Google</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Granger-causality/">Granger causality</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTTPS/">HTTPS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/">MapReduce</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mock/">Mock</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Monument-Vallay/">Monument Vallay</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mysql/">Mysql</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PPTP-vpn/">PPTP, vpn</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Photoshop/">Photoshop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shadowsocks/">Shadowsocks</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ad/">ad</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/apache/">apache</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blade/">blade</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crontab/">crontab</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/falsk-restful/">falsk, restful</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/font/">font</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/">github</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/">go</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hashmap/">hashmap</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux-ldd-依赖关系/">linux, ldd, 依赖关系</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lucene/">lucene</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nio/">nio</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pagerank/">pagerank</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/photo/">photo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/swift-llvm/">swift, llvm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/前端/">前端</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/广告/">广告</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开源，许可/">开源，许可</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/澳门/">澳门</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/监控，zabbix/">监控，zabbix</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/贝叶斯/">贝叶斯</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Apache/" style="font-size: 10px;">Apache</a> <a href="/tags/Bandits/" style="font-size: 12.5px;">Bandits</a> <a href="/tags/FlatBuffers/" style="font-size: 10px;">FlatBuffers</a> <a href="/tags/Google/" style="font-size: 10px;">Google</a> <a href="/tags/Granger-causality/" style="font-size: 10px;">Granger causality</a> <a href="/tags/HTTPS/" style="font-size: 10px;">HTTPS</a> <a href="/tags/MapReduce/" style="font-size: 10px;">MapReduce</a> <a href="/tags/Mock/" style="font-size: 10px;">Mock</a> <a href="/tags/Monument-Vallay/" style="font-size: 10px;">Monument Vallay</a> <a href="/tags/Mysql/" style="font-size: 12.5px;">Mysql</a> <a href="/tags/PPTP-vpn/" style="font-size: 12.5px;">PPTP, vpn</a> <a href="/tags/Photoshop/" style="font-size: 10px;">Photoshop</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/ad/" style="font-size: 10px;">ad</a> <a href="/tags/apache/" style="font-size: 10px;">apache</a> <a href="/tags/blade/" style="font-size: 10px;">blade</a> <a href="/tags/crontab/" style="font-size: 10px;">crontab</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/elasticsearch/" style="font-size: 12.5px;">elasticsearch</a> <a href="/tags/falsk-restful/" style="font-size: 10px;">falsk, restful</a> <a href="/tags/font/" style="font-size: 10px;">font</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/go/" style="font-size: 20px;">go</a> <a href="/tags/hashmap/" style="font-size: 10px;">hashmap</a> <a href="/tags/linux-ldd-依赖关系/" style="font-size: 10px;">linux, ldd, 依赖关系</a> <a href="/tags/lucene/" style="font-size: 10px;">lucene</a> <a href="/tags/nio/" style="font-size: 10px;">nio</a> <a href="/tags/pagerank/" style="font-size: 10px;">pagerank</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/python/" style="font-size: 17.5px;">python</a> <a href="/tags/swift-llvm/" style="font-size: 10px;">swift, llvm</a> <a href="/tags/前端/" style="font-size: 10px;">前端</a> <a href="/tags/广告/" style="font-size: 12.5px;">广告</a> <a href="/tags/开源，许可/" style="font-size: 10px;">开源，许可</a> <a href="/tags/澳门/" style="font-size: 10px;">澳门</a> <a href="/tags/监控，zabbix/" style="font-size: 10px;">监控，zabbix</a> <a href="/tags/贝叶斯/" style="font-size: 10px;">贝叶斯</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">三月 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">六月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">二月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">十一月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">十月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">六月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">十一月 2013</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
  <div id="toTop" class="fa fa-chevron-up"></div>
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Li Jingpeng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
    </div>
  </div>
</footer>
    

<script type="text/javascript">
  var duoshuoQuery = {short_name:"lijingpeng"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>


<script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>