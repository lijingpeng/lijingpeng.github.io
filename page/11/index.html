<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Frank</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="计算机 网络 互联网">
<meta property="og:type" content="website">
<meta property="og:title" content="Frank">
<meta property="og:url" content="http://www.notehub.cn/page/11/index.html">
<meta property="og:site_name" content="Frank">
<meta property="og:description" content="计算机 网络 互联网">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Frank">
<meta name="twitter:description" content="计算机 网络 互联网">
  
  
    <link rel="icon" href="favicon.png">
  
  <link href='//fonts.useso.com/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
  <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css" type="text/css">
  

  
</head>
<body>
  <div id="container">
    <header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="/" id="logo"><i class="logo" style="background-image: url(/css/images/logo.jpg)"></i><span class="site-title">Frank</span></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/.">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      
        <nav id="sub-nav">
          <div class="profile" id="profile-nav">
            <a id="profile-anchor" href="javascript:;"><img class="avatar" src="/css/images/logo.png"><i class="fa fa-caret-down"></i></a>
          </div>
        </nav>
      
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"> </button><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
      </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tr>
        
          <td><a class="main-nav-link" href="/.">Home</a></td>
        
          <td><a class="main-nav-link" href="/archives">Archives</a></td>
        
          <td><a class="main-nav-link" href="/categories">Categories</a></td>
        
          <td><a class="main-nav-link" href="/tags">Tags</a></td>
        
          <td><a class="main-nav-link" href="/about">About</a></td>
        
        <td>
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
        </td>
      </tr>
    </table>
  </div>
</header>

    <div class="outer">
      
        <aside id="profile">
  <div class="inner profile-inner">
    <div class="base-info profile-block">
      <img id="avatar" src="/css/images/logo.png">
      <h2 id="name">Li Jingpeng</h2>
      <!-- <h3 id="title">undefined</h3> -->
      <span id="location"><i class="fa fa-map-marker"></i>Hangzhou, China</span>
      <a id="follow" href="Https://weibo.com/329299516">关注我</a>
    </div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        81
        <span>文章</span>
      </div>
      <div class="article-info-block">
        37
        <span>标签</span>
      </div>
    </div>
    
    <div class="contact-info profile-block">
      <table class="contact-list">
        <tr>
          
          <td><a href="https://github.com/lijingpeng" target="_blank" title="github"><i class="fa fa-github"></i></a></td>
          
          <td><a href="/#" target="_blank" title="twitter"><i class="fa fa-twitter"></i></a></td>
          
          <td><a href="/#" target="_blank" title="facebook"><i class="fa fa-facebook"></i></a></td>
          
          <td><a href="/me@lijingpeng.org" target="_blank" title="email"><i class="fa fa-email"></i></a></td>
          
          <td><a href="/atom.xml" target="_blank" title="rss"><i class="fa fa-rss"></i></a></td>
          
        </tr>
      </table>
    </div>
    
    
  </div>
</aside>

      
      <section id="main">
      <article id="post-algo/beta-a-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/beta-a-md/">二项分布和Beta分布</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/beta-a-md/">
      <time datetime="2015-09-03T06:33:26.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br></pre></td></tr></table></figure>
<h2 id="u4E8C_u9879_u5206_u5E03"><a href="#u4E8C_u9879_u5206_u5E03" class="headerlink" title="二项分布"></a>二项分布</h2><hr>
<p>　　在概率论和统计学中，二项分布是n个独立的[是/非]试验中成功的次数的离散概率分布，其中每次试验的成功概率为$p$。举两个例子就很容易理解二项分布的含义了：</p>
<ul>
<li>抛一次硬币出现正面的概率是0.5($p$)，抛10(n)次硬币，出现k次正面的概率。</li>
<li>掷一次骰子出现六点的概率是1/6，投掷6次骰子出现k次六点的概率。</li>
</ul>
<p>　　在上面的两个例子中，每次抛硬币或者掷骰子都和上次的结果无关，所以每次实验都是独立的。二项分布是一个离散分布，k的取值范围为从0到n，只有n+1种可能的结果。scipy.stats.binom为二项分布，下面用它计算抛十次硬币，出现k次正面的概率分布。</p>
<h4 id="In__5B16_5D_3A"><a href="#In__5B16_5D_3A" class="headerlink" title="In [16]:"></a>In [16]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = np.arange(n+<span class="number">1</span>)</span><br><span class="line">pcoin = stats.binom.pmf(k, n, <span class="number">0.5</span>)</span><br><span class="line">pcoin</span><br></pre></td></tr></table></figure>
<h4 id="Out_5B16_5D_3A"><a href="#Out_5B16_5D_3A" class="headerlink" title="Out[16]:"></a>Out[16]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([ <span class="number">0.00097656</span>,  <span class="number">0.00976563</span>,  <span class="number">0.04394531</span>,  <span class="number">0.1171875</span> ,  <span class="number">0.20507813</span>,</span><br><span class="line">        <span class="number">0.24609375</span>,  <span class="number">0.20507813</span>,  <span class="number">0.1171875</span> ,  <span class="number">0.04394531</span>,  <span class="number">0.00976563</span>,</span><br><span class="line">        <span class="number">0.00097656</span>])</span><br></pre></td></tr></table></figure>
<h4 id="In__5B17_5D_3A"><a href="#In__5B17_5D_3A" class="headerlink" title="In [17]:"></a>In [17]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pl.stem(k, pcoin, basefmt=<span class="string">"k-"</span>)</span><br><span class="line">pl.margins(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss.png" alt=""><br>下面是投掷6次骰子，出现6点的概率分布。</p>
<h4 id="In__5B18_5D_3A"><a href="#In__5B18_5D_3A" class="headerlink" title="In [18]:"></a>In [18]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">6</span></span><br><span class="line">k = np.arange(n+<span class="number">1</span>)</span><br><span class="line">pdice = stats.binom.pmf(k, n, <span class="number">1.0</span>/<span class="number">6</span>)</span><br><span class="line">pdice</span><br></pre></td></tr></table></figure>
<h4 id="Out_5B18_5D_3A"><a href="#Out_5B18_5D_3A" class="headerlink" title="Out[18]:"></a>Out[18]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([  <span class="number">3.34897977e-01</span>,   <span class="number">4.01877572e-01</span>,   <span class="number">2.00938786e-01</span>,</span><br><span class="line">         <span class="number">5.35836763e-02</span>,   <span class="number">8.03755144e-03</span>,   <span class="number">6.43004115e-04</span>,</span><br><span class="line">         <span class="number">2.14334705e-05</span>])</span><br></pre></td></tr></table></figure>
<h4 id="In__5B19_5D_3A"><a href="#In__5B19_5D_3A" class="headerlink" title="In [19]:"></a>In [19]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pl.stem(k, pdice, basefmt=<span class="string">"k-"</span>)</span><br><span class="line">pl.margins(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss1.png" alt=""></p>
<h2 id="Beta_u5206_u5E03"><a href="#Beta_u5206_u5E03" class="headerlink" title="Beta分布"></a>Beta分布</h2><hr>
<p>　　对于硬币或者骰子这样的简单实验，我们事先能很准确地掌握系统成功的概率。然而通常情况下，系统成功的概率是未知的。为了测试系统的成功概率$p$，我们做n次试验，统计成功的次数k，于是很直观地就可以计算出$p = k/n$。然而由于系统成功的概率是未知的，这个公式计算出的$p$只是系统成功概率的最佳估计。也就是说实际上$p$也可能为其它的值，只是为其它的值的概率较小。</p>
<p>　　例如有某种特殊的硬币，我们事先完全无法确定它出现正面的概率。然后抛10次硬币，出现5次正面，于是我们认为硬币出现正面的概率最可能是0.5。但是即使硬币出现正面的概率为0.4，也会出现抛10次出现5次正面的情况。因此我们并不能完全确定硬币出现正面的概率就是0.5，所以$p$也是一个随机变量，它符合Beta分布。</p>
<p>　　Beta分布是一个连续分布，由于它描述概率$p$的分布，因此其取值范围为0到1。 Beta分布有$\alpha$和$\beta$两个参数，其中$\alpha$为成功次数加1，$\beta$为失败次数加1。连续分布用概率密度函数描述，下面绘制实验10次，成功4次和5次时，系统成功概率$p$的分布情况。可以看出$k=5$时，曲线的峰值在$p=0.5$处，而$k=4$时，曲线的峰值在$p=0.4$处。</p>
<h4 id="In__5B20_5D_3A"><a href="#In__5B20_5D_3A" class="headerlink" title="In [20]:"></a>In [20]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = <span class="number">5</span></span><br><span class="line">p = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"k=5"</span>, lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"k=4"</span>, lw=<span class="number">2</span>)</span><br><span class="line">xlabel(<span class="string">"$p$"</span>)</span><br><span class="line">legend(loc=<span class="string">"best"</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss3.png" alt=""><br>　　下面绘制$n=10, k=4$和$n=20, k=8$的概率分布。可以看出峰值都在$p=0.4$处，但是$n=20$的山峰更陡峭。也就是说随着实验次数的增加，$p$取其它值的可能就越小，对$p$的估计就更有信心，因此山峰也就更陡峭了。</p>
<h4 id="In__5B30_5D_3A"><a href="#In__5B30_5D_3A" class="headerlink" title="In [30]:"></a>In [30]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">10</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">p = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"n=10"</span>, lw=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">20</span></span><br><span class="line">k = <span class="number">8</span></span><br><span class="line">pbeta = stats.beta.pdf(p, k+<span class="number">1</span>, n-k+<span class="number">1</span>)</span><br><span class="line">plot(p, pbeta, label=<span class="string">"n=20"</span>, lw=<span class="number">2</span>)</span><br><span class="line">xlabel(<span class="string">"$p$"</span>)</span><br><span class="line">legend(loc=<span class="string">"best"</span>);</span><br></pre></td></tr></table></figure>
<p><img src="/images/algo/ssss4.png" alt=""></p>
<h2 id="u7528pymc_u6A21_u62DF"><a href="#u7528pymc_u6A21_u62DF" class="headerlink" title="用pymc模拟"></a>用pymc模拟</h2><hr>
<p>　　假设我们的知识库中没有Beta分布，如何通过模拟实验找出$p$的概率分布呢？pymc是一个用于统计估计的库，它可以通过 先验概率和 观测值 模拟出 后验概率 的分布。下面先解释一下这两个概率：</p>
<ul>
<li>先验概率：在贝叶斯统计中，某一不确定量p的先验概率分布是在考虑”观测数据”前，能表达p不确定性的概率分布。</li>
<li>后验概率：在考虑相关证据或数据后所得到的不确定量p的概率分布。</li>
</ul>
<p>　　拿前面抛硬币的实验来说，如果在做实验之前能确信硬币出现正面的概率大概在0.5附近的话，那么它的先验概率就是一个以0.5为中心的山峰波形。而如果是某种特殊的硬币，我们对其出现正面的概率完全不了解，那么它的先验概率就是一个从0到1的平均分布。为了估计这个特殊硬币出现正面的概率，我们做了20次实验，其中出现了8次正面。通过这个实验，硬币出现正面的可能性的后验概率就如上图中的绿色曲线所示。</p>
<p>　　pymc库可以通过先验概率和观测值模拟出后验概率的分布，这对于一些复杂的系统的估计是很有用的。下面我们看看如何用pymc来对这个特殊硬币出现正面的可能性进行估计：首先pcoin是这个特殊硬币出现正面的概率，由于我们没有任何先验知识，因此它的先验概率是一个从0到1的平均分布(Uniform)。假设我们做了20次实验，其中8次为正面。根据前面的介绍可知，出现正面的次数符合二项分布(Binomial)，并且这个二项分布的概率$p$为pcoin。这个通过value参数指定了实验的结果。因此experiment虽然是一个二项分布，但是它已经不能取其它值了。</p>
<h4 id="In__5B32_5D_3A"><a href="#In__5B32_5D_3A" class="headerlink" title="In [32]:"></a>In [32]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymc</span><br><span class="line">pcoin = pymc.Uniform(<span class="string">"pcoin"</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">experiment = pymc.Binomial(<span class="string">"experiment"</span>, <span class="number">20</span>, pcoin, value=<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<p>　　接下来通过MCMC对象模拟pcoin的后验概率。MCMC是Markov chain Monte Carlo(马尔科夫蒙特卡洛)的缩写，它是一种用马尔可夫链从随机分布取样的算法。通过调用MCMC对象的sample()，可以对pcoin的后验概率分布进行取样。这里30000为取样次数，5000表示不保存头5000次取样值。这时因为MCMC算法通常有一个收敛过程，我们希望只保留收敛之后的取样值。</p>
<h4 id="In__5B33_5D_3A"><a href="#In__5B33_5D_3A" class="headerlink" title="In [33]:"></a>In [33]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mc = pymc.MCMC([pcoin])</span><br><span class="line">mc.sample(<span class="number">30000</span>, <span class="number">5000</span>)</span><br></pre></td></tr></table></figure>
<p>[<strong><strong><strong><em>**</em></strong></strong></strong>100%<strong><strong><strong><strong>**</strong></strong></strong></strong>]  30000 of 30000 complete<br>　　通过MCMC对象trace()可以获得某个不确定量的取样值。下面的程序获得pcoin的25000次取样值，并用hist()显示其分布情况。由结果可知pcoin的分布与前面介绍的Beta分布一致。</p>
<h4 id="In__5B31_5D_3A"><a href="#In__5B31_5D_3A" class="headerlink" title="In [31]:"></a>In [31]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pcoin_trace = mc.trace(<span class="string">"pcoin"</span>)[:]</span><br><span class="line">hist(pcoin_trace, normed=<span class="keyword">True</span>, bins=<span class="number">30</span>);</span><br><span class="line">plot(p, pbeta, <span class="string">"r"</span>, label=<span class="string">"n=20"</span>, lw=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h4 id="Out_5B31_5D_3A"><a href="#Out_5B31_5D_3A" class="headerlink" title="Out[31]:"></a>Out[31]:</h4><p><img src="/images/algo/ssss5.png" alt=""></p>
<h4 id="In__5B34_5D_3A"><a href="#In__5B34_5D_3A" class="headerlink" title="In [34]:"></a>In [34]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcoin_trace.shape</span><br></pre></td></tr></table></figure>
<h4 id="Out_5B34_5D_3A"><a href="#Out_5B34_5D_3A" class="headerlink" title="Out[34]:"></a>Out[34]:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">25000</span>,)</span><br></pre></td></tr></table></figure>
<p>链接：<a href="http://hyry.dip.jp/tech/slice/slice.html/42" target="_blank" rel="external">http://hyry.dip.jp/tech/slice/slice.html/42</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/beta-a-md/" data-id="cilxthd44006xt5jigayvut6j" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/beta-a-md/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-algo/beta-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/beta-md/">理解Beta分布和Dirichlet分布</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/beta-md/">
      <time datetime="2015-09-03T06:18:04.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p><br><br>在Machine Learning中，有一个很常见的概率分布叫做Beta Distribution：<br><img src="/images/algo/j8b261e3942f702b2a36d5221f9a006bf.png" alt=""><br>同时，Dirichelet Distribution：</p>
<p><img src="/images/algo/j24fc194e3126c49d315032f55d0a52e2.png" alt=""></p>
<h3 id="u89E3_u91CA"><a href="#u89E3_u91CA" class="headerlink" title="解释"></a>解释</h3><hr>
<p>　　如果给你一个硬币，投这个硬币有\theta的概率抛出Head，有(1-\theta)的概率抛出Tail。如果在未来抛了五次这个硬币，有三次是Head，有两次是Tail，这个\theta最有可能是多少呢？如果你必须给出一个确定的值，并且你完全根据目前观测的结果来估计\theta，那么\theta = 3/5。</p>
<p><img src="/images/algo/a.png" alt=""></p>
<p>　　如果未来抛出五次硬币，全部都是Head。那么按照1中的逻辑，你将估计\theta为1。也就是说，你估计这枚硬币不管怎么投，都朝上！可是，你想这或许是巧合：世界上没有这么屌的硬币，硬币还是有一定可能抛出Tail的。就算观测到再多次的Head，抛出Tail的概率还是不可能为0。这时候，Bayesian公式横空出世（如下图所示）。我们在估计\theta时，心中先有一个估计，即先验概率。这个估计，表现在Probability中，就是一个概率分布。通俗得来讲，我们不再认为\theta是个固定的值了。</p>
<p><img src="/images/algo/j8b6e228eaeb570260d0f8c12a18add50.png" alt=""></p>
<p>　　在上面的Bayesian公式中，p(\theta)就是个概率分布。这个概率分布可以是任何概率分布，比如高斯分布，比如我们想要说的Beta Distribution。下图是Beta(5,2)的概率分布图。如果我们将这个概率分布作为p(\theta)，那么我们在还未抛硬币前，便认为\theta很可能接近于0.8，而不大可能是个很小的值或是一个很大的值。即，我们在抛硬币前，便估计这枚硬币更可能有0.8的概率抛出正面。</p>
<p><img src="/images/algo/j9f3ba3610336773ac92573a548621b3e.png" alt=""></p>
<p>　　虽然p(\theta)可以是任何种类的概率分布，但是如果使用Beta Distribution，会让之后的计算更加方便。我们接着继续看便知道这是为什么了。况且，通过调节Beta Distribution中的a和b，你可以让这个概率分布变成各种你想要的形状！Beta Distribution已经很足够表达你事先对\theta的估计了。现在我们已经估计好了p(\theta)为一个Beta Distribution，那么p(X|\theta)是多少呢？其实就是个二项分布。继续以1中抛5次硬币抛出3次Head为例，X=抛5次硬币抛出3个Head的事件。</p>
<p><img src="/images/algo/ja3a99d005b464c5164166547afc9e13b.png" alt=""><br>　　Bayesian公式下的p(X)是个Normalizer，或者叫做marginal probability。在\theta离散的情况下，p(X)就是\theta为不同值的时候，p(X|\theta)的求和。比如，如果我们事先估计硬币抛出正面的概率只可能是0.5或者0.8，那么p(X) = p(X|\theta=0.5)+p(X|\theta=0.8)，计算时分别将\theta=0.5和\theta=0.8代入到7中的公式中。而如果我们用Beta Distribution，\theta的概率分布在[0,1]之间是连续的，所以要用积分。</p>
<p><img src="/images/algo/j48e8020e87f818d9414e03ffb9fcf248.png" alt=""></p>
<p>　　p(\theta)是个Beta Distribution，那么在观测到X=抛5次硬币中有3个head的事件后，p(\theta|X)依旧是个Beta Distribution！只是这个概率分布的形状因为观测的事件而发生了变化。<br><img src="/images/algo/j0eca37b51f989944703ffbabadb40086.png" alt=""></p>
<p>　　因为观测前后，对\theta估计的概率分布均为Beta Distribution，这就是为什么使用Beta Distribution方便我们计算的原因了。当我们得知p(\theta|X)=Beta(\theta|a+3, b+2)后，我们就只要根据Beta Distribution的特性，得出\theta最有可能等于多少了。（即\theta等于多少时，观测后得到的Beta distribution有最大的概率密度）。例如下图，仔细观察新得到的Beta Distribution，和（5）中的概率分布对比，发现峰值从0.8左右的位置移向了0.7左右的位置。这是因为新观测到的数据中，5次有3次是head（60%），这让我们觉得，\theta没有0.8那么高。但由于我们之前觉得\theta有0.8那么高，我们觉得抛出head的概率肯定又要比60%高一些！这就是Bayesian方法和普通的统计方法不同的地方。我们结合自己的先验概率和观测结果来给出预测。</p>
<p><img src="/images/algo/j01a0b8b112291e2355890ac32572b01b.png" alt=""></p>
<p>　　如果我们投的不是硬币，而是一个多面体（比如筛子），那么我们就要使用Dirichlet Distribution了。使用Dirichlet Distributio的目的，也是为了让观测后得到的posterior probability依旧是Dirichlet Distribution。比如，我们抛掷一个三面体。抛出这三个面的概率分别为\theta_1, \theta_2和\theta_3。不论\theta_1, \theta_2和\theta_3如何分布，它们相加必须等于1。那它们的概率分布，是在一个立体的空间里的一个面。这个面由\theta_1+\theta_2+\theta_3=1表示。这个面上的任意一点，表示某种\theta_1, \theta_2和\theta_3组合的概率密度。下三图分别由不同的\alpha vector初始化得到不同的Dirichlet Distribution，红颜色代表概率密度较大，蓝颜色的区域概率密度较小。</p>
<p><img src="/images/algo/j3f8307ef170c6664eea5996932322a29.png" alt=""><br>　　Dirichlet Distribution和Beta Distribution都叫做Conjugate Prior。根据你的likelihood function，你可以选择对应的conjugate prior作为你对p(\theta)事先的估计。<br><img src="/images/algo/j3481aac389b57152d20380150d0abd4a.png" alt=""><br>转自：<a href="http://maider.blog.sohu.com/306392863.html" target="_blank" rel="external">http://maider.blog.sohu.com/306392863.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/beta-md/" data-id="cilxthd3p006vt5jioco18tco" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/beta-md/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-other/nitian-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/other/nitian-md/">忠诚度越高买东西越贵</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/other/nitian-md/">
      <time datetime="2015-09-03T06:01:28.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/other/">other</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>　　引言：马云曾说，阿里巴巴本质上就是一家数据公司，做淘宝的目的也不是为了卖货，而是获得所有零售的数据和制造业的数据；做物流也不仅仅为了送包裹，而是要把这些数据合在一起。而亚马逊公司作为美国最大的一家网络电子商务公司，是网络上最早开始经营电子商务的公司之一，20年的持续发展关键也离不开对数据的分析。如今，我们正从IT时代走向DT时代，即从information technology转向data technology。</p>
<p>　　先问大家一个问题，AB两个顾客同时想买某个品牌的东西，其中A顾客对这个品牌非常喜欢，B是新顾客。如果你是这个品牌的经营者的话，你会卖给谁更贵（假设不是标准定价）？</p>
<p>　　答案是A，我们很多人的观点是我们一定要对老顾客好一些，给他们最优的待遇。这其实是从消费者的角度出发思考，其实从经营的角度来说，忠诚度越高我们反而应该卖得更贵，因为企业经营是追求利润最大化（互联网思维的企业除外哈），另外忠诚度高的顾客不用太担心流失。</p>
<p>　　欺负老顾客，这是一个人艰不拆的真理，会让很多人眼泪忍不住的流下来。其实现在不就是这样的吗？首次打车的顾客免单，第一次购买电影票补贴，第一次消费打折等等。只是这些我们能接受，我们认为合理，接下来讲一个真实的差异化定价的案例。</p>
<h3 id="u4E9A_u9A6C_u900A_u5DEE_u5F02_u5316_u5B9A_u4EF7_u6D4B_u8BD5"><a href="#u4E9A_u9A6C_u900A_u5DEE_u5F02_u5316_u5B9A_u4EF7_u6D4B_u8BD5" class="headerlink" title="亚马逊差异化定价测试"></a>亚马逊差异化定价测试</h3><p>　　为提高在主营产品上的赢利，亚马逊在2000年9月中旬开始了著名的差别定价实验。他们选择了68种DVD碟片进行动态定价试验。试验当中，亚马逊根据潜在客户的人口统计资料、在亚马逊的购物历史、上网行为以及上网使用的软件系统确定对这68种碟片的报价水平。</p>
<p>　　例如，名为《泰特斯》（Titus）的碟片对新顾客的报价为22.74美元，而对那些对该碟片表现出兴趣的老顾客的报价则为26.24美元。通过这一定价策略，部分顾客付出了比其他顾客更高的价格，亚马逊因此提高了销售的毛利率。（网络购物可以做到千人千面，每个人看到的页面不一样，价格也可以不一样）</p>
<p>　　但是好景不长，这一差别定价策略实施不到一个月，就有细心的消费者发现了这一秘密，通过在名为DVDTalk 的音乐爱好者社区的交流，成百上千的DVD消费者知道了此事，那些付出高价的顾客当然怨声载道，纷纷在网上以激烈的言辞对亚马逊的做法进行口诛笔伐，有人甚至公开表示以后绝不会在亚马逊购买任何东西。更不巧的是，由于亚马逊前不久才公布了它对消费者在网站上的购物习惯和行为进行了跟踪和记录，因此，这次事件曝光后，消费者和媒体开始怀疑亚马逊是否利用其收集的消费者资料作为其价格调整的依据，这样的猜测让亚马逊的价格事件与敏感的网络隐私问题联系在了一起。最后的结局是亚马逊道歉，然后将差价退给了那些买贵了的顾客。这件事虽然以失败告终，但是这种差异化定价的思路却是可以借鉴的。</p>
<p>　　放眼望去，我们身边到处都是差异化定价的案例：菜市场的小贩看人下菜单，不同顾客买到的机票价格都不同，会员和非会员的价格也不一样，买的多和买得少价格也不一样。唯一不一样的是，这些差异化定价是按照我们常人的逻辑在运行，如买的多就应该便宜。亚马逊的案例恰恰和常规相反，但确实是经营的需要。那么如何做到根据需求差异定价呢？这种需求差异主要体现在时间、地点、消费对象之间三个方面。“时间就是金钱”在这点上彻底体现出来了，新手机上市，如果你是品牌忠实的追随者，那你必须付高价才能得到它，反之，你可以慢慢等待，等到价格降到你的目标价位的时候出手，有些地方高峰电价和平峰电价不一样，机票的价格和距起飞时间成反比，旅游景区的淡旺季门票差异等，这都是需求中利用时间差异的定价方法。</p>
<p>　　新开一个超市如果附近没有竞争对手和有竞争对手时的定价策略是不一样的，一瓶同样品牌的啤酒在超市和酒吧的价格大相径庭，演唱会前排的价格高于后排的价格，海景房的价格比山景房的价格贵等等，这都是需求中地点差异的定价方法。消费对象的定价差异更多体现在会员顾客和非会员顾客的价格差异上，以及女性相对于男性对价格敏感的差异上。未来随着科技的进步会逐渐发展到个体的定价差异上，例如零售商根据你购买或维修冰箱的数据，发现你的冰箱到了更换的时候，就可以给你寄一张200元的冰箱代金券，这样你的价格就和其他人不一样了。需要注意的是差异定价不能引起顾客的反感，需要透彻分析其中的风险。针对亚马逊这个案例，错就错在互联网购物价格太透明了，一旦穿帮就是丑闻。那怎么让顾客不反感，同时企业又能贯彻忠诚度高的顾客价格越贵的原则呢？答案见下图。</p>
<p><img src="/images/bb/792c43ea9c648c61a22c1a50a6439b15.jpg" alt=""><br>看明白了吗？</p>
<p>没看明白的话我就给大家点破吧！</p>
<p>将抽奖结果关联用户数据！</p>
<p>　　怎么理解这句话？就是当买家在网站买东西的时候，旁边放一个抽奖链接，买家可以根据抽奖结果来付款，抽奖结果又减30，减50，一分不减等选项。当买家在按下抽奖按钮的同时，后台大数据就开始工作了，根据你以往的购买数据很快可以算出你对这个商品的忠诚度，喜好度，需要的紧迫性等。当发现你从来没有买过类似的商品的话，就会让你中“大奖”。当发现你是优质买家，那不好意思了，一分不减。这样是不是每个人都高高兴兴的了？你还以为抽奖结果是随机的呢。其实买的永远没有卖的精！你可以看看现在淘宝、京东等消费性电商培都用了这一招！</p>
<h3 id="u6BD4_u8F83_u6709_u4EF7_u503C_u7684_u8BC4_u8BBA_uFF1A"><a href="#u6BD4_u8F83_u6709_u4EF7_u503C_u7684_u8BC4_u8BBA_uFF1A" class="headerlink" title="比较有价值的评论："></a>比较有价值的评论：</h3><ol>
<li><p>就是利用信息不对称赚钱，不过互联网就是要消除信息不对称，所以这条路其实在互联网上是走不通的</p>
</li>
<li><p>互联网时代，价格是透明的，跨店比价购买的成本近乎为零，同一件商品如果亚马逊卖50，京东卖49，天猫卖45，你猜消 费者会怎么选择？</p>
</li>
<li><p>杀熟很危险，如果用户知道了，可能会对品牌造成致命的影响，而你得到的不过蝇头小利。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/other/nitian-md/" data-id="cilxthd030017t5ji36chxwqo" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/other/nitian-md/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-algo/baysian-bandit-application-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/baysian-bandit-application-md/">Bayesian Bandits原理及在互联网广告行业的应用</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/baysian-bandit-application-md/">
      <time datetime="2015-09-03T05:48:13.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="1-_The_Multi-Armed_Bandit_Problem"><a href="#1-_The_Multi-Armed_Bandit_Problem" class="headerlink" title="1. The Multi-Armed Bandit Problem"></a>1. The Multi-Armed Bandit Problem</h2><p>Suppose you are faced with N slot machines (colourfully called multi-armed bandits). Each bandit has an unknown probability of distributing a prize (assume for now the prizes are the same for each bandit, only the probabilities differ). Some bandits are very generous, others not so much. Of course, you don’t know what these probabilities are. By only choosing one bandit per round, our task is devise a strategy to maximize our winnings.</p>
<p>Of course, if we knew the bandit with the largest probability, then always picking this bandit would yield the maximum winnings. So our task can be phrased as “Find the best bandit, and as quickly as possible”.</p>
<p>The task is complicated by the stochastic nature of the bandits. A suboptimal bandit can return many winnings, purely by chance, which would make us believe that it is a very profitable bandit. Similarly, the best bandit can return many duds. Should we keep trying losers then, or give up?</p>
<p>A more troublesome problem is, if we have a found a bandit that returns pretty good results, do we keep drawing from it to maintain our pretty good score, or do we try other bandits in hopes of finding an even-better bandit? This is the exploration vs. exploitation dilemma.</p>
<h2 id="2-_Applications"><a href="#2-_Applications" class="headerlink" title="2. Applications"></a>2. Applications</h2><p>The Multi-Armed Bandit problem at first seems very artificial, something only a mathematician would love, but that is only before we address some applications:</p>
<p>Internet display advertising: companies have a suite of potential ads they can display to visitors, but the company is not sure which ad strategy to follow to maximize sales. This is similar to A/B testing, but has the added advantage of naturally minimizing strategies that do not work (and generalizes to A/B/C/D… strategies)</p>
<ol>
<li>Ecology: animals have a finite amount of energy to expend, and following certain behaviours has uncertain rewards. How does the animal maximize its fitness?</li>
<li>Finance: which stock option gives the highest return, under time-varying return profiles.</li>
<li>Clinical trials: a researcher would like to find the best treatment, out of many possible treatments, while minimizing losses.</li>
</ol>
<p>Many of these questions above are fundamental to the application’s field. It turns out the optimal solution is incredibly difficult, and it took decades for an overall solution to develop. There are also many approximately-optimal solutions which are quite good. The one I wish to discuss is one of the few solutions that can scale incredibly well. The solution is known asBayesian Bandits.</p>
<h2 id="3-_A_Proposed_Solution"><a href="#3-_A_Proposed_Solution" class="headerlink" title="3. A Proposed Solution"></a>3. A Proposed Solution</h2><p>Any proposed strategy is called an online algorithm (not in the internet sense, but in the continuously-being-updated sense), and more specifically a reinforcement learning algorithm. The algorithm starts in an ignorant state, where it knows nothing, and begins to acquire data by testing the system. As it acquires data and results, it learns what the best and worst behaviours are (in this case, it learns which bandit is the best). With this in mind, perhaps we can add an additional application of the Multi-Armed Bandit problem:</p>
<p>Psychology: how does punishment and reward effect our behaviour? How do humans’ learn?<br>The Bayesian solution begins by assuming priors on the probability of winning for each bandit. In our vignette we assumed complete ignorance of the these probabilities. So a very natural prior is the flat prior over 0 to 1. The algorithm proceeds as follows:</p>
<p>For each round,</p>
<ol>
<li>Sample a random variable Xb from the prior of bandit b, for all b.</li>
<li>Select the bandit with largest sample, i.e. select bandit B=argmaxXb.</li>
<li>Observe the result of pulling bandit B, and update your prior on bandit B.</li>
<li>Return to 1.</li>
</ol>
<p>That’s it. Computationally, the algorithm involves sampling from N distributions. Since the initial priors are Beta(α=1,β=1) (a uniform distribution), and the observed result X (a win or loss, encoded 1 and 0 respectfully) is Binomial, the posterior is a Beta(α=1+X,β=1+1−X)(see here for why to is true). </p>
<p>To answer a question from before, this algorithm suggests that we should not discard losers, but we should pick them at a decreasing rate as we gather confidence that there exist better bandits. This follows because there is always a non-zero chance that a loser will achieve the status of B, but the probability of this event decreases as we play more rounds (see figure below). Below is an implementation of the Bayesian Bandits strategy (which can be skipped for the less Pythonic-ly interested).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pymc <span class="keyword">import</span> rbeta</span><br><span class="line"> </span><br><span class="line">rand = np.random.rand</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bandits</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    This class represents N bandits machines.</span><br><span class="line"> </span><br><span class="line">    parameters:</span><br><span class="line">        p_array: a (n,) Numpy array of probabilities &gt;0, &lt;1.</span><br><span class="line"> </span><br><span class="line">    methods:</span><br><span class="line">        pull( i ): return the results, 0 or 1, of pulling </span><br><span class="line">                   the ith bandit.</span><br><span class="line">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, p_array)</span>:</span></span><br><span class="line">        self.p = p_array</span><br><span class="line">        self.optimal = np.argmax(p_array)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pull</span><span class="params">( self, i )</span>:</span></span><br><span class="line">        <span class="comment">#i is which arm to pull</span></span><br><span class="line">        <span class="keyword">return</span> rand() &lt; self.p[i]</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.p)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BayesianStrategy</span><span class="params">( object )</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Implements a online, learning strategy to solve</span><br><span class="line">    the Multi-Armed Bandit problem.</span><br><span class="line"> </span><br><span class="line">    parameters:</span><br><span class="line">        bandits: a Bandit class with .pull method</span><br><span class="line"> </span><br><span class="line">    methods:</span><br><span class="line">        sample_bandits(n): sample and train on n pulls.</span><br><span class="line"> </span><br><span class="line">    attributes:</span><br><span class="line">        N: the cumulative number of samples</span><br><span class="line">        choices: the historical choices as a (N,) array</span><br><span class="line">        bb_score: the historical score as a (N,) array</span><br><span class="line"> </span><br><span class="line">    """</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, bandits)</span>:</span></span><br><span class="line"> </span><br><span class="line">        self.bandits = bandits</span><br><span class="line">        n_bandits = len( self.bandits )</span><br><span class="line">        self.wins = np.zeros( n_bandits )</span><br><span class="line">        self.trials = np.zeros(n_bandits )</span><br><span class="line">        self.N = <span class="number">0</span></span><br><span class="line">        self.choices = []</span><br><span class="line">        self.bb_score = []</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample_bandits</span><span class="params">( self, n=<span class="number">1</span> )</span>:</span></span><br><span class="line"> </span><br><span class="line">        bb_score = np.zeros( n )</span><br><span class="line">        choices = np.zeros( n )</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="comment">#sample from the bandits's priors, and select the largest sample</span></span><br><span class="line">            choice = np.argmax( rbeta( <span class="number">1</span> + self.wins, <span class="number">1</span> + self.trials - self.wins) )</span><br><span class="line"> </span><br><span class="line">            <span class="comment">#sample the chosen bandit</span></span><br><span class="line">            result = self.bandits.pull( choice )</span><br><span class="line"> </span><br><span class="line">            <span class="comment">#update priors and score</span></span><br><span class="line">            self.wins[ choice ] += result</span><br><span class="line">            self.trials[ choice ] += <span class="number">1</span></span><br><span class="line">            bb_score[ k ] = result </span><br><span class="line">            self.N += <span class="number">1</span></span><br><span class="line">            choices[ k ] = choice</span><br><span class="line"> </span><br><span class="line">        self.bb_score = np.r_[ self.bb_score, bb_score ]</span><br><span class="line">        self.choices = np.r_[ self.choices, choices ]</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>Below we present a visualization of the algorithm sequentially learning the solution. In the figure below, the dashed lines represent the true hidden probabilities, which are (0.85, 0.60, 0.75)(this can be extended to many more dimensions, but the figure suffers, so I kept it at 3).</p>
<p><img src="/images/bb/updating2.png" alt=""></p>
<p>Note that we don’t real care how accurate we become about inference of the hidden probabilities — for this problem we are more interested in choosing the best bandit (or more accurately, becoming more confident in choosing the best bandit). For this reason, the distribution of the red bandit is very wide (representing ignorance about what that hidden probability might be) but we are reasonably confident that it is not the best, so the algorithm chooses to ignore it.</p>
<h3 id="u51E0_u7BC7_u4ECB_u7ECDBayesian_Bandits_u7684_u539F_u7406_u7684_u6587_u7AE0_uFF1A"><a href="#u51E0_u7BC7_u4ECB_u7ECDBayesian_Bandits_u7684_u539F_u7406_u7684_u6587_u7AE0_uFF1A" class="headerlink" title="几篇介绍Bayesian Bandits的原理的文章："></a>几篇介绍Bayesian Bandits的原理的文章：</h3><ol>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html</a></li>
<li>在线演示博弈过程： <a href="https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/" target="_blank" rel="external">https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/</a></li>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html</a></li>
<li><a href="http://camdp.com/blogs/multi-armed-bandits" target="_blank" rel="external">http://camdp.com/blogs/multi-armed-bandits</a></li>
<li>贝叶斯书籍：<a href="https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers" target="_blank" rel="external">https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/" data-id="cilxthd490077t5ji5c2d2jj6" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bandits/">Bandits</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/baysian-bandit-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/baysian-bandit-md/">Bayesian Bandits – optimizing click throughs with statistics</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/baysian-bandit-md/">
      <time datetime="2015-09-03T05:36:48.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>Great news! A murder victim has been found. No slow news day today! The story is already written, now a title needs to be selected. The clever reporter who wrote the story has come up with two potential titles – “Murder victim found in adult entertainment venue” and “Headless Body found in Topless Bar”. (The latter title is one I’ve shamelessly stolen from the NY Daily News.) Once upon a time, deciding which title to run was a matter for a news editor to decide. Those days are now over – the geeks now rule the earth. Title selection is now primarily an algorithmic problem, not an editorial one.</p>
<p>One common approach is to display both potential versions of the title on the homepage or news feed, and measure the Click Through Rate (CTR) of each version of the title. At some point, when the measured CTR for one title exceeds that of the other title, you’ll switch to the one with the highest for all users. Algorithms for solving this problem are called bandit algorithms.</p>
<p>In this blog post I’ll describe one of my favorite bandit algorithms, the Bayesian Bandit, and show why it is an excellent method to use for problems which give us more information than typical bandit algorithms.</p>
<p>Unless you are already familiar with Bayesian statistics and beta distributions, I strongly recommend reading the previous blog post. That post provides much introductory material, and I’ll depend on it heavily.</p>
<h2 id="1-_The_problem_to_be_solved_2C_and_the_underlying_model"><a href="#1-_The_problem_to_be_solved_2C_and_the_underlying_model" class="headerlink" title="1. The problem to be solved, and the underlying model"></a>1. The problem to be solved, and the underlying model</h2><hr>
<p>Ultimately the problem we want to solve is the following. Consider an article being published on a website. The author or editor has come up with several possible titles – “Murder victim found in adult entertainment venue”, “Headless Body found in Topless Bar”, etc. We want to choose the title with the best click through rate (CTR). Let us represent each CTR by θi – i.e., θi is the true probability that an individual user will click on the i-th title. As a simplifying assumption, we assume that these rates θi do not change over time. It is important to note that we don’t actually know what θi is – if we did, we could simply choose i for which θi was largest and move on.</p>
<p>The goal of the bandit algorithm is to do the following. To begin with, it should display all possible titles to a random selection of users, and measure which titles are clicked on more frequently. Over time, it will use these observations to infer which articles have the higher CTR. Then, once the estimation of the CTR becomes more precise, it will preferentially display articles with the higher CTR.</p>
<h2 id="2-_The_Bayesian_Approach"><a href="#2-_The_Bayesian_Approach" class="headerlink" title="2. The Bayesian Approach"></a>2. The Bayesian Approach</h2><hr>
<p>In the model described above, we have N possible story titles, each of which has a click through rate θi. Unfortunately we do not know what θi is. As the astute reader can guess from the title, we are following a Bayesian approach, so we will construct a probability distribution which represents our belief about what the actual value of θi is.<br><img src="/images/bb/beliefs_about_theta.png" alt=""><br>In the figure above, we believe that θi is somewhere between 0.1 and 0.7, with values of 0.3-0.4 being considerably more likely than values of 0.1-0.2 or 0.6-0.7. For those who forgot STATS 101, the area under this curve between the points a and b is the probability thta θi lies between a and b. I.e.:<br><img src="/images/bb/11.png" alt=""><br>The basic idea behind Bayesian methods is to update our beliefs based on evidence. As we gather more data by showing different titles to other users and observing click throughs, we can incrementally narrow the width of the probability distribution.</p>
<p>As in all Bayesian inference, we need to choose a prior. The prior is something we believe to be true before we have any evidence – i.e., before we have shown the title to any visitors. This is just a starting point – after enough evidence is gathered, our prior will play a very minimal role in what we actually believe. Choosing a good prior is important both for mathematical simplicity, and because if your prior is accurate, you don’t need as much evidence to get the correct answer.</p>
<p>I’ll follow the approach I described in a previous blog post, and I’ll use a beta distribution as the prior:<br><img src="/images/bb/31.png" alt=""><br>The parameters αi,βi&gt;1 are the prior parameters. One reasonable choice is αi=βi=1, which amounts to the uniform distribution on [0,1]. What this means is that we are assuming that all possible values of θi are equally likely. Depending on the circumstances (which I’ll explain shortly), we might want to choose other possible values.</p>
<h2 id="3-_Updating_our_beliefs"><a href="#3-_Updating_our_beliefs" class="headerlink" title="3. Updating our beliefs"></a>3. Updating our beliefs</h2><p>Now we address the question of using evidence. After showing title i to ni visitors, we have observed that si of them have actually clicked on the title. We now want to compute theposterior distribution, which is to say the distribution that represents our beliefs after we have evidence.</p>
<p>I did a little bit of algebra previously, in which I showed that if the prior is fαi,βi(θi), then the posterior distribution is:<br><img src="/images/bb/21.png" alt=""><br>The key idea here is that to update our probability distribution describing θi, we need only update the parameters of our beta distribution.</p>
<p>So what does this mean in practice? As we run more experiments, our probability distribution on where θi lives becomes sharper:</p>
<p><img src="/images/bb/beta_distribution_evolution.png" alt=""><br>Before we run any experiments, θi could be anything (as represented by the blue line). Once we have run 700 experiments, yielding 175 click throughs, we are reasonably confident that θi lives roughly between 0.2 and 0.3.</p>
<p>What we’ve done so far is figured out how to estimate what our click through rates actually are based on empirical evidence. But that doesn’t actually give us a method of optimizing them yet.</p>
<h2 id="4-_Optimizing_click_throughs"><a href="#4-_Optimizing_click_throughs" class="headerlink" title="4. Optimizing click throughs"></a>4. Optimizing click throughs</h2><p>Now that we have a method of representing our beliefs about CTRs, it is useful to construct an algorithm to identify the best ones. There are many popular choices – I’ve written about the UCB Algorithm before, and I consider it a good choice.</p>
<p>But my new favorite method is a Monte Carlo method which I’ll describe now.</p>
<p>The ultimate goal of the bandit algorithm is to display to the user whichever title has the highest CTR. One method of estimating the CTRs of the articles is to sample the posterior distribution. I.e., suppose we have two possible titles, from which we have drawn n0=200,s0=64and n1=180,n2=40. Then one possible set of samples we might observe is this:</p>
<p><img src="/images/bb/beta_distribution_sampling1.png" alt=""></p>
<p>For title 0, our sample of θ0 has worked out to be 0.35, while our sample of θ1 is only 0.28. Since θ0=0.35&gt;θ1=0.28, we will display title 0 to the user.</p>
<p>However, there was no guarantee that things worked out this way. It was possible, although less likely, that θ1 could come out larger than θ0:<br><img src="/images/bb/beta_distribution_sampling2.png" alt=""><br>In this case, we would have displayed title 1 to the user rather than title 0.</p>
<p>The net result is that for overlapping probability distributions, we will display the title with the larger expected CTR the majority of the time. But occasionally, we will draw from the other distributions simply because it is within the realm of possibility that they are greater.</p>
<p>As we gather more data our probability distributions will become narrower and a clear winner will become apparent. When this occurs, we will almost surely choose the winner:<br><img src="/images/bb/beta_distribution_sampling3.png" alt=""><br>In python, the algorithm looks like this:</p>
<p>The results of this algorithm are exactly what any good bandit algorithm should do. I ran the following simulation, giving the beta bandit two titles – title 0 had a CTR of 0.25, title 1 had a CTR of 0.35. To start with, both titles were displayed to the user with roughly equal probability. Over time, evidence accumulated that title 1 was considerably better than title 0. At this point the algorithm switched to displaying primarily title 1, and the overall CTR of the experiment converged to 0.35 (the optimal CTR).</p>
<p><img src="/images/bb/beta_bandit_results.png" alt=""></p>
<p>Source code to generate this graph is available here. This method is called Thompson Sampling and is a a fairly popular method in Bayesian AI techniques. For the remainder of this post, I’ll call this method the Bayesian Bandit.</p>
<h2 id="5-Incorporating_common_sense"><a href="#5-Incorporating_common_sense" class="headerlink" title="5.Incorporating common sense"></a>5.Incorporating common sense</h2><p>Anyone with common sense is now scoffing at the geekiness embodied in this post. Even before using statistics, it was fairly obvious that “Headless Body found in Topless Bar” was going to beat “Murder victim found in adult entertainment venue”. The former just sounds catchier and any good editor would run with it.</p>
<p>The wonderful thing about Bayesian methods is that we can modify them to take into account our prior knowledge. Suppose we believe editors intuition is a real thing – can we quantify it? Certainly. We can do this with a fairly simple experiment. We require editors to rate a collection of titles as “catchy” or “not catchy”, run them on the site, and then measure the CTR of the “catchy” and “not catchy” samples. Suppose we did such an experiment, and observed the following aggregate results:</p>
<p><img src="/images/bb/empirical_prior.png" alt=""></p>
<p>This isn’t a solid win for the editor – some catchy titles have low CTRs, and some boring titles have good CTRs. But nevertheless, it’s better for a story to have catchy title than not.</p>
<p>What we want to do is incorporate this information into our bandit algorithm. The beauty of a Bayesian method is that it gives you a clear and meaningful place to plug this information in, namely the prior. In contrast, for many other methods (e.g., UCB) it’s somewhat difficult to do this – there is no obvious parameter to tune as a result of our prior empirical data.</p>
<p>The first step is to fit a theoretical distribution to the empirical data. Due to the fact that I chose the “empirical” (i.e., made up) data to be very nice, a beta distribution fits well [1] – specifically beta distributions with (α0,β0)=(9,20) and (α1,β1)=(4,20).<br><img src="/images/bb/theoretical_prior.png" alt=""></p>
<p>Then the only modification needed to the algorithm is to plug these variables into the prior:<br><img src="/images/bb/41.png" alt=""><br>Everything else remains unchanged. In terms of modifications to source code, this is only a very small change to the previous code – an implementation can be found here.</p>
<h2 id="6-_Empirics_of_including_priors"><a href="#6-_Empirics_of_including_priors" class="headerlink" title="6. Empirics of including priors"></a>6. Empirics of including priors</h2><p>To measure the benefits of incorporating priors into the Bayesian bandit, I ran some numerical experiments, the source code of which is available in this github gist. The methodology was the following.</p>
<p>To compare the Bayesian bandit with priors to that without, I drew a pair (θ0,θ1) from the prior distribution given above. For each pair, I then ran the Bayes Bandit with and without priors for this pair theta, for k trials. This is modelling the scenario that we have k page views on our homepage, and we can only leave a story on the homepage for 1 day.</p>
<p>I then repeated the experiment for 1000 different possible days, or equivalently for 1000 different pairs of (θ0,θ1). I then computed the average gain per page view over all trials and all days.</p>
<p>The result is the following. If we get 50 page views/day (i.e., the Bayes Bandit has very little data to use), the prior gives us a big gain. Without prior knowledge, the Bandit achieved a gain of 0.3749 on average, whereas the bandit with prior knowledge achieved a gain of 0.4274. If we run 150 experiments, the Bayes Bandit improves significantly – it achieves a gain of 0.40. If we run 300 experiments, the Bayes Bandit improves to 0.4146, while the bandit with priors improves to 0.4296. If we get 1000 page views/day, the Bayes Bandit improves to 0.4211, while the bandit with priors gains 0.4249.</p>
<p>The net result is the following – incorporating priors into the Bayes Bandit is an excellent way to improve your results when you don’t have a large number data points to use to train the bandit. If you have a lot of data points, you don’t need strong priors (but they still help a little).</p>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7.Conclusion"></a>7.Conclusion</h2><p>Bandit algorithms are a great way of optimizing many factors of your website. There are many good options – I’ve written about UCB before and consider it a great choice. But if you have other information you want to include, consider using the Bayesian Bandit. It’s simple to implement, straightforward to use, and very importantly it’s also straightforward to extend.</p>
<p>It’s also important to note that the theoretical properties of the Bayesian Bandit (namely logarithmic regret) have been proven. So asymptotically, you lose nothing by using it. There are also attempts at constructing a Bayesian UCB algorithm – I don’t currently understand it well enough to comment.</p>
<p>I’ve written other articles related to this post. I have one post comparing bandit algorithms to a/b testing. I also I wrote about measuring a changing conversion rate, which provides an alternate algorithm for computing the posterior distribution if your conversion rate is not constant.</p>
<p>[1] If a single Beta distribution doesn’t fit, one can also use a convex combination of Beta distributions. The math works out just as nicely.</p>
<p>P.S. After I published this blog post, this related article was also pointed out to me, as was this online simulation of the Bayesian bandit.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/" data-id="cilxthd470073t5jipl2pw6ya" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bandits/">Bandits</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/10/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/12/">下一页 &raquo;</a>
      </nav>
    </section>
      
        <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul id="recent-post" class="">
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/03/18/dev/python/python_mysql/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/03/18/dev/python/python_mysql/" class="title">Python MySQLdb</a></p>
              <p class="item-date"><time datetime="2016-03-18T02:19:56.000Z" itemprop="datePublished">2016-03-18</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/03/10/dev/python/python_logging/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/03/10/dev/python/python_logging/" class="title">Python日志输出——logging模块</a></p>
              <p class="item-date"><time datetime="2016-03-10T02:19:56.000Z" itemprop="datePublished">2016-03-10</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/03/01/algo/ml/18/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
              <p class="item-title"><a href="/2016/03/01/algo/ml/18/" class="title">18大经典数据挖掘算法小结</a></p>
              <p class="item-date"><time datetime="2016-02-29T16:00:00.000Z" itemprop="datePublished">2016-03-01</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/02/24/dev/web/fcgi/" class="thumbnail">
  
    <span style="background-image:url(/images/other/fcgi.png
)" alt="FastCGI 工作原理分析" class="thumbnail-image"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/web/">web</a></p>
              <p class="item-title"><a href="/2016/02/24/dev/web/fcgi/" class="title">FastCGI 工作原理分析</a></p>
              <p class="item-date"><time datetime="2016-02-24T05:19:56.000Z" itemprop="datePublished">2016-02-24</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/02/16/algo/lib/dl_lib/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
              <p class="item-title"><a href="/2016/02/16/algo/lib/dl_lib/" class="title">深度学习框架的评估与比较</a></p>
              <p class="item-date"><time datetime="2016-02-16T08:07:12.000Z" itemprop="datePublished">2016-02-16</time></p>
            </div>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hash/">Hash</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Photo/">Photo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SQL/">SQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ads/">ads</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c++</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/dev/">dev</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/github/">github</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/internet/">internet</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/system/">system</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/travel/">travel</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apache/">Apache</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bandits/">Bandits</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FlatBuffers/">FlatBuffers</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Google/">Google</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Granger-causality/">Granger causality</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTTPS/">HTTPS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/">MapReduce</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mock/">Mock</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Monument-Vallay/">Monument Vallay</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mysql/">Mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PPTP-vpn/">PPTP, vpn</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Photoshop/">Photoshop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shadowsocks/">Shadowsocks</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ad/">ad</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/apache/">apache</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blade/">blade</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/crontab/">crontab</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/falsk-restful/">falsk, restful</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/font/">font</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/">github</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/">go</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hashmap/">hashmap</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux-ldd-依赖关系/">linux, ldd, 依赖关系</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lucene/">lucene</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nio/">nio</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pagerank/">pagerank</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/photo/">photo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/swift-llvm/">swift, llvm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/前端/">前端</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/广告/">广告</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开源，许可/">开源，许可</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/澳门/">澳门</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/监控，zabbix/">监控，zabbix</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/贝叶斯/">贝叶斯</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Apache/" style="font-size: 10px;">Apache</a> <a href="/tags/Bandits/" style="font-size: 12.5px;">Bandits</a> <a href="/tags/FlatBuffers/" style="font-size: 10px;">FlatBuffers</a> <a href="/tags/Google/" style="font-size: 10px;">Google</a> <a href="/tags/Granger-causality/" style="font-size: 10px;">Granger causality</a> <a href="/tags/HTTPS/" style="font-size: 10px;">HTTPS</a> <a href="/tags/MapReduce/" style="font-size: 10px;">MapReduce</a> <a href="/tags/Mock/" style="font-size: 10px;">Mock</a> <a href="/tags/Monument-Vallay/" style="font-size: 10px;">Monument Vallay</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/PPTP-vpn/" style="font-size: 12.5px;">PPTP, vpn</a> <a href="/tags/Photoshop/" style="font-size: 10px;">Photoshop</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/ad/" style="font-size: 10px;">ad</a> <a href="/tags/apache/" style="font-size: 10px;">apache</a> <a href="/tags/blade/" style="font-size: 10px;">blade</a> <a href="/tags/crontab/" style="font-size: 10px;">crontab</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/elasticsearch/" style="font-size: 12.5px;">elasticsearch</a> <a href="/tags/falsk-restful/" style="font-size: 10px;">falsk, restful</a> <a href="/tags/font/" style="font-size: 10px;">font</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/go/" style="font-size: 20px;">go</a> <a href="/tags/hashmap/" style="font-size: 10px;">hashmap</a> <a href="/tags/linux-ldd-依赖关系/" style="font-size: 10px;">linux, ldd, 依赖关系</a> <a href="/tags/lucene/" style="font-size: 10px;">lucene</a> <a href="/tags/nio/" style="font-size: 10px;">nio</a> <a href="/tags/pagerank/" style="font-size: 10px;">pagerank</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/python/" style="font-size: 17.5px;">python</a> <a href="/tags/swift-llvm/" style="font-size: 10px;">swift, llvm</a> <a href="/tags/前端/" style="font-size: 10px;">前端</a> <a href="/tags/广告/" style="font-size: 12.5px;">广告</a> <a href="/tags/开源，许可/" style="font-size: 10px;">开源，许可</a> <a href="/tags/澳门/" style="font-size: 10px;">澳门</a> <a href="/tags/监控，zabbix/" style="font-size: 10px;">监控，zabbix</a> <a href="/tags/贝叶斯/" style="font-size: 10px;">贝叶斯</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">三月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">11</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">六月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">二月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">十一月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">十月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">六月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">十一月 2013</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
  <div id="toTop" class="fa fa-chevron-up"></div>
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Li Jingpeng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
    </div>
  </div>
</footer>
    

<script type="text/javascript">
  var duoshuoQuery = {short_name:"lijingpeng"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>


<script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>