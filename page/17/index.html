<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Frank</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="计算机 网络 互联网">
<meta property="og:type" content="website">
<meta property="og:title" content="Frank">
<meta property="og:url" content="http://www.notehub.cn/page/17/index.html">
<meta property="og:site_name" content="Frank">
<meta property="og:description" content="计算机 网络 互联网">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Frank">
<meta name="twitter:description" content="计算机 网络 互联网">
  
  
    <link rel="icon" href="favicon.png">
  
  <link href='//fonts.css.network/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
  <link href="//fonts.css.network/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  

  
</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="/" id="logo"><i class="logo" style="background-image: url(/css/images/logo.jpg)"></i><span class="site-title">Frank</span></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/.">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      
        <nav id="sub-nav">
          <div class="profile" id="profile-nav">
            <a id="profile-anchor" href="javascript:;"><img class="avatar" src="/css/images/logo.png"><i class="fa fa-caret-down"></i></a>
          </div>
        </nav>
      
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"> </button><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
      </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tr>
        
          <td><a class="main-nav-link" href="/.">Home</a></td>
        
          <td><a class="main-nav-link" href="/archives">Archives</a></td>
        
          <td><a class="main-nav-link" href="/categories">Categories</a></td>
        
          <td><a class="main-nav-link" href="/tags">Tags</a></td>
        
          <td><a class="main-nav-link" href="/about">About</a></td>
        
        <td>
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
        </td>
      </tr>
    </table>
  </div>
</header>

    <div class="outer">
      
        <aside id="profile">
  <div class="inner profile-inner">
    <div class="base-info profile-block">
      <img id="avatar" src="/css/images/logo.png">
      <h2 id="name">Li Jingpeng</h2>
      <!-- <h3 id="title">undefined</h3> -->
      <span id="location"><i class="fa fa-map-marker"></i>Hangzhou, China</span>
      <a id="follow" href="Https://weibo.com/329299516">关注我</a>
    </div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        109
        <span>文章</span>
      </div>
      <div class="article-info-block">
        42
        <span>标签</span>
      </div>
    </div>
    
    <div class="contact-info profile-block">
      <table class="contact-list">
        <tr>
          
          <td><a href="https://github.com/lijingpeng" target="_blank" title="github"><i class="fa fa-github"></i></a></td>
          
          <td><a href="#" target="_blank" title="twitter"><i class="fa fa-twitter"></i></a></td>
          
          <td><a href="#" target="_blank" title="facebook"><i class="fa fa-facebook"></i></a></td>
          
          <td><a href="/me@lijingpeng.org" target="_blank" title="email"><i class="fa fa-email"></i></a></td>
          
          <td><a href="/atom.xml" target="_blank" title="rss"><i class="fa fa-rss"></i></a></td>
          
        </tr>
      </table>
    </div>
    
    
  </div>
</aside>

      
      <section id="main">
      <article id="post-algo/beta-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/beta-md/">理解Beta分布和Dirichlet分布</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/beta-md/">
      <time datetime="2015-09-03T06:18:04.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p><br><br>在Machine Learning中，有一个很常见的概率分布叫做Beta Distribution：<br><img src="/images/algo/j8b261e3942f702b2a36d5221f9a006bf.png" alt=""><br>同时，Dirichelet Distribution：</p>
<p><img src="/images/algo/j24fc194e3126c49d315032f55d0a52e2.png" alt=""></p>
<h3 id="u89E3_u91CA"><a href="#u89E3_u91CA" class="headerlink" title="解释"></a>解释</h3><hr>
<p>　　如果给你一个硬币，投这个硬币有\theta的概率抛出Head，有(1-\theta)的概率抛出Tail。如果在未来抛了五次这个硬币，有三次是Head，有两次是Tail，这个\theta最有可能是多少呢？如果你必须给出一个确定的值，并且你完全根据目前观测的结果来估计\theta，那么\theta = 3/5。</p>
<p><img src="/images/algo/a.png" alt=""></p>
<p>　　如果未来抛出五次硬币，全部都是Head。那么按照1中的逻辑，你将估计\theta为1。也就是说，你估计这枚硬币不管怎么投，都朝上！可是，你想这或许是巧合：世界上没有这么屌的硬币，硬币还是有一定可能抛出Tail的。就算观测到再多次的Head，抛出Tail的概率还是不可能为0。这时候，Bayesian公式横空出世（如下图所示）。我们在估计\theta时，心中先有一个估计，即先验概率。这个估计，表现在Probability中，就是一个概率分布。通俗得来讲，我们不再认为\theta是个固定的值了。</p>
<p><img src="/images/algo/j8b6e228eaeb570260d0f8c12a18add50.png" alt=""></p>
<p>　　在上面的Bayesian公式中，p(\theta)就是个概率分布。这个概率分布可以是任何概率分布，比如高斯分布，比如我们想要说的Beta Distribution。下图是Beta(5,2)的概率分布图。如果我们将这个概率分布作为p(\theta)，那么我们在还未抛硬币前，便认为\theta很可能接近于0.8，而不大可能是个很小的值或是一个很大的值。即，我们在抛硬币前，便估计这枚硬币更可能有0.8的概率抛出正面。</p>
<p><img src="/images/algo/j9f3ba3610336773ac92573a548621b3e.png" alt=""></p>
<p>　　虽然p(\theta)可以是任何种类的概率分布，但是如果使用Beta Distribution，会让之后的计算更加方便。我们接着继续看便知道这是为什么了。况且，通过调节Beta Distribution中的a和b，你可以让这个概率分布变成各种你想要的形状！Beta Distribution已经很足够表达你事先对\theta的估计了。现在我们已经估计好了p(\theta)为一个Beta Distribution，那么p(X|\theta)是多少呢？其实就是个二项分布。继续以1中抛5次硬币抛出3次Head为例，X=抛5次硬币抛出3个Head的事件。</p>
<p><img src="/images/algo/ja3a99d005b464c5164166547afc9e13b.png" alt=""><br>　　Bayesian公式下的p(X)是个Normalizer，或者叫做marginal probability。在\theta离散的情况下，p(X)就是\theta为不同值的时候，p(X|\theta)的求和。比如，如果我们事先估计硬币抛出正面的概率只可能是0.5或者0.8，那么p(X) = p(X|\theta=0.5)+p(X|\theta=0.8)，计算时分别将\theta=0.5和\theta=0.8代入到7中的公式中。而如果我们用Beta Distribution，\theta的概率分布在[0,1]之间是连续的，所以要用积分。</p>
<p><img src="/images/algo/j48e8020e87f818d9414e03ffb9fcf248.png" alt=""></p>
<p>　　p(\theta)是个Beta Distribution，那么在观测到X=抛5次硬币中有3个head的事件后，p(\theta|X)依旧是个Beta Distribution！只是这个概率分布的形状因为观测的事件而发生了变化。<br><img src="/images/algo/j0eca37b51f989944703ffbabadb40086.png" alt=""></p>
<p>　　因为观测前后，对\theta估计的概率分布均为Beta Distribution，这就是为什么使用Beta Distribution方便我们计算的原因了。当我们得知p(\theta|X)=Beta(\theta|a+3, b+2)后，我们就只要根据Beta Distribution的特性，得出\theta最有可能等于多少了。（即\theta等于多少时，观测后得到的Beta distribution有最大的概率密度）。例如下图，仔细观察新得到的Beta Distribution，和（5）中的概率分布对比，发现峰值从0.8左右的位置移向了0.7左右的位置。这是因为新观测到的数据中，5次有3次是head（60%），这让我们觉得，\theta没有0.8那么高。但由于我们之前觉得\theta有0.8那么高，我们觉得抛出head的概率肯定又要比60%高一些！这就是Bayesian方法和普通的统计方法不同的地方。我们结合自己的先验概率和观测结果来给出预测。</p>
<p><img src="/images/algo/j01a0b8b112291e2355890ac32572b01b.png" alt=""></p>
<p>　　如果我们投的不是硬币，而是一个多面体（比如筛子），那么我们就要使用Dirichlet Distribution了。使用Dirichlet Distributio的目的，也是为了让观测后得到的posterior probability依旧是Dirichlet Distribution。比如，我们抛掷一个三面体。抛出这三个面的概率分别为\theta_1, \theta_2和\theta_3。不论\theta_1, \theta_2和\theta_3如何分布，它们相加必须等于1。那它们的概率分布，是在一个立体的空间里的一个面。这个面由\theta_1+\theta_2+\theta_3=1表示。这个面上的任意一点，表示某种\theta_1, \theta_2和\theta_3组合的概率密度。下三图分别由不同的\alpha vector初始化得到不同的Dirichlet Distribution，红颜色代表概率密度较大，蓝颜色的区域概率密度较小。</p>
<p><img src="/images/algo/j3f8307ef170c6664eea5996932322a29.png" alt=""><br>　　Dirichlet Distribution和Beta Distribution都叫做Conjugate Prior。根据你的likelihood function，你可以选择对应的conjugate prior作为你对p(\theta)事先的估计。<br><img src="/images/algo/j3481aac389b57152d20380150d0abd4a.png" alt=""><br>转自：<a href="http://maider.blog.sohu.com/306392863.html" target="_blank" rel="external">http://maider.blog.sohu.com/306392863.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/beta-md/" data-id="ciuh3332l000dcqjh5osxc0x6" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/beta-md/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-other/nitian-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/other/nitian-md/">忠诚度越高买东西越贵</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/other/nitian-md/">
      <time datetime="2015-09-03T06:01:28.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/other/">other</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>　　引言：马云曾说，阿里巴巴本质上就是一家数据公司，做淘宝的目的也不是为了卖货，而是获得所有零售的数据和制造业的数据；做物流也不仅仅为了送包裹，而是要把这些数据合在一起。而亚马逊公司作为美国最大的一家网络电子商务公司，是网络上最早开始经营电子商务的公司之一，20年的持续发展关键也离不开对数据的分析。如今，我们正从IT时代走向DT时代，即从information technology转向data technology。</p>
<p>　　先问大家一个问题，AB两个顾客同时想买某个品牌的东西，其中A顾客对这个品牌非常喜欢，B是新顾客。如果你是这个品牌的经营者的话，你会卖给谁更贵（假设不是标准定价）？</p>
<p>　　答案是A，我们很多人的观点是我们一定要对老顾客好一些，给他们最优的待遇。这其实是从消费者的角度出发思考，其实从经营的角度来说，忠诚度越高我们反而应该卖得更贵，因为企业经营是追求利润最大化（互联网思维的企业除外哈），另外忠诚度高的顾客不用太担心流失。</p>
<p>　　欺负老顾客，这是一个人艰不拆的真理，会让很多人眼泪忍不住的流下来。其实现在不就是这样的吗？首次打车的顾客免单，第一次购买电影票补贴，第一次消费打折等等。只是这些我们能接受，我们认为合理，接下来讲一个真实的差异化定价的案例。</p>
<h3 id="u4E9A_u9A6C_u900A_u5DEE_u5F02_u5316_u5B9A_u4EF7_u6D4B_u8BD5"><a href="#u4E9A_u9A6C_u900A_u5DEE_u5F02_u5316_u5B9A_u4EF7_u6D4B_u8BD5" class="headerlink" title="亚马逊差异化定价测试"></a>亚马逊差异化定价测试</h3><p>　　为提高在主营产品上的赢利，亚马逊在2000年9月中旬开始了著名的差别定价实验。他们选择了68种DVD碟片进行动态定价试验。试验当中，亚马逊根据潜在客户的人口统计资料、在亚马逊的购物历史、上网行为以及上网使用的软件系统确定对这68种碟片的报价水平。</p>
<p>　　例如，名为《泰特斯》（Titus）的碟片对新顾客的报价为22.74美元，而对那些对该碟片表现出兴趣的老顾客的报价则为26.24美元。通过这一定价策略，部分顾客付出了比其他顾客更高的价格，亚马逊因此提高了销售的毛利率。（网络购物可以做到千人千面，每个人看到的页面不一样，价格也可以不一样）</p>
<p>　　但是好景不长，这一差别定价策略实施不到一个月，就有细心的消费者发现了这一秘密，通过在名为DVDTalk 的音乐爱好者社区的交流，成百上千的DVD消费者知道了此事，那些付出高价的顾客当然怨声载道，纷纷在网上以激烈的言辞对亚马逊的做法进行口诛笔伐，有人甚至公开表示以后绝不会在亚马逊购买任何东西。更不巧的是，由于亚马逊前不久才公布了它对消费者在网站上的购物习惯和行为进行了跟踪和记录，因此，这次事件曝光后，消费者和媒体开始怀疑亚马逊是否利用其收集的消费者资料作为其价格调整的依据，这样的猜测让亚马逊的价格事件与敏感的网络隐私问题联系在了一起。最后的结局是亚马逊道歉，然后将差价退给了那些买贵了的顾客。这件事虽然以失败告终，但是这种差异化定价的思路却是可以借鉴的。</p>
<p>　　放眼望去，我们身边到处都是差异化定价的案例：菜市场的小贩看人下菜单，不同顾客买到的机票价格都不同，会员和非会员的价格也不一样，买的多和买得少价格也不一样。唯一不一样的是，这些差异化定价是按照我们常人的逻辑在运行，如买的多就应该便宜。亚马逊的案例恰恰和常规相反，但确实是经营的需要。那么如何做到根据需求差异定价呢？这种需求差异主要体现在时间、地点、消费对象之间三个方面。“时间就是金钱”在这点上彻底体现出来了，新手机上市，如果你是品牌忠实的追随者，那你必须付高价才能得到它，反之，你可以慢慢等待，等到价格降到你的目标价位的时候出手，有些地方高峰电价和平峰电价不一样，机票的价格和距起飞时间成反比，旅游景区的淡旺季门票差异等，这都是需求中利用时间差异的定价方法。</p>
<p>　　新开一个超市如果附近没有竞争对手和有竞争对手时的定价策略是不一样的，一瓶同样品牌的啤酒在超市和酒吧的价格大相径庭，演唱会前排的价格高于后排的价格，海景房的价格比山景房的价格贵等等，这都是需求中地点差异的定价方法。消费对象的定价差异更多体现在会员顾客和非会员顾客的价格差异上，以及女性相对于男性对价格敏感的差异上。未来随着科技的进步会逐渐发展到个体的定价差异上，例如零售商根据你购买或维修冰箱的数据，发现你的冰箱到了更换的时候，就可以给你寄一张200元的冰箱代金券，这样你的价格就和其他人不一样了。需要注意的是差异定价不能引起顾客的反感，需要透彻分析其中的风险。针对亚马逊这个案例，错就错在互联网购物价格太透明了，一旦穿帮就是丑闻。那怎么让顾客不反感，同时企业又能贯彻忠诚度高的顾客价格越贵的原则呢？答案见下图。</p>
<p><img src="/images/bb/792c43ea9c648c61a22c1a50a6439b15.jpg" alt=""><br>看明白了吗？</p>
<p>没看明白的话我就给大家点破吧！</p>
<p>将抽奖结果关联用户数据！</p>
<p>　　怎么理解这句话？就是当买家在网站买东西的时候，旁边放一个抽奖链接，买家可以根据抽奖结果来付款，抽奖结果又减30，减50，一分不减等选项。当买家在按下抽奖按钮的同时，后台大数据就开始工作了，根据你以往的购买数据很快可以算出你对这个商品的忠诚度，喜好度，需要的紧迫性等。当发现你从来没有买过类似的商品的话，就会让你中“大奖”。当发现你是优质买家，那不好意思了，一分不减。这样是不是每个人都高高兴兴的了？你还以为抽奖结果是随机的呢。其实买的永远没有卖的精！你可以看看现在淘宝、京东等消费性电商培都用了这一招！</p>
<h3 id="u6BD4_u8F83_u6709_u4EF7_u503C_u7684_u8BC4_u8BBA_uFF1A"><a href="#u6BD4_u8F83_u6709_u4EF7_u503C_u7684_u8BC4_u8BBA_uFF1A" class="headerlink" title="比较有价值的评论："></a>比较有价值的评论：</h3><ol>
<li><p>就是利用信息不对称赚钱，不过互联网就是要消除信息不对称，所以这条路其实在互联网上是走不通的</p>
</li>
<li><p>互联网时代，价格是透明的，跨店比价购买的成本近乎为零，同一件商品如果亚马逊卖50，京东卖49，天猫卖45，你猜消 费者会怎么选择？</p>
</li>
<li><p>杀熟很危险，如果用户知道了，可能会对品牌造成致命的影响，而你得到的不过蝇头小利。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/other/nitian-md/" data-id="ciuh33345001acqjh4z0cs2tc" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/other/nitian-md/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-algo/baysian-bandit-application-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/baysian-bandit-application-md/">Bayesian Bandits原理及在互联网广告行业的应用</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/baysian-bandit-application-md/">
      <time datetime="2015-09-03T05:48:13.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="1-_The_Multi-Armed_Bandit_Problem"><a href="#1-_The_Multi-Armed_Bandit_Problem" class="headerlink" title="1. The Multi-Armed Bandit Problem"></a>1. The Multi-Armed Bandit Problem</h2><p>Suppose you are faced with N slot machines (colourfully called multi-armed bandits). Each bandit has an unknown probability of distributing a prize (assume for now the prizes are the same for each bandit, only the probabilities differ). Some bandits are very generous, others not so much. Of course, you don’t know what these probabilities are. By only choosing one bandit per round, our task is devise a strategy to maximize our winnings.</p>
<p>Of course, if we knew the bandit with the largest probability, then always picking this bandit would yield the maximum winnings. So our task can be phrased as “Find the best bandit, and as quickly as possible”.</p>
<p>The task is complicated by the stochastic nature of the bandits. A suboptimal bandit can return many winnings, purely by chance, which would make us believe that it is a very profitable bandit. Similarly, the best bandit can return many duds. Should we keep trying losers then, or give up?</p>
<p>A more troublesome problem is, if we have a found a bandit that returns pretty good results, do we keep drawing from it to maintain our pretty good score, or do we try other bandits in hopes of finding an even-better bandit? This is the exploration vs. exploitation dilemma.</p>
<h2 id="2-_Applications"><a href="#2-_Applications" class="headerlink" title="2. Applications"></a>2. Applications</h2><p>The Multi-Armed Bandit problem at first seems very artificial, something only a mathematician would love, but that is only before we address some applications:</p>
<p>Internet display advertising: companies have a suite of potential ads they can display to visitors, but the company is not sure which ad strategy to follow to maximize sales. This is similar to A/B testing, but has the added advantage of naturally minimizing strategies that do not work (and generalizes to A/B/C/D… strategies)</p>
<ol>
<li>Ecology: animals have a finite amount of energy to expend, and following certain behaviours has uncertain rewards. How does the animal maximize its fitness?</li>
<li>Finance: which stock option gives the highest return, under time-varying return profiles.</li>
<li>Clinical trials: a researcher would like to find the best treatment, out of many possible treatments, while minimizing losses.</li>
</ol>
<p>Many of these questions above are fundamental to the application’s field. It turns out the optimal solution is incredibly difficult, and it took decades for an overall solution to develop. There are also many approximately-optimal solutions which are quite good. The one I wish to discuss is one of the few solutions that can scale incredibly well. The solution is known asBayesian Bandits.</p>
<h2 id="3-_A_Proposed_Solution"><a href="#3-_A_Proposed_Solution" class="headerlink" title="3. A Proposed Solution"></a>3. A Proposed Solution</h2><p>Any proposed strategy is called an online algorithm (not in the internet sense, but in the continuously-being-updated sense), and more specifically a reinforcement learning algorithm. The algorithm starts in an ignorant state, where it knows nothing, and begins to acquire data by testing the system. As it acquires data and results, it learns what the best and worst behaviours are (in this case, it learns which bandit is the best). With this in mind, perhaps we can add an additional application of the Multi-Armed Bandit problem:</p>
<p>Psychology: how does punishment and reward effect our behaviour? How do humans’ learn?<br>The Bayesian solution begins by assuming priors on the probability of winning for each bandit. In our vignette we assumed complete ignorance of the these probabilities. So a very natural prior is the flat prior over 0 to 1. The algorithm proceeds as follows:</p>
<p>For each round,</p>
<ol>
<li>Sample a random variable Xb from the prior of bandit b, for all b.</li>
<li>Select the bandit with largest sample, i.e. select bandit B=argmaxXb.</li>
<li>Observe the result of pulling bandit B, and update your prior on bandit B.</li>
<li>Return to 1.</li>
</ol>
<p>That’s it. Computationally, the algorithm involves sampling from N distributions. Since the initial priors are Beta(α=1,β=1) (a uniform distribution), and the observed result X (a win or loss, encoded 1 and 0 respectfully) is Binomial, the posterior is a Beta(α=1+X,β=1+1−X)(see here for why to is true). </p>
<p>To answer a question from before, this algorithm suggests that we should not discard losers, but we should pick them at a decreasing rate as we gather confidence that there exist better bandits. This follows because there is always a non-zero chance that a loser will achieve the status of B, but the probability of this event decreases as we play more rounds (see figure below). Below is an implementation of the Bayesian Bandits strategy (which can be skipped for the less Pythonic-ly interested).</p>
<pre><code class="python">from pymc import rbeta

rand = np.random.rand

class Bandits(object):
    &quot;&quot;&quot;
    This class represents N bandits machines.

    parameters:
        p_array: a (n,) Numpy array of probabilities &gt;0, &lt;1.

    methods:
        pull( i ): return the results, 0 or 1, of pulling 
                   the ith bandit.
    &quot;&quot;&quot;
    def __init__(self, p_array):
        self.p = p_array
        self.optimal = np.argmax(p_array)

    def pull( self, i ):
        #i is which arm to pull
        return rand() &lt; self.p[i]

    def __len__(self):
        return len(self.p)


class BayesianStrategy( object ):
    &quot;&quot;&quot;
    Implements a online, learning strategy to solve
    the Multi-Armed Bandit problem.

    parameters:
        bandits: a Bandit class with .pull method

    methods:
        sample_bandits(n): sample and train on n pulls.

    attributes:
        N: the cumulative number of samples
        choices: the historical choices as a (N,) array
        bb_score: the historical score as a (N,) array

    &quot;&quot;&quot;

    def __init__(self, bandits):

        self.bandits = bandits
        n_bandits = len( self.bandits )
        self.wins = np.zeros( n_bandits )
        self.trials = np.zeros(n_bandits )
        self.N = 0
        self.choices = []
        self.bb_score = []


    def sample_bandits( self, n=1 ):

        bb_score = np.zeros( n )
        choices = np.zeros( n )

        for k in range(n):
            #sample from the bandits&#39;s priors, and select the largest sample
            choice = np.argmax( rbeta( 1 + self.wins, 1 + self.trials - self.wins) )

            #sample the chosen bandit
            result = self.bandits.pull( choice )

            #update priors and score
            self.wins[ choice ] += result
            self.trials[ choice ] += 1
            bb_score[ k ] = result 
            self.N += 1
            choices[ k ] = choice

        self.bb_score = np.r_[ self.bb_score, bb_score ]
        self.choices = np.r_[ self.choices, choices ]
        return
</code></pre>
<p>Below we present a visualization of the algorithm sequentially learning the solution. In the figure below, the dashed lines represent the true hidden probabilities, which are (0.85, 0.60, 0.75)(this can be extended to many more dimensions, but the figure suffers, so I kept it at 3).</p>
<p><img src="/images/bb/updating2.png" alt=""></p>
<p>Note that we don’t real care how accurate we become about inference of the hidden probabilities — for this problem we are more interested in choosing the best bandit (or more accurately, becoming more confident in choosing the best bandit). For this reason, the distribution of the red bandit is very wide (representing ignorance about what that hidden probability might be) but we are reasonably confident that it is not the best, so the algorithm chooses to ignore it.</p>
<h3 id="u51E0_u7BC7_u4ECB_u7ECDBayesian_Bandits_u7684_u539F_u7406_u7684_u6587_u7AE0_uFF1A"><a href="#u51E0_u7BC7_u4ECB_u7ECDBayesian_Bandits_u7684_u539F_u7406_u7684_u6587_u7AE0_uFF1A" class="headerlink" title="几篇介绍Bayesian Bandits的原理的文章："></a>几篇介绍Bayesian Bandits的原理的文章：</h3><ol>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html</a></li>
<li>在线演示博弈过程： <a href="https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/" target="_blank" rel="external">https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/</a></li>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html</a></li>
<li><a href="http://camdp.com/blogs/multi-armed-bandits" target="_blank" rel="external">http://camdp.com/blogs/multi-armed-bandits</a></li>
<li>贝叶斯书籍：<a href="https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers" target="_blank" rel="external">https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/" data-id="ciuh3332i000bcqjhe5z7q92l" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bandits/">Bandits</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/baysian-bandit-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/baysian-bandit-md/">Bayesian Bandits – optimizing click throughs with statistics</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/baysian-bandit-md/">
      <time datetime="2015-09-03T05:36:48.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>Great news! A murder victim has been found. No slow news day today! The story is already written, now a title needs to be selected. The clever reporter who wrote the story has come up with two potential titles – “Murder victim found in adult entertainment venue” and “Headless Body found in Topless Bar”. (The latter title is one I’ve shamelessly stolen from the NY Daily News.) Once upon a time, deciding which title to run was a matter for a news editor to decide. Those days are now over – the geeks now rule the earth. Title selection is now primarily an algorithmic problem, not an editorial one.</p>
<p>One common approach is to display both potential versions of the title on the homepage or news feed, and measure the Click Through Rate (CTR) of each version of the title. At some point, when the measured CTR for one title exceeds that of the other title, you’ll switch to the one with the highest for all users. Algorithms for solving this problem are called bandit algorithms.</p>
<p>In this blog post I’ll describe one of my favorite bandit algorithms, the Bayesian Bandit, and show why it is an excellent method to use for problems which give us more information than typical bandit algorithms.</p>
<p>Unless you are already familiar with Bayesian statistics and beta distributions, I strongly recommend reading the previous blog post. That post provides much introductory material, and I’ll depend on it heavily.</p>
<h2 id="1-_The_problem_to_be_solved_2C_and_the_underlying_model"><a href="#1-_The_problem_to_be_solved_2C_and_the_underlying_model" class="headerlink" title="1. The problem to be solved, and the underlying model"></a>1. The problem to be solved, and the underlying model</h2><hr>
<p>Ultimately the problem we want to solve is the following. Consider an article being published on a website. The author or editor has come up with several possible titles – “Murder victim found in adult entertainment venue”, “Headless Body found in Topless Bar”, etc. We want to choose the title with the best click through rate (CTR). Let us represent each CTR by θi – i.e., θi is the true probability that an individual user will click on the i-th title. As a simplifying assumption, we assume that these rates θi do not change over time. It is important to note that we don’t actually know what θi is – if we did, we could simply choose i for which θi was largest and move on.</p>
<p>The goal of the bandit algorithm is to do the following. To begin with, it should display all possible titles to a random selection of users, and measure which titles are clicked on more frequently. Over time, it will use these observations to infer which articles have the higher CTR. Then, once the estimation of the CTR becomes more precise, it will preferentially display articles with the higher CTR.</p>
<h2 id="2-_The_Bayesian_Approach"><a href="#2-_The_Bayesian_Approach" class="headerlink" title="2. The Bayesian Approach"></a>2. The Bayesian Approach</h2><hr>
<p>In the model described above, we have N possible story titles, each of which has a click through rate θi. Unfortunately we do not know what θi is. As the astute reader can guess from the title, we are following a Bayesian approach, so we will construct a probability distribution which represents our belief about what the actual value of θi is.<br><img src="/images/bb/beliefs_about_theta.png" alt=""><br>In the figure above, we believe that θi is somewhere between 0.1 and 0.7, with values of 0.3-0.4 being considerably more likely than values of 0.1-0.2 or 0.6-0.7. For those who forgot STATS 101, the area under this curve between the points a and b is the probability thta θi lies between a and b. I.e.:<br><img src="/images/bb/11.png" alt=""><br>The basic idea behind Bayesian methods is to update our beliefs based on evidence. As we gather more data by showing different titles to other users and observing click throughs, we can incrementally narrow the width of the probability distribution.</p>
<p>As in all Bayesian inference, we need to choose a prior. The prior is something we believe to be true before we have any evidence – i.e., before we have shown the title to any visitors. This is just a starting point – after enough evidence is gathered, our prior will play a very minimal role in what we actually believe. Choosing a good prior is important both for mathematical simplicity, and because if your prior is accurate, you don’t need as much evidence to get the correct answer.</p>
<p>I’ll follow the approach I described in a previous blog post, and I’ll use a beta distribution as the prior:<br><img src="/images/bb/31.png" alt=""><br>The parameters αi,βi&gt;1 are the prior parameters. One reasonable choice is αi=βi=1, which amounts to the uniform distribution on [0,1]. What this means is that we are assuming that all possible values of θi are equally likely. Depending on the circumstances (which I’ll explain shortly), we might want to choose other possible values.</p>
<h2 id="3-_Updating_our_beliefs"><a href="#3-_Updating_our_beliefs" class="headerlink" title="3. Updating our beliefs"></a>3. Updating our beliefs</h2><p>Now we address the question of using evidence. After showing title i to ni visitors, we have observed that si of them have actually clicked on the title. We now want to compute theposterior distribution, which is to say the distribution that represents our beliefs after we have evidence.</p>
<p>I did a little bit of algebra previously, in which I showed that if the prior is fαi,βi(θi), then the posterior distribution is:<br><img src="/images/bb/21.png" alt=""><br>The key idea here is that to update our probability distribution describing θi, we need only update the parameters of our beta distribution.</p>
<p>So what does this mean in practice? As we run more experiments, our probability distribution on where θi lives becomes sharper:</p>
<p><img src="/images/bb/beta_distribution_evolution.png" alt=""><br>Before we run any experiments, θi could be anything (as represented by the blue line). Once we have run 700 experiments, yielding 175 click throughs, we are reasonably confident that θi lives roughly between 0.2 and 0.3.</p>
<p>What we’ve done so far is figured out how to estimate what our click through rates actually are based on empirical evidence. But that doesn’t actually give us a method of optimizing them yet.</p>
<h2 id="4-_Optimizing_click_throughs"><a href="#4-_Optimizing_click_throughs" class="headerlink" title="4. Optimizing click throughs"></a>4. Optimizing click throughs</h2><p>Now that we have a method of representing our beliefs about CTRs, it is useful to construct an algorithm to identify the best ones. There are many popular choices – I’ve written about the UCB Algorithm before, and I consider it a good choice.</p>
<p>But my new favorite method is a Monte Carlo method which I’ll describe now.</p>
<p>The ultimate goal of the bandit algorithm is to display to the user whichever title has the highest CTR. One method of estimating the CTRs of the articles is to sample the posterior distribution. I.e., suppose we have two possible titles, from which we have drawn n0=200,s0=64and n1=180,n2=40. Then one possible set of samples we might observe is this:</p>
<p><img src="/images/bb/beta_distribution_sampling1.png" alt=""></p>
<p>For title 0, our sample of θ0 has worked out to be 0.35, while our sample of θ1 is only 0.28. Since θ0=0.35&gt;θ1=0.28, we will display title 0 to the user.</p>
<p>However, there was no guarantee that things worked out this way. It was possible, although less likely, that θ1 could come out larger than θ0:<br><img src="/images/bb/beta_distribution_sampling2.png" alt=""><br>In this case, we would have displayed title 1 to the user rather than title 0.</p>
<p>The net result is that for overlapping probability distributions, we will display the title with the larger expected CTR the majority of the time. But occasionally, we will draw from the other distributions simply because it is within the realm of possibility that they are greater.</p>
<p>As we gather more data our probability distributions will become narrower and a clear winner will become apparent. When this occurs, we will almost surely choose the winner:<br><img src="/images/bb/beta_distribution_sampling3.png" alt=""><br>In python, the algorithm looks like this:</p>
<p>The results of this algorithm are exactly what any good bandit algorithm should do. I ran the following simulation, giving the beta bandit two titles – title 0 had a CTR of 0.25, title 1 had a CTR of 0.35. To start with, both titles were displayed to the user with roughly equal probability. Over time, evidence accumulated that title 1 was considerably better than title 0. At this point the algorithm switched to displaying primarily title 1, and the overall CTR of the experiment converged to 0.35 (the optimal CTR).</p>
<p><img src="/images/bb/beta_bandit_results.png" alt=""></p>
<p>Source code to generate this graph is available here. This method is called Thompson Sampling and is a a fairly popular method in Bayesian AI techniques. For the remainder of this post, I’ll call this method the Bayesian Bandit.</p>
<h2 id="5-Incorporating_common_sense"><a href="#5-Incorporating_common_sense" class="headerlink" title="5.Incorporating common sense"></a>5.Incorporating common sense</h2><p>Anyone with common sense is now scoffing at the geekiness embodied in this post. Even before using statistics, it was fairly obvious that “Headless Body found in Topless Bar” was going to beat “Murder victim found in adult entertainment venue”. The former just sounds catchier and any good editor would run with it.</p>
<p>The wonderful thing about Bayesian methods is that we can modify them to take into account our prior knowledge. Suppose we believe editors intuition is a real thing – can we quantify it? Certainly. We can do this with a fairly simple experiment. We require editors to rate a collection of titles as “catchy” or “not catchy”, run them on the site, and then measure the CTR of the “catchy” and “not catchy” samples. Suppose we did such an experiment, and observed the following aggregate results:</p>
<p><img src="/images/bb/empirical_prior.png" alt=""></p>
<p>This isn’t a solid win for the editor – some catchy titles have low CTRs, and some boring titles have good CTRs. But nevertheless, it’s better for a story to have catchy title than not.</p>
<p>What we want to do is incorporate this information into our bandit algorithm. The beauty of a Bayesian method is that it gives you a clear and meaningful place to plug this information in, namely the prior. In contrast, for many other methods (e.g., UCB) it’s somewhat difficult to do this – there is no obvious parameter to tune as a result of our prior empirical data.</p>
<p>The first step is to fit a theoretical distribution to the empirical data. Due to the fact that I chose the “empirical” (i.e., made up) data to be very nice, a beta distribution fits well [1] – specifically beta distributions with (α0,β0)=(9,20) and (α1,β1)=(4,20).<br><img src="/images/bb/theoretical_prior.png" alt=""></p>
<p>Then the only modification needed to the algorithm is to plug these variables into the prior:<br><img src="/images/bb/41.png" alt=""><br>Everything else remains unchanged. In terms of modifications to source code, this is only a very small change to the previous code – an implementation can be found here.</p>
<h2 id="6-_Empirics_of_including_priors"><a href="#6-_Empirics_of_including_priors" class="headerlink" title="6. Empirics of including priors"></a>6. Empirics of including priors</h2><p>To measure the benefits of incorporating priors into the Bayesian bandit, I ran some numerical experiments, the source code of which is available in this github gist. The methodology was the following.</p>
<p>To compare the Bayesian bandit with priors to that without, I drew a pair (θ0,θ1) from the prior distribution given above. For each pair, I then ran the Bayes Bandit with and without priors for this pair theta, for k trials. This is modelling the scenario that we have k page views on our homepage, and we can only leave a story on the homepage for 1 day.</p>
<p>I then repeated the experiment for 1000 different possible days, or equivalently for 1000 different pairs of (θ0,θ1). I then computed the average gain per page view over all trials and all days.</p>
<p>The result is the following. If we get 50 page views/day (i.e., the Bayes Bandit has very little data to use), the prior gives us a big gain. Without prior knowledge, the Bandit achieved a gain of 0.3749 on average, whereas the bandit with prior knowledge achieved a gain of 0.4274. If we run 150 experiments, the Bayes Bandit improves significantly – it achieves a gain of 0.40. If we run 300 experiments, the Bayes Bandit improves to 0.4146, while the bandit with priors improves to 0.4296. If we get 1000 page views/day, the Bayes Bandit improves to 0.4211, while the bandit with priors gains 0.4249.</p>
<p>The net result is the following – incorporating priors into the Bayes Bandit is an excellent way to improve your results when you don’t have a large number data points to use to train the bandit. If you have a lot of data points, you don’t need strong priors (but they still help a little).</p>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7.Conclusion"></a>7.Conclusion</h2><p>Bandit algorithms are a great way of optimizing many factors of your website. There are many good options – I’ve written about UCB before and consider it a great choice. But if you have other information you want to include, consider using the Bayesian Bandit. It’s simple to implement, straightforward to use, and very importantly it’s also straightforward to extend.</p>
<p>It’s also important to note that the theoretical properties of the Bayesian Bandit (namely logarithmic regret) have been proven. So asymptotically, you lose nothing by using it. There are also attempts at constructing a Bayesian UCB algorithm – I don’t currently understand it well enough to comment.</p>
<p>I’ve written other articles related to this post. I have one post comparing bandit algorithms to a/b testing. I also I wrote about measuring a changing conversion rate, which provides an alternate algorithm for computing the posterior distribution if your conversion rate is not constant.</p>
<p>[1] If a single Beta distribution doesn’t fit, one can also use a convex combination of Beta distributions. The math works out just as nicely.</p>
<p>P.S. After I published this blog post, this related article was also pointed out to me, as was this online simulation of the Bayesian bandit.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/" data-id="ciuh3332f0007cqjh070qcxbm" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bandits/">Bandits</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-dev/hive-udf-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/dev/hive-udf-md/">Hive UDF开发</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/dev/hive-udf-md/">
      <time datetime="2015-09-03T04:49:45.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>Hive进行UDAF开发，相对要比UDF复杂一些，不过也不是很难。请看一个例子:</p>
<pre><code class="java">package org.hrj.hive.udf;

import org.apache.hadoop.hive.ql.exec.UDAFEvaluator;
import org.apache.hadoop.hive.serde2.io.DoubleWritable;

public class UDAFSum_Sample extends NumericUDAF {
    public static class Evaluator implements UDAFEvaluator {
        private boolean mEmpty;
        private double mSum;
        public Evaluator() {
            super();
            init();
        }

        public void init() {
            mSum = 0;
            mEmpty = true;
        }

        public boolean iterate(DoubleWritable o) {
            if (o != null) {
                mSum += o.get();
                mEmpty = false;
            }
            return true;
        }

        public DoubleWritable terminatePartial() {
            // This is SQL standard - sum of zero items should be null.
            return mEmpty ? null : new DoubleWritable(mSum);
        }

        public boolean merge(DoubleWritable o) {
            if (o != null) {
                mSum += o.get();
                mEmpty = false;
            }
            return true;
        }

        public DoubleWritable terminate() {
            // This is SQL standard - sum of zero items should be null.
            return mEmpty ? null : new DoubleWritable(mSum);
        }
    }
}
</code></pre>
<p>1.将java文件编译成Sum_Sample.jar</p>
<p>2.进入hive</p>
<pre><code class="bash">
hive&gt; add jar Sum_sample.jar;

hive&gt; create temporary function sum_test as &#39;com.hrj.hive.udf.UDAFSum_Sample&#39;;

hive&gt; select sum_test(t.num) from t;

hive&gt; drop temporary function sum_test;

hive&gt; quit;
</code></pre>
<p>关于UDAF开发注意点：</p>
<p>1.需要import org.apache.hadoop.hive.ql.exec.UDAF以及org.apache.hadoop.hive.ql.exec.UDAFEvaluator,这两个包都是必须的</p>
<p>2.函数类需要继承UDAF类，内部类Evaluator实现UDAFEvaluator接口</p>
<p>3.Evaluator需要实现 init、iterate、terminatePartial、merge、terminate这几个函数</p>
<pre><code>1）init函数类似于构造函数，用于UDAF的初始化

2）iterate接收传入的参数，并进行内部的轮转。其返回类型为boolean

3）terminatePartial无参数，其为iterate函数轮转结束后，返回乱转数据，iterate和terminatePartial类似于hadoop的Combiner

4）merge接收terminatePartial的返回结果，进行数据merge操作，其返回类型为boolean

5）terminate返回最终的聚集函数结果
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/dev/hive-udf-md/" data-id="ciuh3333f000vcqjhn5v3yami" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/dev/hive-udf-md/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/16/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="page-number" href="/page/16/">16</a><span class="page-number current">17</span><a class="page-number" href="/page/18/">18</a><a class="page-number" href="/page/19/">19</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/18/">下一页 &raquo;</a>
      </nav>
    </section>
      
        <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul id="recent-post" class="">
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/10/15/algo/ml/OnebyOne_Convolution/" class="thumbnail">
  
    <span style="background-image:url(/images/dl/full_padding_no_strides_transposed.gif
)" alt="One by One [ 1 x 1 ] Convolution - counter-intuitively useful" class="thumbnail-image"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
              <p class="item-title"><a href="/2016/10/15/algo/ml/OnebyOne_Convolution/" class="title">One by One [ 1 x 1 ] Convolution - counter-intuitively useful</a></p>
              <p class="item-date"><time datetime="2016-10-14T16:00:00.000Z" itemprop="datePublished">2016-10-15</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/10/11/dev/node_essentail/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/10/11/dev/node_essentail/" class="title">Node/npm安装基本问题</a></p>
              <p class="item-date"><time datetime="2016-10-11T12:19:56.000Z" itemprop="datePublished">2016-10-11</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/10/10/dev/esop/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/10/10/dev/esop/" class="title">Elasticsearch-索引优化</a></p>
              <p class="item-date"><time datetime="2016-10-10T02:19:56.000Z" itemprop="datePublished">2016-10-10</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/09/18/algo/ml/categorical_features/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
              <p class="item-title"><a href="/2016/09/18/algo/ml/categorical_features/" class="title">Handling categorical features</a></p>
              <p class="item-date"><time datetime="2016-09-17T16:00:00.000Z" itemprop="datePublished">2016-09-18</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/09/18/algo/sklearn/Dummification_vs_encoding/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
              <p class="item-title"><a href="/2016/09/18/algo/sklearn/Dummification_vs_encoding/" class="title">XGBoost Categorical Variables - Dummification vs encoding</a></p>
              <p class="item-date"><time datetime="2016-09-17T16:00:00.000Z" itemprop="datePublished">2016-09-18</time></p>
            </div>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hash/">Hash</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Photo/">Photo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SQL/">SQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ads/">ads</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c++</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/dev/">dev</a><span class="category-list-count">33</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/github/">github</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/internet/">internet</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/kaggle/">kaggle</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/system/">system</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/travel/">travel</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Apache/" style="font-size: 10px;">Apache</a> <a href="/tags/Bandits/" style="font-size: 12.5px;">Bandits</a> <a href="/tags/Elasticsearch-docker/" style="font-size: 10px;">Elasticsearch, docker</a> <a href="/tags/FlatBuffers/" style="font-size: 10px;">FlatBuffers</a> <a href="/tags/Google/" style="font-size: 10px;">Google</a> <a href="/tags/Granger-causality/" style="font-size: 10px;">Granger causality</a> <a href="/tags/GridSearchCV/" style="font-size: 10px;">GridSearchCV</a> <a href="/tags/HTTPS/" style="font-size: 10px;">HTTPS</a> <a href="/tags/Jquery/" style="font-size: 10px;">Jquery</a> <a href="/tags/MapReduce/" style="font-size: 10px;">MapReduce</a> <a href="/tags/Mock/" style="font-size: 10px;">Mock</a> <a href="/tags/Monument-Vallay/" style="font-size: 10px;">Monument Vallay</a> <a href="/tags/Mysql/" style="font-size: 12.5px;">Mysql</a> <a href="/tags/PPTP-vpn/" style="font-size: 12.5px;">PPTP, vpn</a> <a href="/tags/Photoshop/" style="font-size: 10px;">Photoshop</a> <a href="/tags/Pipeline/" style="font-size: 10px;">Pipeline</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/ad/" style="font-size: 10px;">ad</a> <a href="/tags/apache/" style="font-size: 10px;">apache</a> <a href="/tags/blade/" style="font-size: 10px;">blade</a> <a href="/tags/crontab/" style="font-size: 10px;">crontab</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/elasticsearch/" style="font-size: 12.5px;">elasticsearch</a> <a href="/tags/font/" style="font-size: 10px;">font</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/go/" style="font-size: 17.5px;">go</a> <a href="/tags/hashmap/" style="font-size: 10px;">hashmap</a> <a href="/tags/kaggle/" style="font-size: 20px;">kaggle</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/linux-ldd-依赖关系/" style="font-size: 10px;">linux, ldd, 依赖关系</a> <a href="/tags/lucene/" style="font-size: 10px;">lucene</a> <a href="/tags/nio/" style="font-size: 10px;">nio</a> <a href="/tags/pagerank/" style="font-size: 10px;">pagerank</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/swift-llvm/" style="font-size: 10px;">swift, llvm</a> <a href="/tags/前端/" style="font-size: 10px;">前端</a> <a href="/tags/广告/" style="font-size: 12.5px;">广告</a> <a href="/tags/开源，许可/" style="font-size: 10px;">开源，许可</a> <a href="/tags/澳门/" style="font-size: 10px;">澳门</a> <a href="/tags/监控，zabbix/" style="font-size: 10px;">监控，zabbix</a> <a href="/tags/贝叶斯/" style="font-size: 10px;">贝叶斯</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">三月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">六月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">二月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">十一月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">十月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">六月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">十一月 2013</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
  <div id="toTop" class="fa fa-chevron-up"></div>
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Li Jingpeng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
    </div>
  </div>
</footer>
    

<script type="text/javascript">
  var duoshuoQuery = {short_name:"lijingpeng"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>


<script src="//ajax.css.network/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>