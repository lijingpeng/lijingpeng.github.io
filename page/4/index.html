<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Frank</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="è®¡ç®—æœº ç½‘ç»œ äº’è”ç½‘">
<meta property="og:type" content="website">
<meta property="og:title" content="Frank">
<meta property="og:url" content="http://www.notehub.cn/page/4/index.html">
<meta property="og:site_name" content="Frank">
<meta property="og:description" content="è®¡ç®—æœº ç½‘ç»œ äº’è”ç½‘">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Frank">
<meta name="twitter:description" content="è®¡ç®—æœº ç½‘ç»œ äº’è”ç½‘">
  
  
    <link rel="icon" href="favicon.png">
  
  <link href='//fonts.css.network/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
  <link href="//fonts.css.network/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  

  
</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="/" id="logo"><i class="logo" style="background-image: url(/css/images/logo.jpg)"></i><span class="site-title">Frank</span></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/.">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      
        <nav id="sub-nav">
          <div class="profile" id="profile-nav">
            <a id="profile-anchor" href="javascript:;"><img class="avatar" src="/css/images/logo.png"><i class="fa fa-caret-down"></i></a>
          </div>
        </nav>
      
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"> </button><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
      </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tr>
        
          <td><a class="main-nav-link" href="/.">Home</a></td>
        
          <td><a class="main-nav-link" href="/archives">Archives</a></td>
        
          <td><a class="main-nav-link" href="/categories">Categories</a></td>
        
          <td><a class="main-nav-link" href="/tags">Tags</a></td>
        
          <td><a class="main-nav-link" href="/about">About</a></td>
        
        <td>
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
        </td>
      </tr>
    </table>
  </div>
</header>

    <div class="outer">
      
        <aside id="profile">
  <div class="inner profile-inner">
    <div class="base-info profile-block">
      <img id="avatar" src="/css/images/logo.png">
      <h2 id="name">Li Jingpeng</h2>
      <!-- <h3 id="title">undefined</h3> -->
      <span id="location"><i class="fa fa-map-marker"></i>Hangzhou, China</span>
      <a id="follow" href="Https://weibo.com/329299516">å…³æ³¨æˆ‘</a>
    </div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        110
        <span>æ–‡ç« </span>
      </div>
      <div class="article-info-block">
        42
        <span>æ ‡ç­¾</span>
      </div>
    </div>
    
    <div class="contact-info profile-block">
      <table class="contact-list">
        <tr>
          
          <td><a href="https://github.com/lijingpeng" target="_blank" title="github"><i class="fa fa-github"></i></a></td>
          
          <td><a href="#" target="_blank" title="twitter"><i class="fa fa-twitter"></i></a></td>
          
          <td><a href="#" target="_blank" title="facebook"><i class="fa fa-facebook"></i></a></td>
          
          <td><a href="/me@lijingpeng.org" target="_blank" title="email"><i class="fa fa-email"></i></a></td>
          
          <td><a href="/atom.xml" target="_blank" title="rss"><i class="fa fa-rss"></i></a></td>
          
        </tr>
      </table>
    </div>
    
    
  </div>
</aside>

      
      <section id="main">
      <article id="post-algo/sklearn/pipeline" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/23/algo/sklearn/pipeline/">sklearn pipelineç®€ä»‹</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/23/algo/sklearn/pipeline/">
      <time datetime="2016-08-23T05:48:13.000Z" itemprop="datePublished">2016-08-23</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/sklearn/">sklearn</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>Pipelineå¯ä»¥å°†è®¸å¤šç®—æ³•æ¨¡å‹ä¸²è”èµ·æ¥ï¼Œæ¯”å¦‚å°†ç‰¹å¾æå–ã€å½’ä¸€åŒ–ã€åˆ†ç±»ç»„ç»‡åœ¨ä¸€èµ·å½¢æˆä¸€ä¸ªå…¸å‹çš„æœºå™¨å­¦ä¹ é—®é¢˜å·¥ä½œæµã€‚ä¸»è¦å¸¦æ¥ä¸¤ç‚¹å¥½å¤„ï¼š  </p>
<ol>
<li>ç›´æ¥è°ƒç”¨fitå’Œpredictæ–¹æ³•æ¥å¯¹pipelineä¸­çš„æ‰€æœ‰ç®—æ³•æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹ã€‚  </li>
<li>å¯ä»¥ç»“åˆgrid searchå¯¹å‚æ•°è¿›è¡Œé€‰æ‹©</li>
</ol>
<p>ä¸‹é¢æ˜¯ä¸€ä¸ªå®˜æ–¹æ–‡æ¡£çš„ç¤ºä¾‹ï¼š</p>
<pre><code class="python">&gt;&gt;&gt; from sklearn.pipeline import Pipeline
&gt;&gt;&gt; from sklearn.svm import SVC
&gt;&gt;&gt; from sklearn.decomposition import PCA
&gt;&gt;&gt; estimators = [(&#39;reduce_dim&#39;, PCA()), (&#39;svm&#39;, SVC())]
&gt;&gt;&gt; clf = Pipeline(estimators)
&gt;&gt;&gt; clf
Pipeline(steps=[(&#39;reduce_dim&#39;, PCA(copy=True, n_components=None,
    whiten=False)), (&#39;svm&#39;, SVC(C=1.0, cache_size=200, class_weight=None,
    coef0=0.0, decision_function_shape=None, degree=3, gamma=&#39;auto&#39;,
    kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False))])
</code></pre>
<p>estimatorsä¸­å®šä¹‰äº†ä¸¤ä¸ªæ¨¡å‹ï¼Œä¸€ä¸ªæ˜¯PCAã€å¦ä¸€ä¸ªæ˜¯SVCã€‚</p>
<pre><code class="python">&gt;&gt;&gt; clf.set_params(svm__C=10)
</code></pre>
<p>å¯ä»¥é€šè¿‡set_paramså‡½æ•°å¯¹pipelineä¸­çš„æŸä¸ªæ¨¡å‹è®¾å®šå‚æ•°ï¼Œä¸Šé¢æ˜¯å°†svmå‚æ•°Cè®¾ç½®ä¸º10</p>
<p>å¦å¤–ä¸€ä¸ªä¾‹å­ï¼š</p>
<pre><code class="python">&gt;&gt;&gt; from sklearn import svm
&gt;&gt;&gt; from sklearn.datasets import samples_generator
&gt;&gt;&gt; from sklearn.feature_selection import SelectKBest
&gt;&gt;&gt; from sklearn.feature_selection import f_regression
&gt;&gt;&gt; from sklearn.pipeline import Pipeline
&gt;&gt;&gt; # generate some data to play with
&gt;&gt;&gt; X, y = samples_generator.make_classification(
...     n_informative=5, n_redundant=0, random_state=42)
&gt;&gt;&gt; # ANOVA SVM-C
&gt;&gt;&gt; anova_filter = SelectKBest(f_regression, k=5)
&gt;&gt;&gt; clf = svm.SVC(kernel=&#39;linear&#39;)
&gt;&gt;&gt; anova_svm = Pipeline([(&#39;anova&#39;, anova_filter), (&#39;svc&#39;, clf)])
&gt;&gt;&gt; # You can set the parameters using the names issued
&gt;&gt;&gt; # For instance, fit using a k of 10 in the SelectKBest
&gt;&gt;&gt; # and a parameter &#39;C&#39; of the svm
&gt;&gt;&gt; anova_svm.set_params(anova__k=10, svc__C=.1).fit(X, y)
...                                              
Pipeline(steps=[...])
&gt;&gt;&gt; prediction = anova_svm.predict(X)
&gt;&gt;&gt; anova_svm.score(X, y)                        
0.77...
&gt;&gt;&gt; # getting the selected features chosen by anova_filter
&gt;&gt;&gt; anova_svm.named_steps[&#39;anova&#39;].get_support()
...
array([ True,  True,  True, False, False,  True, False,  True,  True, True,
       False, False,  True, False,  True, False, False, False, False,
       True], dtype=bool)
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/23/algo/sklearn/pipeline/" data-id="ciusfm453005s60jhey17047n" class="article-share-link">åˆ†äº«åˆ°</a>
      
        <a href="http://www.notehub.cn/2016/08/23/algo/sklearn/pipeline/#ds-thread" class="article-comment-link">è¯„è®º</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pipeline/">Pipeline</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/kaggle/image_recognize" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/21/algo/kaggle/image_recognize/">kaggleä¹‹è¯†åˆ«è°·æ­Œè¡—æ™¯å›¾ç‰‡ä¸­çš„å­—æ¯</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/21/algo/kaggle/image_recognize/">
      <time datetime="2016-08-21T05:48:13.000Z" itemprop="datePublished">2016-08-21</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="u8BC6_u522B_u8C37_u6B4C_u8857_u666F_u56FE_u7247_u4E2D_u7684_u5B57_u6BCD"><a href="#u8BC6_u522B_u8C37_u6B4C_u8857_u666F_u56FE_u7247_u4E2D_u7684_u5B57_u6BCD" class="headerlink" title="è¯†åˆ«è°·æ­Œè¡—æ™¯å›¾ç‰‡ä¸­çš„å­—æ¯"></a>è¯†åˆ«è°·æ­Œè¡—æ™¯å›¾ç‰‡ä¸­çš„å­—æ¯</h2><p><a href="https://github.com/lijingpeng/kaggle/tree/master/competitions/image_recognize" target="_blank" rel="external">github</a><br><a href="https://www.kaggle.com/c/street-view-getting-started-with-julia" target="_blank" rel="external">street-view-getting-started-with-julia</a> è®©æˆ‘ä»¬ä»è°·æ­Œè¡—æ™¯çš„å›¾ç‰‡ä¸­é‰´å®šå­—æ¯ï¼Œè¿™ä¸ªé¢˜ç›®æ˜¯è®©æˆ‘ä»¬å­¦ä¹ å’Œä½¿ç”¨Juliaï¼ŒJuliaæœ‰pythonå’ŒRçš„æ˜“ç”¨æ€§ï¼Œæœ‰Cè¯­è¨€çš„é€Ÿåº¦ï¼Œæ— å¥ˆå¯¹Juliaä¸æ˜¯å¾ˆç†Ÿæ‚‰ï¼Œæ‰€ä»¥è¿˜æ˜¯æƒ³ç”¨pythonæ¥è¯•è¯•ã€‚</p>
<pre><code class="python">import cv2
import numpy as np
import sys
import pandas as pd
</code></pre>
<p>æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„å›¾ç‰‡æœ€åå­˜å‚¨åœ¨ä¸€ä¸ªnumpyçš„çŸ©é˜µå½“ä¸­ï¼Œæ¯ä¸€è¡Œä¸ºå›¾ç‰‡çš„åƒç´ å€¼ã€‚ä¸ºäº†å¾—åˆ°ç»Ÿä¸€çš„è¡¨è¾¾å‘¢ï¼Œæˆ‘ä»¬å°†RGBä¸‰ä¸ªé€šé“çš„å€¼åšå¹³å‡å¾—åˆ°çš„ç°åº¦å›¾åƒä½œä¸ºæ¯ä¸ªå›¾ç‰‡çš„è¡¨ç¤º:</p>
<pre><code class="python"># typeData ä¸º&quot;train&quot;æˆ–è€…&quot;test&quot;
# labelsInfo åŒ…å«æ¯ä¸€ä¸ªå›¾ç‰‡çš„ID
# å›¾ç‰‡å­˜å‚¨åœ¨trainResizedå’ŒtestResizedæ–‡ä»¶å¤¹å†…
def read_data(typeData, labelsInfo, imageSize):
    labelsIndex = labelsInfo[&quot;ID&quot;]
    x = np.zeros((np.size(labelsIndex), imageSize))
    for idx, idImage in enumerate(labelsIndex):
        # å¾—åˆ°å›¾ç‰‡æ–‡ä»¶åå¹¶è¯»å–
        nameFile = typeData + &quot;Resized/&quot; + str(idImage) + &quot;.Bmp&quot;
        img = cv2.imread(nameFile)
        # è½¬åŒ–ä¸ºç°åº¦å›¾
        temp = np.mean(img, 2)
        # å°†å›¾ç‰‡è½¬åŒ–ä¸ºè¡Œå‘é‡
        x[idx, :] = np.reshape(temp, (1, imageSize))
    return x
</code></pre>
<h3 id="u9884_u5904_u7406_u8BAD_u7EC3_u96C6_u548C_u6D4B_u8BD5_u96C6"><a href="#u9884_u5904_u7406_u8BAD_u7EC3_u96C6_u548C_u6D4B_u8BD5_u96C6" class="headerlink" title="é¢„å¤„ç†è®­ç»ƒé›†å’Œæµ‹è¯•é›†"></a>é¢„å¤„ç†è®­ç»ƒé›†å’Œæµ‹è¯•é›†</h3><pre><code class="python">imageSize = 400
trainlabels = pd.read_csv(&quot;trainLabels.csv&quot;)
testlabels = pd.read_csv(&quot;sampleSubmission.csv&quot;)
# å¾—åˆ°è®­ç»ƒé›†çš„ç‰¹å¾
xTrain = read_data(&#39;train&#39;, trainlabels, imageSize)
# å¾—åˆ°æµ‹è¯•é›†çš„ç‰¹å¾
xTest = read_data(&quot;test&quot;, testlabels, imageSize)
</code></pre>
<h4 id="u9884_u89C8_u6570_u636E_uFF1A"><a href="#u9884_u89C8_u6570_u636E_uFF1A" class="headerlink" title="é¢„è§ˆæ•°æ®ï¼š"></a>é¢„è§ˆæ•°æ®ï¼š</h4><pre><code class="python">print trainlabels.head(2)
print testlabels.head(2)
</code></pre>
<pre><code>   ID Class
0   1     n
1   2     8
     ID Class
0  6284     A
1  6285     A
</code></pre><pre><code class="python">yTrain = trainlabels[&quot;Class&quot;]
yTrain = [ord(x) for x in yTrain]
</code></pre>
<h2 id="u6A21_u578B_u8BAD_u7EC3"><a href="#u6A21_u578B_u8BAD_u7EC3" class="headerlink" title="æ¨¡å‹è®­ç»ƒ"></a>æ¨¡å‹è®­ç»ƒ</h2><h3 id="u968F_u673A_u68EE_u6797"><a href="#u968F_u673A_u68EE_u6797" class="headerlink" title="éšæœºæ£®æ—"></a>éšæœºæ£®æ—</h3><p>ä½¿ç”¨éšæœºæ£®æ—è¿›è¡Œè®­ç»ƒï¼Œæ ‘çš„ä¸ªæ•°å’Œæ·±åº¦éœ€è¦å¤šæ¬¡è°ƒè§£å¯»æ±‚æœ€ä½³å€¼</p>
<pre><code class="python">from sklearn.ensemble import RandomForestClassifier
%time rfc = RandomForestClassifier(n_estimators = 500, max_features = 50, max_depth=None)
rfc.fit(xTrain, yTrain)
</code></pre>
<pre><code>CPU times: user 121 Âµs, sys: 367 Âµs, total: 488 Âµs
Wall time: 494 Âµs





RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
</code></pre><h4 id="u9884_u6D4B"><a href="#u9884_u6D4B" class="headerlink" title="é¢„æµ‹"></a>é¢„æµ‹</h4><p>å°†è®­ç»ƒåçš„æ¨¡å‹åº”ç”¨åˆ°æµ‹è¯•é›†ä¸Šï¼Œå¹¶ä¿å­˜ç»“æœï¼š</p>
<pre><code class="python">predTest = rfc.predict(xTest)
predResult = [chr(x) for x in predTest]
testlabels[&quot;Class&quot;] = predResult
testlabels.to_csv(&quot;rf_500_50_result.csv&quot;,index = None)
</code></pre>
<h4 id="u7ED3_u679C"><a href="#u7ED3_u679C" class="headerlink" title="ç»“æœ"></a>ç»“æœ</h4><p>ä½¿ç”¨50é¢—æ ‘è¿›è¡Œè®­ç»ƒï¼Œæäº¤kaggleä¹‹åå‡†ç¡®ç‡çº¦ä¸º0.40<br>æ”¹ç”¨300é¢—æ ‘è¿›è¡Œè®­ç»ƒï¼Œæäº¤kaggleä¹‹åå‡†ç¡®ç‡ä¸º0.46695<br>æ”¹ç”¨500é¢—æ ‘è¿›è¡Œè®­ç»ƒï¼Œæ·±åº¦ä¸º10ï¼Œæä»·kaggleåå‡†ç¡®ç‡ä¸º0.40ï¼Œä¼°è®¡å‡ºç°äº†è¿‡æ‹Ÿåˆ<br>æ”¹ç”¨500é¢—æ ‘è¿›è¡Œè®­ç»ƒï¼Œä¸è®¾ç½®æ·±åº¦ï¼Œæä»·kaggleåå‡†ç¡®ç‡ä¸º0.47480  </p>
<h3 id="u8D1D_u53F6_u65AF"><a href="#u8D1D_u53F6_u65AF" class="headerlink" title="è´å¶æ–¯"></a>è´å¶æ–¯</h3><pre><code class="python">from sklearn.naive_bayes import GaussianNB as GNB
model_GNB = GNB()
model_GNB.fit(xTrain, yTrain)

predTest = model_GNB.predict(xTest)
predResult = [chr(x) for x in predTest]
testlabels[&quot;Class&quot;] = predResult
testlabels.to_csv(&quot;gnb_result.csv&quot;,index = None)
</code></pre>
<p>è´å¶æ–¯çš„è®­ç»ƒéå¸¸çš„å¿«ï¼ŒæŠŠç»“æœæäº¤kaggleåï¼Œå¾—åˆ°0.02389çš„å‡†ç¡®ç‡ï¼Œæ˜æ˜¾ä½äºéšæœºæ£®æ—</p>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><pre><code class="python">from sklearn.ensemble import GradientBoostingClassifier
%time GBDT = GradientBoostingClassifier(loss=&#39;deviance&#39;, learning_rate=0.1, n_estimators=100, subsample=1.0, \
                        min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None, \
                        random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort=&#39;auto&#39;)

%time GBDT.fit(xTrain, yTrain)

%time predTest = GBDT.predict(xTest)
predResult = [chr(x) for x in predTest]
testlabels[&quot;Class&quot;] = predResult
testlabels.to_csv(&quot;gbdt_result.csv&quot;,index = None)
</code></pre>
<pre><code>CPU times: user 91 Âµs, sys: 738 Âµs, total: 829 Âµs
Wall time: 2.93 ms
CPU times: user 40min 16s, sys: 52.3 s, total: 41min 9s
Wall time: 2h 55min 22s
CPU times: user 1.75 s, sys: 44.5 ms, total: 1.8 s
Wall time: 1.79 s
</code></pre><p>ä½¿ç”¨GBDTä»…å¾—åˆ°äº†0.31937çš„å‡†ç¡®ç‡ï¼Œå¯èƒ½æ˜¯æˆ‘çš„é»˜è®¤å‚æ•°æ²¡æœ‰è°ƒèŠ‚å¥½ï¼Œå…³é”®æ˜¯GBDTçš„è®­ç»ƒæ—¶é—´å¤ªé•¿ï¼Œè°ƒè¯•æˆæœ¬ä¹Ÿæ¯”è¾ƒé«˜</p>
<h3 id="u795E_u7ECF_u7F51_u7EDC"><a href="#u795E_u7ECF_u7F51_u7EDC" class="headerlink" title="ç¥ç»ç½‘ç»œ"></a>ç¥ç»ç½‘ç»œ</h3><pre><code class="python">import os
from skimage.io import imread
from lasagne import layers
from lasagne.nonlinearities import softmax
from nolearn.lasagne import NeuralNet, BatchIterator
</code></pre>
<pre><code class="python"># Define functions
def read_datax(typeData, labelsInfo, imageSize, path):
    x = np.zeros((labelsInfo.shape[0], imageSize))

    for (index, idImage) in enumerate(labelsInfo[&#39;ID&#39;]):
        # use specially created 32 x 32 images
        nameFile = &#39;{0}/{1}Resized32/{2}.Bmp&#39;.format(path,
                    typeData, idImage)
        img = imread(nameFile, as_grey = True)

        x[index, :] = np.reshape(img, (1, imageSize))

    return x

def fit_model(reshaped_train_x, y, image_width,
                    image_height, reshaped_test_x):
    net = NeuralNet(
        layers = [
            (&#39;input&#39;, layers.InputLayer),
            (&#39;conv1&#39;, layers.Conv2DLayer),
            (&#39;pool1&#39;, layers.MaxPool2DLayer),
            (&#39;dropout1&#39;, layers.DropoutLayer),
            (&#39;conv2&#39;, layers.Conv2DLayer),
            (&#39;pool2&#39;, layers.MaxPool2DLayer),
            (&#39;dropout2&#39;, layers.DropoutLayer),
            (&#39;conv3&#39;, layers.Conv2DLayer),
            (&#39;hidden4&#39;, layers.DenseLayer),
            (&#39;output&#39;, layers.DenseLayer),
        ],
        input_shape = (None, 1, 32, 32),
        conv1_num_filters=32, conv1_filter_size=(5, 5),
        pool1_pool_size=(2, 2),
        dropout1_p=0.2,
        conv2_num_filters=64, conv2_filter_size=(5, 5),
        pool2_pool_size=(2, 2),
        dropout2_p=0.2,
        conv3_num_filters = 128, conv3_filter_size = (5, 5),
        hidden4_num_units=500,
        output_num_units = 62, output_nonlinearity = softmax,

        update_learning_rate = 0.01,
        update_momentum = 0.9,

        batch_iterator_train = BatchIterator(batch_size = 100),
        batch_iterator_test = BatchIterator(batch_size = 100),

        use_label_encoder = True,
        regression = False,
        max_epochs = 100,
        verbose = 1,
    )

    net.fit(reshaped_train_x, y)
    prediction = net.predict(reshaped_test_x)

    return prediction
</code></pre>
<pre><code class="python"># é¢„å¤„ç†æ•°æ®ï¼Œé¦–å…ˆå°†å›¾ç‰‡ä¿å­˜ä¸º32*32çš„å°å›¾ç‰‡
imageSize = 1024 # 32 x 32
image_width = image_height = int(imageSize ** 0.5)

labelsInfoTrain = pd.read_csv\
            (&#39;trainLabels.csv&#39;.format(path))
labelsInfoTest = pd.read_csv\
            (&#39;sampleSubmission.csv&#39;.format(path))

# Load dataset
nnxTrain = read_datax(&#39;train&#39;, labelsInfoTrain, imageSize, &#39;.&#39;)
nnxTest = read_datax(&#39;test&#39;, labelsInfoTest, imageSize, &#39;.&#39;)

nnyTrain = map(ord, labelsInfoTrain[&#39;Class&#39;])
nnyTrain = np.array(yTrain)
</code></pre>
<pre><code class="python"># å½’ä¸€åŒ–æ•°æ®
nnxTrain /= nnxTrain.std(axis = None)
nnxTrain -= nnxTrain.mean()

nnxTest /= nnxTest.std(axis = None)
nnxTest -= nnxTest.mean()
</code></pre>
<pre><code class="python"># Reshape data
train_x_reshaped = nnxTrain.reshape(nnxTrain.shape[0], 1,
                  image_height, image_width).astype(&#39;float32&#39;)
test_x_reshaped = nnxTest.reshape(nnxTest.shape[0], 1,
                  image_height, image_width).astype(&#39;float32&#39;)
</code></pre>
<pre><code class="python"># è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•
predict = fit_model(train_x_reshaped, nnyTrain, image_width, image_height, test_x_reshaped)
</code></pre>
<pre><code># Neural Network with 352586 learnable parameters

## Layer information

  #  name      size
---  --------  --------
  0  input     1x32x32
  1  conv1     32x28x28
  2  pool1     32x14x14
  3  dropout1  32x14x14
  4  conv2     64x10x10
  5  pool2     64x5x5
  6  dropout2  64x5x5
  7  conv3     128x1x1
  8  hidden4   500
  9  output    62

  epoch    trn loss    val loss    trn/val    valid acc  dur
-------  ----------  ----------  ---------  -----------  ------
      1     [36m4.08201[0m     [32m4.01012[0m    1.01793      0.07254  16.55s
      2     [36m3.87688[0m     [32m3.84326[0m    1.00875      0.04836  17.72s
      3     [36m3.82788[0m     [32m3.79976[0m    1.00740      0.04914  16.58s
      4     [36m3.78741[0m     [32m3.78872[0m    0.99965      0.07254  16.14s
      5     [36m3.78030[0m     [32m3.78600[0m    0.99850      0.07254  16.37s
      6     [36m3.77679[0m     [32m3.78520[0m    0.99778      0.07254  16.56s
      7     [36m3.77487[0m     3.78537    0.99723      0.07254  16.30s
      8     [36m3.77411[0m     [32m3.78468[0m    0.99721      0.07254  16.51s
      9     [36m3.77257[0m     3.78518    0.99667      0.07254  15.92s
     10     [36m3.77202[0m     [32m3.78459[0m    0.99668      0.07254  16.55s
     11     [36m3.76948[0m     [32m3.78458[0m    0.99601      0.07254  16.25s
     12     [36m3.76882[0m     [32m3.78414[0m    0.99595      0.07254  16.31s
     13     [36m3.76717[0m     [32m3.78411[0m    0.99552      0.07254  15.70s
     14     [36m3.76606[0m     3.78469    0.99508      0.07254  16.04s
     15     [36m3.76419[0m     3.78671    0.99405      0.07176  15.70s
     16     [36m3.76277[0m     [32m3.78392[0m    0.99441      0.07176  16.05s
     17     [36m3.76014[0m     3.78821    0.99259      0.07176  15.71s
     18     3.78179     3.78606    0.99887      0.07254  16.11s
     19     3.76928     [32m3.78321[0m    0.99632      0.07254  15.75s
     20     3.76688     3.78358    0.99559      0.07254  16.05s
     21     3.76434     [32m3.78255[0m    0.99519      0.07254  17.36s
     22     3.76186     [32m3.78174[0m    0.99474      0.07254  18.12s
     23     [36m3.75829[0m     3.78184    0.99377      0.07878  17.90s
     24     [36m3.75370[0m     3.78545    0.99161      0.07488  18.19s
     25     [36m3.74749[0m     [32m3.77908[0m    0.99164      0.07098  17.81s
     26     [36m3.73650[0m     [32m3.77806[0m    0.98900      0.07020  18.08s
     27     [36m3.71592[0m     [32m3.77626[0m    0.98402      0.06474  18.03s
     28     [36m3.67805[0m     [32m3.74531[0m    0.98204      0.07176  18.04s
     29     [36m3.59550[0m     3.79802    0.94668      0.07566  18.12s
     30     [36m3.44086[0m     [32m3.35483[0m    1.02564      0.19111  18.06s
     31     [36m3.14160[0m     [32m3.00021[0m    1.04713      0.29251  17.41s
     32     [36m2.73389[0m     [32m2.89130[0m    0.94556      0.31903  16.19s
     33     [36m2.61587[0m     [32m2.53098[0m    1.03354      0.38144  15.73s
     34     [36m2.25316[0m     [32m2.26086[0m    0.99660      0.43994  16.14s
     35     [36m1.95499[0m     [32m2.03661[0m    0.95993      0.48206  15.76s
     36     [36m1.75483[0m     [32m1.94987[0m    0.89997      0.49610  16.01s
     37     [36m1.60276[0m     [32m1.78637[0m    0.89722      0.52106  15.60s
     38     [36m1.47862[0m     [32m1.73524[0m    0.85211      0.54524  15.98s
     39     [36m1.35049[0m     [32m1.65705[0m    0.81500      0.55694  15.62s
     40     [36m1.27458[0m     [32m1.65253[0m    0.77129      0.57254  16.01s
     41     [36m1.18548[0m     [32m1.60550[0m    0.73839      0.58112  15.61s
     42     [36m1.11862[0m     1.62259    0.68940      0.58268  16.51s
     43     [36m1.05698[0m     1.68044    0.62899      0.58112  16.24s
     44     [36m1.01350[0m     1.64642    0.61558      0.59126  16.50s
     45     [36m0.93587[0m     1.62059    0.57749      0.59906  15.81s
     46     [36m0.87893[0m     1.65983    0.52953      0.59984  16.54s
     47     [36m0.83695[0m     1.66309    0.50325      0.60452  16.42s
     48     1.72887     2.92194    0.59169      0.54446  16.31s
     49     3.85830     3.39520    1.13640      0.21373  15.84s
     50     2.26598     1.97743    1.14592      0.46724  18.41s
     51     2.11105     1.89927    1.11150      0.49298  18.02s
     52     1.66393     1.75705    0.94700      0.51794  17.99s
     53     1.48332     1.65795    0.89467      0.54212  17.94s
     54     1.38197     [32m1.60296[0m    0.86214      0.55928  17.73s
     55     1.28419     [32m1.56050[0m    0.82293      0.56318  17.94s
     56     1.21078     [32m1.54983[0m    0.78123      0.57176  17.70s
     57     1.13885     1.55330    0.73318      0.55616  17.93s
     58     1.10488     [32m1.53462[0m    0.71997      0.57956  17.71s
     59     1.03479     1.54234    0.67092      0.58502  17.70s
     60     0.98439     [32m1.52492[0m    0.64554      0.59984  17.95s
     61     0.93277     [32m1.49128[0m    0.62548      0.59204  17.67s
     62     1.03055     1.58280    0.65109      0.57878  18.01s
     63     0.89008     1.54904    0.57460      0.59750  17.69s
     64     0.83698     1.59463    0.52487      0.58346  17.92s
     65     [36m0.79801[0m     1.59534    0.50021      0.60452  17.80s
     66     [36m0.77752[0m     1.56702    0.49618      0.60842  17.91s
     67     [36m0.73901[0m     1.61821    0.45668      0.59594  17.81s
     68     [36m0.71108[0m     1.56703    0.45377      0.61154  17.98s
     69     [36m0.67279[0m     1.61497    0.41659      0.61154  17.81s
     70     [36m0.64651[0m     1.66452    0.38841      0.60530  17.97s
     71     [36m0.61597[0m     1.65828    0.37145      0.62012  17.84s
     72     [36m0.59188[0m     1.69796    0.34858      0.60296  17.92s
     73     [36m0.57862[0m     1.72392    0.33564      0.60686  17.73s
     74     [36m0.56451[0m     1.75449    0.32175      0.60062  17.56s
     75     [36m0.53835[0m     1.74351    0.30877      0.62090  17.77s
     76     [36m0.53288[0m     1.80642    0.29499      0.60842  18.08s
     77     [36m0.49975[0m     1.76941    0.28244      0.61700  17.76s
     78     [36m0.48489[0m     1.75930    0.27561      0.60998  17.92s
     79     [36m0.45688[0m     1.81943    0.25111      0.61622  17.78s
     80     0.46801     1.80187    0.25974      0.62480  17.96s
     81     [36m0.45527[0m     1.88136    0.24199      0.61310  17.84s
     82     [36m0.43178[0m     1.93961    0.22261      0.61622  18.56s
     83     [36m0.41726[0m     1.90341    0.21922      0.61856  16.52s
     84     [36m0.38590[0m     1.91029    0.20201      0.61778  15.59s
     85     [36m0.38510[0m     1.93524    0.19900      0.61778  16.00s
     86     [36m0.37565[0m     1.92514    0.19513      0.61466  15.56s
     87     [36m0.36222[0m     1.99870    0.18123      0.61544  15.88s
     88     0.38495     2.08839    0.18433      0.61466  15.55s
     89     [36m0.34101[0m     1.94872    0.17499      0.62559  15.97s
     90     [36m0.33575[0m     2.01506    0.16662      0.61856  15.63s
     91     [36m0.32353[0m     2.05956    0.15709      0.62090  16.03s
     92     [36m0.30422[0m     2.12548    0.14313      0.64041  15.66s
     93     [36m0.29631[0m     2.10645    0.14067      0.63495  16.02s
     94     0.32050     2.11861    0.15128      0.62168  15.73s
     95     0.30140     2.14516    0.14050      0.62871  15.99s
     96     [36m0.28195[0m     2.09292    0.13472      0.63339  15.67s
     97     0.30323     2.20744    0.13737      0.62246  16.07s
     98     [36m0.27107[0m     2.15645    0.12570      0.63729  16.32s
     99     0.27947     2.22565    0.12557      0.62637  16.51s
    100     [36m0.26500[0m     2.22825    0.11893      0.64431  16.52s
</code></pre><pre><code class="python"># ä¿å­˜ç»“æœ
yTest = map(chr, predict)
labelsInfoTest[&#39;Class&#39;] = yTest
labelsInfoTest.to_csv(&#39;nnresult.csv&#39;.format(path), index = False)
</code></pre>
<p>æäº¤kaggleä¹‹åçš„å‡†ç¡®ç‡ï¼š0.64562</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/21/algo/kaggle/image_recognize/" data-id="ciusfm44a004a60jh47nii04x" class="article-share-link">åˆ†äº«åˆ°</a>
      
        <a href="http://www.notehub.cn/2016/08/21/algo/kaggle/image_recognize/#ds-thread" class="article-comment-link">è¯„è®º</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/kaggle/titanic" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/19/algo/kaggle/titanic/">kaggleä¹‹Titanic æ²‰æ²¡</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/19/algo/kaggle/titanic/">
      <time datetime="2016-08-19T12:30:13.000Z" itemprop="datePublished">2016-08-19</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="Titanic__u6C89_u6CA1"><a href="#Titanic__u6C89_u6CA1" class="headerlink" title="Titanic æ²‰æ²¡"></a>Titanic æ²‰æ²¡</h2><p><a href="https://github.com/lijingpeng" target="_blank" rel="external">Githubåœ°å€</a>     </p>
<p>è¿™æ˜¯ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œç‰¹å¾åŒ…å«ç¦»æ•£ç‰¹å¾å’Œè¿ç»­ç‰¹å¾ï¼Œæ•°æ®å¦‚ä¸‹ï¼š<a href="https://www.kaggle.com/c/titanic/data" target="_blank" rel="external">Kaggleåœ°å€</a>ã€‚ç›®æ ‡æ˜¯æ ¹æ®æ•°æ®ç‰¹å¾é¢„æµ‹ä¸€ä¸ªäººæ˜¯å¦èƒ½åœ¨æ³°å¦å°¼å…‹çš„æ²‰æ²¡äº‹æ•…ä¸­å­˜æ´»ä¸‹æ¥ã€‚æ¥ä¸‹æ¥è§£é‡Šä¸‹æ•°æ®çš„æ ¼å¼ï¼š</p>
<pre><code>survival        ç›®æ ‡åˆ—ï¼Œæ˜¯å¦å­˜æ´»ï¼Œ1ä»£è¡¨å­˜æ´» (0 = No; 1 = Yes)  
pclass          ä¹˜åçš„èˆ±ä½çº§åˆ« (1 = 1st; 2 = 2nd; 3 = 3rd)  
name            å§“å
sex             æ€§åˆ«  
age             å¹´é¾„  
sibsp           å…„å¼Ÿå§å¦¹çš„æ•°é‡ï¼ˆä¹˜å®¢ä¸­ï¼‰  
parch           çˆ¶æ¯çš„æ•°é‡ï¼ˆä¹˜å®¢ä¸­ï¼‰  
ticket          ç¥¨å·  
fare            ç¥¨ä»·  
cabin           å®¢èˆ±  
embarked        ç™»èˆ¹çš„æ¸¯å£  
                (C = Cherbourg; Q = Queenstown; S = Southampton)
</code></pre><h2 id="u8F7D_u5165_u6570_u636E_u5E76_u5206_u6790"><a href="#u8F7D_u5165_u6570_u636E_u5E76_u5206_u6790" class="headerlink" title="è½½å…¥æ•°æ®å¹¶åˆ†æ"></a>è½½å…¥æ•°æ®å¹¶åˆ†æ</h2><pre><code class="python"># -*- coding: UTF-8 -*-
%matplotlib inline

import pandas as pd
import string
import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
</code></pre>
<pre><code class="python">train = pd.read_csv(&#39;train.csv&#39;)
test = pd.read_csv(&#39;test.csv&#39;)

def substrings_in_string(big_string, substrings):
    for substring in substrings:
        if string.find(big_string, substring) != -1:
            return substring
    return np.nan

def replace_titles(x):
    title=x[&#39;Title&#39;]
    if title in [&#39;Mr&#39;,&#39;Don&#39;, &#39;Major&#39;, &#39;Capt&#39;, &#39;Jonkheer&#39;, &#39;Rev&#39;, &#39;Col&#39;]:
        return &#39;Mr&#39;
    elif title in [&#39;Master&#39;]:
        return &#39;Master&#39;
    elif title in [&#39;Countess&#39;, &#39;Mme&#39;,&#39;Mrs&#39;]:
        return &#39;Mrs&#39;
    elif title in [&#39;Mlle&#39;, &#39;Ms&#39;,&#39;Miss&#39;]:
        return &#39;Miss&#39;
    elif title ==&#39;Dr&#39;:
        if x[&#39;Sex&#39;]==&#39;Male&#39;:
            return &#39;Mr&#39;
        else:
            return &#39;Mrs&#39;
    elif title ==&#39;&#39;:
        if x[&#39;Sex&#39;]==&#39;Male&#39;:
            return &#39;Master&#39;
        else:
            return &#39;Miss&#39;
    else:
        return title

title_list = [&#39;Mrs&#39;, &#39;Mr&#39;, &#39;Master&#39;, &#39;Miss&#39;, &#39;Major&#39;, &#39;Rev&#39;,
                &#39;Dr&#39;, &#39;Ms&#39;, &#39;Mlle&#39;,&#39;Col&#39;, &#39;Capt&#39;, &#39;Mme&#39;, &#39;Countess&#39;,
                &#39;Don&#39;, &#39;Jonkheer&#39;]
</code></pre>
<pre><code class="python">label = train[&#39;Survived&#39;] # ç›®æ ‡åˆ—
</code></pre>
<h3 id="Pclass_u3001Sex_u3001Embarked_u79BB_u6563_u7279_u5F81_u6570_u636E_u9884_u89C8"><a href="#Pclass_u3001Sex_u3001Embarked_u79BB_u6563_u7279_u5F81_u6570_u636E_u9884_u89C8" class="headerlink" title="Pclassã€Sexã€Embarkedç¦»æ•£ç‰¹å¾æ•°æ®é¢„è§ˆ"></a>Pclassã€Sexã€Embarkedç¦»æ•£ç‰¹å¾æ•°æ®é¢„è§ˆ</h3><p>é™¤æ­¤ä¹‹å¤–Nameã€Ticketã€Cabinä¹Ÿæ˜¯ç¦»æ•£ç‰¹å¾ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸ç”¨è¿™å‡ ä¸ªç‰¹å¾ï¼Œç›´è§‚ä¸Šæ¥è®²ï¼Œå«ä»€ä¹ˆåå­—è·Ÿåœ¨äº‹æ•…ä¸­æ˜¯å¦å­˜æ´»å¥½åƒæ²¡æœ‰å¤ªå¤§çš„è”ç³»ã€‚</p>
<pre><code class="python"># æ¥ä¸‹æ¥æˆ‘ä»¬å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œä¸€ä¸‹åˆ†æï¼š
train.groupby([&#39;Pclass&#39;])[&#39;PassengerId&#39;].count().plot(kind=&#39;bar&#39;)
</code></pre>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x102bef590&gt;
</code></pre><p><img src="output_6_1.png" alt="png"></p>
<pre><code class="python">train.groupby([&#39;SibSp&#39;])[&#39;PassengerId&#39;].count().plot(kind=&#39;bar&#39;)
</code></pre>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x106c41a10&gt;
</code></pre><p><img src="output_7_1.png" alt="png"></p>
<pre><code class="python">train.groupby([&#39;Parch&#39;])[&#39;PassengerId&#39;].count().plot(kind=&#39;bar&#39;)
</code></pre>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x106d7b090&gt;
</code></pre><p><img src="output_8_1.png" alt="png"></p>
<pre><code class="python">train.groupby([&#39;Embarked&#39;])[&#39;PassengerId&#39;].count().plot(kind=&#39;bar&#39;)
</code></pre>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x106eca590&gt;
</code></pre><p><img src="output_9_1.png" alt="png"></p>
<pre><code class="python">train.groupby([&#39;Sex&#39;])[&#39;PassengerId&#39;].count().plot(kind=&#39;bar&#39;)
</code></pre>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x106ff83d0&gt;
</code></pre><p><img src="output_10_1.png" alt="png"></p>
<h3 id="u8FDE_u7EED_u7279_u5F81_u5904_u7406"><a href="#u8FDE_u7EED_u7279_u5F81_u5904_u7406" class="headerlink" title="è¿ç»­ç‰¹å¾å¤„ç†"></a>è¿ç»­ç‰¹å¾å¤„ç†</h3><p>Ageã€Fareæ˜¯è¿ç»­ç‰¹å¾ï¼Œè§‚å¯Ÿæ•°æ®åˆ†å¸ƒæŸ¥çœ‹æ˜¯å¦æœ‰ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼Œæˆ‘ä»¬çœ‹åˆ°Ageä¸­å­˜åœ¨ç¼ºå¤±å€¼ï¼Œæˆ‘ä»¬è€ƒè™‘ä½¿ç”¨å‡å€¼æ¥å¡«å……ç¼ºå¤±å€¼ã€‚</p>
<pre><code class="python">print &#39;æ£€æµ‹æ˜¯å¦æœ‰ç¼ºå¤±å€¼ï¼š&#39;
print train[train[&#39;Age&#39;].isnull()][&#39;Age&#39;].head()
print train[train[&#39;Fare&#39;].isnull()][&#39;Fare&#39;].head()
print train[train[&#39;SibSp&#39;].isnull()][&#39;SibSp&#39;].head()
print train[train[&#39;Parch&#39;].isnull()][&#39;Parch&#39;].head()
train[&#39;Age&#39;] = train[&#39;Age&#39;].fillna(train[&#39;Age&#39;].mean())
print &#39;å¡«å……ä¹‹åå†æ£€æµ‹ï¼š&#39;
print train[train[&#39;Age&#39;].isnull()][&#39;Age&#39;].head()
print train[train[&#39;Fare&#39;].isnull()][&#39;Fare&#39;].head()
</code></pre>
<pre><code>æ£€æµ‹æ˜¯å¦æœ‰ç¼ºå¤±å€¼ï¼š
5    NaN
17   NaN
19   NaN
26   NaN
28   NaN
Name: Age, dtype: float64
Series([], Name: Fare, dtype: float64)
Series([], Name: SibSp, dtype: int64)
Series([], Name: Parch, dtype: int64)
å¡«å……ä¹‹åå†æ£€æµ‹ï¼š
Series([], Name: Age, dtype: float64)
Series([], Name: Fare, dtype: float64)
</code></pre><pre><code class="python">print &#39;æ£€æµ‹æµ‹è¯•é›†æ˜¯å¦æœ‰ç¼ºå¤±å€¼ï¼š&#39;
print test[test[&#39;Age&#39;].isnull()][&#39;Age&#39;].head()
print test[test[&#39;Fare&#39;].isnull()][&#39;Fare&#39;].head()
print test[test[&#39;SibSp&#39;].isnull()][&#39;SibSp&#39;].head()
print test[test[&#39;Parch&#39;].isnull()][&#39;Parch&#39;].head()
test[&#39;Age&#39;] = test[&#39;Age&#39;].fillna(test[&#39;Age&#39;].mean())
test[&#39;Fare&#39;] = test[&#39;Fare&#39;].fillna(test[&#39;Fare&#39;].mean())
print &#39;å¡«å……ä¹‹åå†æ£€æµ‹ï¼š&#39;
print test[test[&#39;Age&#39;].isnull()][&#39;Age&#39;].head()
print test[test[&#39;Fare&#39;].isnull()][&#39;Fare&#39;].head()
</code></pre>
<pre><code>æ£€æµ‹æµ‹è¯•é›†æ˜¯å¦æœ‰ç¼ºå¤±å€¼ï¼š
10   NaN
22   NaN
29   NaN
33   NaN
36   NaN
Name: Age, dtype: float64
152   NaN
Name: Fare, dtype: float64
Series([], Name: SibSp, dtype: int64)
Series([], Name: Parch, dtype: int64)
å¡«å……ä¹‹åå†æ£€æµ‹ï¼š
Series([], Name: Age, dtype: float64)
Series([], Name: Fare, dtype: float64)
</code></pre><pre><code class="python"># å¤„ç†Titleç‰¹å¾
train[&#39;Title&#39;] = train[&#39;Name&#39;].map(lambda x: substrings_in_string(x, title_list))
test[&#39;Title&#39;] = test[&#39;Name&#39;].map(lambda x: substrings_in_string(x, title_list))

train[&#39;Title&#39;] = train.apply(replace_titles, axis=1)
test[&#39;Title&#39;] = test.apply(replace_titles, axis=1)

# familyç‰¹å¾
train[&#39;Family_Size&#39;] = train[&#39;SibSp&#39;] + train[&#39;Parch&#39;]
train[&#39;Family&#39;] = train[&#39;SibSp&#39;] * train[&#39;Parch&#39;]
test[&#39;Family_Size&#39;] = test[&#39;SibSp&#39;] + test[&#39;Parch&#39;]
test[&#39;Family&#39;] = test[&#39;SibSp&#39;] * test[&#39;Parch&#39;]
</code></pre>
<pre><code class="python">train[&#39;AgeFill&#39;] = train[&#39;Age&#39;]
mean_ages = np.zeros(4)
mean_ages[0] = np.average(train[train[&#39;Title&#39;] == &#39;Miss&#39;][&#39;Age&#39;].dropna())
mean_ages[1] = np.average(train[train[&#39;Title&#39;] == &#39;Mrs&#39;][&#39;Age&#39;].dropna())
mean_ages[2] = np.average(train[train[&#39;Title&#39;] == &#39;Mr&#39;][&#39;Age&#39;].dropna())
mean_ages[3] = np.average(train[train[&#39;Title&#39;] == &#39;Master&#39;][&#39;Age&#39;].dropna())
train.loc[ (train.Age.isnull()) &amp; (train.Title == &#39;Miss&#39;) ,&#39;AgeFill&#39;] = mean_ages[0]
train.loc[ (train.Age.isnull()) &amp; (train.Title == &#39;Mrs&#39;) ,&#39;AgeFill&#39;] = mean_ages[1]
train.loc[ (train.Age.isnull()) &amp; (train.Title == &#39;Mr&#39;) ,&#39;AgeFill&#39;] = mean_ages[2]
train.loc[ (train.Age.isnull()) &amp; (train.Title == &#39;Master&#39;) ,&#39;AgeFill&#39;] = mean_ages[3]

train[&#39;AgeCat&#39;] = train[&#39;AgeFill&#39;]
train.loc[ (train.AgeFill&lt;=10), &#39;AgeCat&#39;] = &#39;child&#39;
train.loc[ (train.AgeFill&gt;60), &#39;AgeCat&#39;] = &#39;aged&#39;
train.loc[ (train.AgeFill&gt;10) &amp; (train.AgeFill &lt;=30) ,&#39;AgeCat&#39;] = &#39;adult&#39;
train.loc[ (train.AgeFill&gt;30) &amp; (train.AgeFill &lt;=60) ,&#39;AgeCat&#39;] = &#39;senior&#39;

train[&#39;Fare_Per_Person&#39;] = train[&#39;Fare&#39;] / (train[&#39;Family_Size&#39;] + 1)
</code></pre>
<pre><code class="python">test[&#39;AgeFill&#39;] = test[&#39;Age&#39;]
mean_ages = np.zeros(4)
mean_ages[0] = np.average(test[test[&#39;Title&#39;] == &#39;Miss&#39;][&#39;Age&#39;].dropna())
mean_ages[1] = np.average(test[test[&#39;Title&#39;] == &#39;Mrs&#39;][&#39;Age&#39;].dropna())
mean_ages[2] = np.average(test[test[&#39;Title&#39;] == &#39;Mr&#39;][&#39;Age&#39;].dropna())
mean_ages[3] = np.average(test[test[&#39;Title&#39;] == &#39;Master&#39;][&#39;Age&#39;].dropna())
test.loc[ (test.Age.isnull()) &amp; (test.Title == &#39;Miss&#39;) ,&#39;AgeFill&#39;] = mean_ages[0]
test.loc[ (test.Age.isnull()) &amp; (test.Title == &#39;Mrs&#39;) ,&#39;AgeFill&#39;] = mean_ages[1]
test.loc[ (test.Age.isnull()) &amp; (test.Title == &#39;Mr&#39;) ,&#39;AgeFill&#39;] = mean_ages[2]
test.loc[ (test.Age.isnull()) &amp; (test.Title == &#39;Master&#39;) ,&#39;AgeFill&#39;] = mean_ages[3]

test[&#39;AgeCat&#39;] = test[&#39;AgeFill&#39;]
test.loc[ (test.AgeFill&lt;=10), &#39;AgeCat&#39;] = &#39;child&#39;
test.loc[ (test.AgeFill&gt;60), &#39;AgeCat&#39;] = &#39;aged&#39;
test.loc[ (test.AgeFill&gt;10) &amp; (test.AgeFill &lt;=30) ,&#39;AgeCat&#39;] = &#39;adult&#39;
test.loc[ (test.AgeFill&gt;30) &amp; (test.AgeFill &lt;=60) ,&#39;AgeCat&#39;] = &#39;senior&#39;

test[&#39;Fare_Per_Person&#39;] = test[&#39;Fare&#39;] / (test[&#39;Family_Size&#39;] + 1)
</code></pre>
<pre><code class="python">train.Embarked = train.Embarked.fillna(&#39;S&#39;)
test.Embarked = test.Embarked.fillna(&#39;S&#39;)

train.loc[ train.Cabin.isnull() == True, &#39;Cabin&#39;] = 0.2
train.loc[ train.Cabin.isnull() == False, &#39;Cabin&#39;] = 1

test.loc[ test.Cabin.isnull() == True, &#39;Cabin&#39;] = 0.2
test.loc[ test.Cabin.isnull() == False, &#39;Cabin&#39;] = 1
</code></pre>
<pre><code class="python">#Age times class
train[&#39;AgeClass&#39;] = train[&#39;AgeFill&#39;] * train[&#39;Pclass&#39;]
train[&#39;ClassFare&#39;] = train[&#39;Pclass&#39;] * train[&#39;Fare_Per_Person&#39;]

train[&#39;HighLow&#39;] = train[&#39;Pclass&#39;]
train.loc[ (train.Fare_Per_Person &lt; 8) ,&#39;HighLow&#39;] = &#39;Low&#39;
train.loc[ (train.Fare_Per_Person &gt;= 8) ,&#39;HighLow&#39;] = &#39;High&#39;

#Age times class
test[&#39;AgeClass&#39;] = test[&#39;AgeFill&#39;] * test[&#39;Pclass&#39;]
test[&#39;ClassFare&#39;] = test[&#39;Pclass&#39;] * test[&#39;Fare_Per_Person&#39;]

test[&#39;HighLow&#39;] = test[&#39;Pclass&#39;]
test.loc[ (test.Fare_Per_Person &lt; 8) ,&#39;HighLow&#39;] = &#39;Low&#39;
test.loc[ (test.Fare_Per_Person &gt;= 8) ,&#39;HighLow&#39;] = &#39;High&#39;
</code></pre>
<pre><code class="python">print train.head(1)
# print test.head()
</code></pre>
<pre><code>   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \
0            1         0       3  Braund, Mr. Owen Harris  male  22.0      1   

   Parch     Ticket  Fare   ...    Embarked Title Family_Size  Family  \
0      0  A/5 21171  7.25   ...           S    Mr           1       0   

   AgeFill  AgeCat Fare_Per_Person  AgeClass  ClassFare  HighLow  
0     22.0   adult           3.625      66.0     10.875      Low  

[1 rows x 21 columns]
</code></pre><h2 id="u7279_u5F81_u5DE5_u7A0B"><a href="#u7279_u5F81_u5DE5_u7A0B" class="headerlink" title="ç‰¹å¾å·¥ç¨‹"></a>ç‰¹å¾å·¥ç¨‹</h2><pre><code class="python"># å¤„ç†è®­ç»ƒé›†
Pclass = pd.get_dummies(train.Pclass)
Sex = pd.get_dummies(train.Sex)
Embarked = pd.get_dummies(train.Embarked)
Title = pd.get_dummies(train.Title)
AgeCat = pd.get_dummies(train.AgeCat)
HighLow = pd.get_dummies(train.HighLow)
train_data = pd.concat([Pclass, Sex, Embarked, Title, AgeCat, HighLow], axis=1)
train_data[&#39;Age&#39;] = train[&#39;Age&#39;]
train_data[&#39;Fare&#39;] = train[&#39;Fare&#39;]
train_data[&#39;SibSp&#39;] = train[&#39;SibSp&#39;]
train_data[&#39;Parch&#39;] = train[&#39;Parch&#39;]
train_data[&#39;Family_Size&#39;] = train[&#39;Family_Size&#39;]
train_data[&#39;Family&#39;] = train[&#39;Family&#39;]
train_data[&#39;AgeFill&#39;] = train[&#39;AgeFill&#39;]
train_data[&#39;Fare_Per_Person&#39;] = train[&#39;Fare_Per_Person&#39;]
train_data[&#39;Cabin&#39;] = train[&#39;Cabin&#39;]
train_data[&#39;AgeClass&#39;] = train[&#39;AgeClass&#39;]
train_data[&#39;ClassFare&#39;] = train[&#39;ClassFare&#39;]

cols = [&#39;Age&#39;, &#39;Fare&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Family_Size&#39;, &#39;Family&#39;, &#39;AgeFill&#39;, &#39;Fare_Per_Person&#39;, &#39;AgeClass&#39;, &#39;ClassFare&#39;]
train_data[cols] = train_data[cols].apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))
print train_data.head()

# å¤„ç†æµ‹è¯•é›†
Pclass = pd.get_dummies(test.Pclass)
Sex = pd.get_dummies(test.Sex)
Embarked = pd.get_dummies(test.Embarked)
Title = pd.get_dummies(test.Title)
AgeCat = pd.get_dummies(test.AgeCat)
HighLow = pd.get_dummies(test.HighLow)
test_data = pd.concat([Pclass, Sex, Embarked, Title, AgeCat, HighLow], axis=1)
test_data[&#39;Age&#39;] = test[&#39;Age&#39;]
test_data[&#39;Fare&#39;] = test[&#39;Fare&#39;]
test_data[&#39;SibSp&#39;] = test[&#39;SibSp&#39;]
test_data[&#39;Parch&#39;] = test[&#39;Parch&#39;]
test_data[&#39;Family_Size&#39;] = test[&#39;Family_Size&#39;]
test_data[&#39;Family&#39;] = test[&#39;Family&#39;]
test_data[&#39;AgeFill&#39;] = test[&#39;AgeFill&#39;]
test_data[&#39;Fare_Per_Person&#39;] = test[&#39;Fare_Per_Person&#39;]
test_data[&#39;Cabin&#39;] = test[&#39;Cabin&#39;]
test_data[&#39;AgeClass&#39;] = test[&#39;AgeClass&#39;]
test_data[&#39;ClassFare&#39;] = test[&#39;ClassFare&#39;]

test_data[cols] = test_data[cols].apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))
print test_data.head()
</code></pre>
<pre><code>     1    2    3  female  male    C    Q    S  Master  Miss    ...      \
0  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0    ...       
1  1.0  0.0  0.0     1.0   0.0  1.0  0.0  0.0     0.0   0.0    ...       
2  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0     0.0   1.0    ...       
3  1.0  0.0  0.0     1.0   0.0  0.0  0.0  1.0     0.0   0.0    ...       
4  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0    ...       

       Fare     SibSp     Parch  Family_Size    Family   AgeFill  \
0 -0.048707  0.059624 -0.063599      0.00954 -0.035494 -0.096747   
1  0.076277  0.059624 -0.063599      0.00954 -0.035494  0.104309   
2 -0.047390 -0.065376 -0.063599     -0.09046 -0.035494 -0.046483   
3  0.040786  0.059624 -0.063599      0.00954 -0.035494  0.066611   
4 -0.047146 -0.065376 -0.063599     -0.09046 -0.035494  0.066611   

   Fare_Per_Person  Cabin  AgeClass  ClassFare  
0        -0.031799      1  0.004673  -0.040180  
1         0.030694      1 -0.121978   0.008161  
2        -0.023406      1  0.058952  -0.015001  
3         0.012948      1 -0.135547  -0.009584  
4        -0.023162      1  0.181080  -0.014269  

[5 rows x 29 columns]
     1    2    3  female  male    C    Q    S  Master  Miss    ...      \
0  0.0  0.0  1.0     0.0   1.0  0.0  1.0  0.0     0.0   0.0    ...       
1  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0     0.0   0.0    ...       
2  0.0  1.0  0.0     0.0   1.0  0.0  1.0  0.0     0.0   0.0    ...       
3  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0    ...       
4  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0     0.0   0.0    ...       

       Fare     SibSp     Parch  Family_Size    Family   AgeFill  \
0 -0.054258 -0.055921 -0.043594    -0.083971 -0.027811  0.055749   
1 -0.055877  0.069079 -0.043594     0.016029 -0.027811  0.220591   
2 -0.050631 -0.055921 -0.043594    -0.083971 -0.027811  0.418402   
3 -0.052632 -0.055921 -0.043594    -0.083971 -0.027811 -0.043157   
4 -0.045556  0.069079  0.067517     0.116029  0.034689 -0.109094   

   Fare_Per_Person  Cabin  AgeClass  ClassFare  
0        -0.053389      1  0.218758  -0.037167  
1        -0.069889      1  0.425952  -0.086667  
2        -0.046307      1  0.332024  -0.052842  
3        -0.050213      1  0.094442  -0.027639  
4        -0.067618      1  0.011564  -0.079855  

[5 rows x 29 columns]
</code></pre><h2 id="u6A21_u578B_u8BAD_u7EC3"><a href="#u6A21_u578B_u8BAD_u7EC3" class="headerlink" title="æ¨¡å‹è®­ç»ƒ"></a>æ¨¡å‹è®­ç»ƒ</h2><pre><code class="python">from sklearn.linear_model import LogisticRegression as LR
from sklearn.cross_validation import cross_val_score
from sklearn.naive_bayes import GaussianNB as GNB
from sklearn.ensemble import RandomForestClassifier

import numpy as np
</code></pre>
<h3 id="u903B_u8F91_u56DE_u5F52"><a href="#u903B_u8F91_u56DE_u5F52" class="headerlink" title="é€»è¾‘å›å½’"></a>é€»è¾‘å›å½’</h3><pre><code class="python">model_lr = LR(penalty = &#39;l2&#39;, dual = True, random_state = 0)
model_lr.fit(train_data, label)
print &quot;é€»è¾‘å›å½’10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†: &quot;, np.mean(cross_val_score(model_lr, train_data, label, cv=10, scoring=&#39;roc_auc&#39;))

result = model_lr.predict( test_data )
output = pd.DataFrame( data={&quot;PassengerId&quot;:test[&quot;PassengerId&quot;], &quot;Survived&quot;:result} )
output.to_csv( &quot;lr.csv&quot;, index=False, quoting=3 )
</code></pre>
<pre><code>é€»è¾‘å›å½’10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†:  0.871878335172
</code></pre><h4 id="u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-78469"><a href="#u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-78469" class="headerlink" title="æäº¤kaggleåå‡†ç¡®ç‡ï¼š0.78469"></a>æäº¤kaggleåå‡†ç¡®ç‡ï¼š0.78469</h4><h3 id="u9AD8_u65AF_u8D1D_u53F6_u65AF"><a href="#u9AD8_u65AF_u8D1D_u53F6_u65AF" class="headerlink" title="é«˜æ–¯è´å¶æ–¯"></a>é«˜æ–¯è´å¶æ–¯</h3><pre><code class="python">model_GNB = GNB()
model_GNB.fit(train_data, label)
print &quot;é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†: &quot;, np.mean(cross_val_score(model_GNB, train_data, label, cv=10, scoring=&#39;roc_auc&#39;))

result = model_GNB.predict( test_data )
output = pd.DataFrame( data={&quot;PassengerId&quot;:test[&quot;PassengerId&quot;], &quot;Survived&quot;:result} )
output.to_csv( &quot;gnb.csv&quot;, index=False, quoting=3 )
</code></pre>
<pre><code>é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†:  0.857323798206
</code></pre><h4 id="u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-74163"><a href="#u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-74163" class="headerlink" title="æäº¤kaggleåå‡†ç¡®ç‡ï¼š0.74163"></a>æäº¤kaggleåå‡†ç¡®ç‡ï¼š0.74163</h4><h3 id="u968F_u673A_u68EE_u6797"><a href="#u968F_u673A_u68EE_u6797" class="headerlink" title="éšæœºæ£®æ—"></a>éšæœºæ£®æ—</h3><pre><code class="python">forest = RandomForestClassifier( n_estimators=500, criterion=&#39;entropy&#39;, max_depth=5, min_samples_split=1,
  min_samples_leaf=1, max_features=&#39;auto&#39;, bootstrap=False, oob_score=False, n_jobs=4,
  verbose=0)

%time forest = forest.fit( train_data, label )
print &quot;éšæœºæ£®æ—åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†: &quot;, np.mean(cross_val_score(forest, train_data, label, cv=10, scoring=&#39;roc_auc&#39;))

result = forest.predict( test_data )
output = pd.DataFrame( data={&quot;PassengerId&quot;:test[&quot;PassengerId&quot;], &quot;Survived&quot;:result} )
output.to_csv( &quot;rf.csv&quot;, index=False, quoting=3 )
</code></pre>
<pre><code>CPU times: user 1.34 s, sys: 208 ms, total: 1.55 s
Wall time: 1.17 s
éšæœºæ£®æ—åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†:  0.870820473644
</code></pre><h4 id="u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-76555"><a href="#u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-76555" class="headerlink" title="æäº¤kaggleåå‡†ç¡®ç‡ï¼š0.76555"></a>æäº¤kaggleåå‡†ç¡®ç‡ï¼š0.76555</h4><hr>
<h2 id="u5BFB_u627E_u6700_u4F73_u53C2_u6570"><a href="#u5BFB_u627E_u6700_u4F73_u53C2_u6570" class="headerlink" title="å¯»æ‰¾æœ€ä½³å‚æ•°"></a>å¯»æ‰¾æœ€ä½³å‚æ•°</h2><pre><code class="python">from sklearn.pipeline import Pipeline
from sklearn.grid_search import GridSearchCV
from sklearn.cross_validation import train_test_split,StratifiedShuffleSplit,StratifiedKFold
param_grid = dict( )

pipeline=Pipeline([ (&#39;clf&#39;, forest) ])
grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=3, scoring=&#39;accuracy&#39;,
cv=StratifiedShuffleSplit(label, n_iter=10, test_size=0.2, train_size=None)).fit(train_data, label)

print(&quot;Best score: %0.3f&quot; % grid_search.best_score_)
</code></pre>
<pre><code>Fitting 10 folds for each of 1 candidates, totalling 10 fits
[CV]  ................................................................
[CV] ....................................... , score=0.849162 -   1.7s
[CV]  ................................................................
[CV] ....................................... , score=0.843575 -   1.5s
[CV]  ................................................................
[CV] ....................................... , score=0.804469 -   1.4s
[CV]  ................................................................
[CV] ....................................... , score=0.804469 -   1.9s
[CV]  ................................................................
[CV] ....................................... , score=0.871508 -   2.1s
[CV]  ................................................................
[CV] ....................................... , score=0.865922 -   1.9s
[CV]  ................................................................
[CV] ....................................... , score=0.854749 -   1.8s
[CV]  ................................................................
[CV] ....................................... , score=0.860335 -   1.7s
[CV]  ................................................................
[CV] ....................................... , score=0.843575 -   1.6s
[CV]  ................................................................
[CV] ....................................... , score=0.826816 -   1.5s


[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   17.1s finished


Best score: 0.842
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/19/algo/kaggle/titanic/" data-id="ciusfm44d004g60jha1zdogwf" class="article-share-link">åˆ†äº«åˆ°</a>
      
        <a href="http://www.notehub.cn/2016/08/19/algo/kaggle/titanic/#ds-thread" class="article-comment-link">è¯„è®º</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/kaggle/sequence" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/19/algo/kaggle/sequence/">kaggleä¹‹æ•°å­—åºåˆ—é¢„æµ‹</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/19/algo/kaggle/sequence/">
      <time datetime="2016-08-19T05:48:13.000Z" itemprop="datePublished">2016-08-19</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="u6570_u5B57_u5E8F_u5217_u9884_u6D4B"><a href="#u6570_u5B57_u5E8F_u5217_u9884_u6D4B" class="headerlink" title="æ•°å­—åºåˆ—é¢„æµ‹"></a>æ•°å­—åºåˆ—é¢„æµ‹</h2><p><a href="https://github.com/lijingpeng/kaggle/tree/master/competitions/Sequence" target="_blank" rel="external">Githubåœ°å€</a><br><a href="https://www.kaggle.com/c/integer-sequence-learning" target="_blank" rel="external">Kaggleåœ°å€</a></p>
<pre><code class="python"># -*- coding: UTF-8 -*-
%matplotlib inline

import pandas as pd
import string
import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
</code></pre>
<pre><code class="python">train = pd.read_csv(&#39;train.csv&#39;)
test = pd.read_csv(&#39;test.csv&#39;)
</code></pre>
<pre><code class="python">last = test.Sequence.apply(lambda x: pd.Series(x.split(&#39;,&#39;))).mode(axis=1).fillna(0)
</code></pre>
<pre><code class="python">submission = pd.DataFrame({&#39;Id&#39;: test[&#39;Id&#39;], &#39;Last&#39;: last[0]})
submission.to_csv(&#39;mode.csv&#39;, index=False)
</code></pre>
<p>æäº¤Kaggleä¹‹åæ˜¯0.05680</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/19/algo/kaggle/sequence/" data-id="ciusfm44c004d60jh3a3qq1zj" class="article-share-link">åˆ†äº«åˆ°</a>
      
        <a href="http://www.notehub.cn/2016/08/19/algo/kaggle/sequence/#ds-thread" class="article-comment-link">è¯„è®º</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/kaggle/movie_reviews" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/16/algo/kaggle/movie_reviews/">kaggleä¹‹ç”µå½±æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/16/algo/kaggle/movie_reviews/">
      <time datetime="2016-08-16T05:48:13.000Z" itemprop="datePublished">2016-08-16</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="u7535_u5F71_u6587_u672C_u60C5_u611F_u5206_u7C7B"><a href="#u7535_u5F71_u6587_u672C_u60C5_u611F_u5206_u7C7B" class="headerlink" title="ç”µå½±æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»"></a>ç”µå½±æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»</h2><p><a href="https://github.com/lijingpeng/kaggle/tree/master/competitions/Bag_of_Words" target="_blank" rel="external">Githubåœ°å€</a><br><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/" target="_blank" rel="external">Kaggleåœ°å€</a></p>
<p>è¿™ä¸ªä»»åŠ¡ä¸»è¦æ˜¯å¯¹ç”µå½±è¯„è®ºæ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ï¼Œä¸»è¦åˆ†ä¸ºæ­£é¢è¯„è®ºå’Œè´Ÿé¢è¯„è®ºï¼Œæ‰€ä»¥æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼ŒäºŒåˆ†ç±»æ¨¡å‹æˆ‘ä»¬å¯ä»¥é€‰å–ä¸€äº›å¸¸è§çš„æ¨¡å‹æ¯”å¦‚è´å¶æ–¯ã€é€»è¾‘å›å½’ç­‰ï¼Œè¿™é‡ŒæŒ‘æˆ˜ä¹‹ä¸€æ˜¯æ–‡æœ¬å†…å®¹çš„å‘é‡åŒ–ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆå°è¯•åŸºäºTF-IDFçš„å‘é‡åŒ–æ–¹æ³•ï¼Œç„¶åå°è¯•word2vecã€‚</p>
<pre><code class="python"># -*- coding: UTF-8 -*-
import pandas as pd
import numpy as np
import re
from bs4 import BeautifulSoup

def review_to_wordlist(review):
    &#39;&#39;&#39;
    æŠŠIMDBçš„è¯„è®ºè½¬æˆè¯åºåˆ—
    å‚è€ƒï¼šhttp://blog.csdn.net/longxinchen_ml/article/details/50629613
    &#39;&#39;&#39;
    # å»æ‰HTMLæ ‡ç­¾ï¼Œæ‹¿åˆ°å†…å®¹
    review_text = BeautifulSoup(review, &quot;html.parser&quot;).get_text()
    # ç”¨æ­£åˆ™è¡¨è¾¾å¼å–å‡ºç¬¦åˆè§„èŒƒçš„éƒ¨åˆ†
    review_text = re.sub(&quot;[^a-zA-Z]&quot;,&quot; &quot;, review_text)
    # å°å†™åŒ–æ‰€æœ‰çš„è¯ï¼Œå¹¶è½¬æˆè¯list
    words = review_text.lower().split()
    # è¿”å›words
    return words
</code></pre>
<h2 id="u8F7D_u5165_u6570_u636E_u96C6"><a href="#u8F7D_u5165_u6570_u636E_u96C6" class="headerlink" title="è½½å…¥æ•°æ®é›†"></a>è½½å…¥æ•°æ®é›†</h2><pre><code class="python"># è½½å…¥æ•°æ®é›†
train = pd.read_csv(&#39;/Users/frank/Documents/workspace/kaggle/dataset/Bag_of_Words_Meets_Bags_of_Popcorn/labeledTrainData.tsv&#39;, header=0, delimiter=&quot;\t&quot;, quoting=3)
test = pd.read_csv(&#39;/Users/frank/Documents/workspace/kaggle/dataset/Bag_of_Words_Meets_Bags_of_Popcorn/testData.tsv&#39;, header=0, delimiter=&quot;\t&quot;, quoting=3)
print train.head()
print test.head()
</code></pre>
<pre><code>         id  sentiment                                             review
0  &quot;5814_8&quot;          1  &quot;With all this stuff going down at the moment ...
1  &quot;2381_9&quot;          1  &quot;\&quot;The Classic War of the Worlds\&quot; by Timothy ...
2  &quot;7759_3&quot;          0  &quot;The film starts with a manager (Nicholas Bell...
3  &quot;3630_4&quot;          0  &quot;It must be assumed that those who praised thi...
4  &quot;9495_8&quot;          1  &quot;Superbly trashy and wondrously unpretentious ...
           id                                             review
0  &quot;12311_10&quot;  &quot;Naturally in a film who&#39;s main themes are of ...
1    &quot;8348_2&quot;  &quot;This movie is a disaster within a disaster fi...
2    &quot;5828_4&quot;  &quot;All in all, this is a movie for kids. We saw ...
3    &quot;7186_2&quot;  &quot;Afraid of the Dark left me with the impressio...
4   &quot;12128_7&quot;  &quot;A very accurate depiction of small time mob l...
</code></pre><h2 id="u9884_u5904_u7406_u6570_u636E"><a href="#u9884_u5904_u7406_u6570_u636E" class="headerlink" title="é¢„å¤„ç†æ•°æ®"></a>é¢„å¤„ç†æ•°æ®</h2><pre><code class="python"># é¢„å¤„ç†æ•°æ®
label = train[&#39;sentiment&#39;]
train_data = []
for i in range(len(train[&#39;review&#39;])):
    train_data.append(&#39; &#39;.join(review_to_wordlist(train[&#39;review&#39;][i])))
test_data = []
for i in range(len(test[&#39;review&#39;])):
    test_data.append(&#39; &#39;.join(review_to_wordlist(test[&#39;review&#39;][i])))

# é¢„è§ˆæ•°æ®
print train_data[0], &#39;\n&#39;
print test_data[0]
</code></pre>
<pre><code>with all this stuff going down at the moment with mj i ve started listening to his music watching the odd documentary here and there watched the wiz and watched moonwalker again maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent moonwalker is part biography part feature film which i remember going to see at the cinema when it was originally released some of it has subtle messages about mj s feeling towards the press and also the obvious message of drugs are bad m kay visually impressive but of course this is all about michael jackson so unless you remotely like mj in anyway then you are going to hate this and find it boring some may call mj an egotist for consenting to the making of this movie but mj and most of his fans would say that he made it for the fans which if true is really nice of him the actual feature film bit when it finally starts is only on for minutes or so excluding the smooth criminal sequence and joe pesci is convincing as a psychopathic all powerful drug lord why he wants mj dead so bad is beyond me because mj overheard his plans nah joe pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno maybe he just hates mj s music lots of cool things in this like mj turning into a car and a robot and the whole speed demon sequence also the director must have had the patience of a saint when it came to filming the kiddy bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene bottom line this movie is for people who like mj on one level or another which i think is most people if not then stay away it does try and give off a wholesome message and ironically mj s bestest buddy in this movie is a girl michael jackson is truly one of the most talented people ever to grace this planet but is he guilty well with all the attention i ve gave this subject hmmm well i don t know because people can be different behind closed doors i know this for a fact he is either an extremely nice but stupid guy or one of the most sickest liars i hope he is not the latter

naturally in a film who s main themes are of mortality nostalgia and loss of innocence it is perhaps not surprising that it is rated more highly by older viewers than younger ones however there is a craftsmanship and completeness to the film which anyone can enjoy the pace is steady and constant the characters full and engaging the relationships and interactions natural showing that you do not need floods of tears to show emotion screams to show fear shouting to show dispute or violence to show anger naturally joyce s short story lends the film a ready made structure as perfect as a polished diamond but the small changes huston makes such as the inclusion of the poem fit in neatly it is truly a masterpiece of tact subtlety and overwhelming beauty
</code></pre><h2 id="u7279_u5F81_u5904_u7406"><a href="#u7279_u5F81_u5904_u7406" class="headerlink" title="ç‰¹å¾å¤„ç†"></a>ç‰¹å¾å¤„ç†</h2><p>ç›´æ¥ä¸¢ç»™è®¡ç®—æœºè¿™äº›è¯æ–‡æœ¬ï¼Œè®¡ç®—æœºæ˜¯æ— æ³•è®¡ç®—çš„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æŠŠæ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œæœ‰å‡ ç§å¸¸è§çš„æ–‡æœ¬å‘é‡å¤„ç†æ–¹æ³•ï¼Œæ¯”å¦‚ï¼š</p>
<ol>
<li>å•è¯è®¡æ•°  </li>
<li>TF-IDFå‘é‡  </li>
<li>Word2vecå‘é‡<br>æˆ‘ä»¬å…ˆä½¿ç”¨TF-IDFæ¥è¯•ä¸€ä¸‹ã€‚</li>
</ol>
<pre><code class="python">from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF
# å‚è€ƒï¼šhttp://blog.csdn.net/longxinchen_ml/article/details/50629613
tfidf = TFIDF(min_df=2, # æœ€å°æ”¯æŒåº¦ä¸º2
           max_features=None,
           strip_accents=&#39;unicode&#39;,
           analyzer=&#39;word&#39;,
           token_pattern=r&#39;\w{1,}&#39;,
           ngram_range=(1, 3),  # äºŒå…ƒæ–‡æ³•æ¨¡å‹
           use_idf=1,
           smooth_idf=1,
           sublinear_tf=1,
           stop_words = &#39;english&#39;) # å»æ‰è‹±æ–‡åœç”¨è¯

# åˆå¹¶è®­ç»ƒå’Œæµ‹è¯•é›†ä»¥ä¾¿è¿›è¡ŒTFIDFå‘é‡åŒ–æ“ä½œ
data_all = train_data + test_data
len_train = len(train_data)

tfidf.fit(data_all)
data_all = tfidf.transform(data_all)
# æ¢å¤æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ¨åˆ†
train_x = data_all[:len_train]
test_x = data_all[len_train:]
print &#39;TF-IDFå¤„ç†ç»“æŸ.&#39;
</code></pre>
<pre><code>TF-IDFå¤„ç†ç»“æŸ.
</code></pre><h2 id="u6734_u7D20_u8D1D_u53F6_u65AF_u8BAD_u7EC3"><a href="#u6734_u7D20_u8D1D_u53F6_u65AF_u8BAD_u7EC3" class="headerlink" title="æœ´ç´ è´å¶æ–¯è®­ç»ƒ"></a>æœ´ç´ è´å¶æ–¯è®­ç»ƒ</h2><pre><code class="python">from sklearn.naive_bayes import MultinomialNB as MNB

model_NB = MNB()
model_NB.fit(train_x, label)
MNB(alpha=1.0, class_prior=None, fit_prior=True)

from sklearn.cross_validation import cross_val_score
import numpy as np

print &quot;å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†: &quot;, np.mean(cross_val_score(model_NB, train_x, label, cv=10, scoring=&#39;roc_auc&#39;))
</code></pre>
<pre><code>å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†:  0.94983968
</code></pre><pre><code class="python">test_predicted = np.array(model_NB.predict(test_x))
print &#39;ä¿å­˜ç»“æœ...&#39;
nb_output = pd.DataFrame(data=test_predicted, columns=[&#39;sentiment&#39;])
nb_output[&#39;id&#39;] = test[&#39;id&#39;]
nb_output = nb_output[[&#39;id&#39;, &#39;sentiment&#39;]]
nb_output.to_csv(&#39;nb_output.csv&#39;, index=False)
print &#39;ç»“æŸ.&#39;
</code></pre>
<pre><code>ä¿å­˜ç»“æœ...
ç»“æŸ.
</code></pre><ol>
<li>æäº¤æœ€ç»ˆçš„ç»“æœåˆ°kaggleï¼ŒAUCä¸ºï¼š0.85728ï¼Œæ’å300å·¦å³ï¼Œ50%çš„æ°´å¹³  </li>
<li>ngram_range = 3, ä¸‰å…ƒæ–‡æ³•ï¼ŒAUCä¸º0.85924</li>
</ol>
<h2 id="u903B_u8F91_u56DE_u5F52"><a href="#u903B_u8F91_u56DE_u5F52" class="headerlink" title="é€»è¾‘å›å½’"></a>é€»è¾‘å›å½’</h2><pre><code class="python">from sklearn.linear_model import LogisticRegression as LR
from sklearn.grid_search import GridSearchCV

# è®¾å®šgrid searchçš„å‚æ•°
grid_values = {&#39;C&#39;:[30]}  
# è®¾å®šæ‰“åˆ†ä¸ºroc_auc
model_LR = GridSearchCV(LR(penalty = &#39;L2&#39;, dual = True, random_state = 0), grid_values, scoring = &#39;roc_auc&#39;, cv = 20)
model_LR.fit(train_x, label)
# 20æŠ˜äº¤å‰éªŒè¯
GridSearchCV(cv=20, estimator=LR(C=1.0, class_weight=None, dual=True,
             fit_intercept=True, intercept_scaling=1, penalty=&#39;L2&#39;, random_state=0, tol=0.0001),
        fit_params={}, iid=True, n_jobs=1,
        param_grid={&#39;C&#39;: [30]}, pre_dispatch=&#39;2*n_jobs&#39;, refit=True,
        scoring=&#39;roc_auc&#39;, verbose=0)
#è¾“å‡ºç»“æœ
print model_LR.grid_scores_
</code></pre>
<pre><code>[mean: 0.96497, std: 0.00476, params: {&#39;C&#39;: 30}]
</code></pre><pre><code class="python">test_predicted = np.array(model_LR.predict(test_x))
print &#39;ä¿å­˜ç»“æœ...&#39;
lr_output = pd.DataFrame(data=test_predicted, columns=[&#39;sentiment&#39;])
lr_output[&#39;id&#39;] = test[&#39;id&#39;]
lr_output = lr_output[[&#39;id&#39;, &#39;sentiment&#39;]]
lr_output.to_csv(&#39;lr_output.csv&#39;, index=False)
print &#39;ç»“æŸ.&#39;
</code></pre>
<pre><code>ä¿å­˜ç»“æœ...
ç»“æŸ.
</code></pre><ol>
<li>æäº¤æœ€ç»ˆçš„ç»“æœåˆ°kaggleï¼ŒAUCä¸ºï¼š0.88956ï¼Œæ’å260å·¦å³ï¼Œæ¯”ä¹‹å‰è´å¶æ–¯æ¨¡å‹æœ‰æ‰€æé«˜   </li>
<li>ä¸‰å…ƒæ–‡æ³•ï¼ŒAUCä¸º0.89076</li>
</ol>
<h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>ç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹L = SUM[log(p(w|contect(w))]ï¼Œå³åœ¨wçš„ä¸Šä¸‹æ–‡ä¸‹è®¡ç®—å½“å‰è¯wçš„æ¦‚ç‡ï¼Œç”±å…¬å¼å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„æ ¸å¿ƒæ˜¯è®¡ç®—p(w|contect(w)ï¼Œ Word2vecç»™å‡ºäº†æ„é€ è¿™ä¸ªæ¦‚ç‡çš„ä¸€ä¸ªæ–¹æ³•ã€‚</p>
<pre><code class="python">import gensim
import nltk
from nltk.corpus import stopwords

tokenizer = nltk.data.load(&#39;tokenizers/punkt/english.pickle&#39;)

def review_to_wordlist( review, remove_stopwords=False ):
    review_text = BeautifulSoup(review, &quot;html.parser&quot;).get_text()
    review_text = re.sub(&quot;[^a-zA-Z]&quot;,&quot; &quot;, review_text)

    words = review_text.lower().split()

    if remove_stopwords:
        stops = set(stopwords.words(&quot;english&quot;))
        words = [w for w in words if not w in stops]

    return(words)

def review_to_sentences( review, tokenizer, remove_stopwords=False ):
    &#39;&#39;&#39;
    å°†è¯„è®ºæ®µè½è½¬æ¢ä¸ºå¥å­ï¼Œè¿”å›å¥å­åˆ—è¡¨ï¼Œæ¯ä¸ªå¥å­ç”±ä¸€å †è¯ç»„æˆ
    &#39;&#39;&#39;
    raw_sentences = tokenizer.tokenize(review.strip().decode(&#39;utf8&#39;))

    sentences = []
    for raw_sentence in raw_sentences:
        if len(raw_sentence) &gt; 0:
            # è·å–å¥å­ä¸­çš„è¯åˆ—è¡¨
            sentences.append( review_to_wordlist( raw_sentence, remove_stopwords ))
    return sentences
</code></pre>
<pre><code class="python">sentences = []
for i, review in enumerate(train[&quot;review&quot;]):
    sentences += review_to_sentences(review, tokenizer)
</code></pre>
<pre><code class="python">unlabeled_train = pd.read_csv(&quot;/Users/frank/Documents/workspace/kaggle/dataset/Bag_of_Words_Meets_Bags_of_Popcorn/unlabeledTrainData.tsv&quot;, header=0, delimiter=&quot;\t&quot;, quoting=3 )
for review in unlabeled_train[&quot;review&quot;]:
    sentences += review_to_sentences(review, tokenizer)
print &#39;é¢„å¤„ç†unlabeled_train data...&#39;
print len(train_data)
print len(sentences)
</code></pre>
<pre><code>    é¢„å¤„ç†unlabeled_train data...
    25000
    795538
</code></pre><h3 id="u6784_u5EFAword2vec_u6A21_u578B"><a href="#u6784_u5EFAword2vec_u6A21_u578B" class="headerlink" title="æ„å»ºword2vecæ¨¡å‹"></a>æ„å»ºword2vecæ¨¡å‹</h3><pre><code class="python">import time
from gensim.models import Word2Vec
# æ¨¡å‹å‚æ•°
num_features = 300    # Word vector dimensionality                      
min_word_count = 40   # Minimum word count                        
num_workers = 4       # Number of threads to run in parallel
context = 10          # Context window size                                                                                    
downsampling = 1e-3   # Downsample setting for frequent words
</code></pre>
<pre><code class="python">%%time
# è®­ç»ƒæ¨¡å‹
print(&quot;è®­ç»ƒæ¨¡å‹ä¸­...&quot;)
model = Word2Vec(sentences, workers=num_workers, \
            size=num_features, min_count = min_word_count, \
            window = context, sample = downsampling)
</code></pre>
<pre><code>è®­ç»ƒæ¨¡å‹ä¸­...
CPU times: user 6min 16s, sys: 8.34 s, total: 6min 24s
Wall time: 2min 27s
</code></pre><pre><code class="python">print &#39;ä¿å­˜æ¨¡å‹...&#39;
model.init_sims(replace=True)
model_name = &quot;300features_40minwords_10context&quot;
model.save(model_name)
</code></pre>
<pre><code>ä¿å­˜æ¨¡å‹...
</code></pre><h3 id="u9884_u89C8_u6A21_u578B"><a href="#u9884_u89C8_u6A21_u578B" class="headerlink" title="é¢„è§ˆæ¨¡å‹"></a>é¢„è§ˆæ¨¡å‹</h3><pre><code class="python">model.doesnt_match(&quot;man woman child kitchen&quot;.split())
</code></pre>
<pre><code>&#39;kitchen&#39;
</code></pre><pre><code class="python">model.doesnt_match(&quot;france england germany berlin&quot;.split())
</code></pre>
<pre><code>&#39;berlin&#39;
</code></pre><pre><code class="python">model.doesnt_match(&quot;paris berlin london austria&quot;.split())
</code></pre>
<pre><code>&#39;london&#39;
</code></pre><pre><code class="python">model.most_similar(&quot;man&quot;)
</code></pre>
<pre><code>[(u&#39;woman&#39;, 0.6246455907821655),
 (u&#39;lady&#39;, 0.6008599400520325),
 (u&#39;lad&#39;, 0.5698915719985962),
 (u&#39;businessman&#39;, 0.5431989431381226),
 (u&#39;chap&#39;, 0.53116375207901),
 (u&#39;monk&#39;, 0.5250570774078369),
 (u&#39;men&#39;, 0.5177899599075317),
 (u&#39;guy&#39;, 0.517480731010437),
 (u&#39;farmer&#39;, 0.5114585757255554),
 (u&#39;person&#39;, 0.5109285116195679)]
</code></pre><pre><code class="python">model.most_similar(&quot;queen&quot;)
</code></pre>
<pre><code>[(u&#39;princess&#39;, 0.6759523153305054),
 (u&#39;bride&#39;, 0.6207793951034546),
 (u&#39;belle&#39;, 0.6001157760620117),
 (u&#39;shearer&#39;, 0.5995810031890869),
 (u&#39;stepmother&#39;, 0.596365749835968),
 (u&#39;victoria&#39;, 0.5917614698410034),
 (u&#39;dame&#39;, 0.589063286781311),
 (u&#39;latifah&#39;, 0.5790275931358337),
 (u&#39;countess&#39;, 0.5776904821395874),
 (u&#39;widow&#39;, 0.5727116465568542)]
</code></pre><pre><code class="python">model.most_similar(&quot;awful&quot;)
</code></pre>
<pre><code>[(u&#39;terrible&#39;, 0.7642339468002319),
 (u&#39;atrocious&#39;, 0.7405279874801636),
 (u&#39;horrible&#39;, 0.7376815676689148),
 (u&#39;abysmal&#39;, 0.7010303139686584),
 (u&#39;dreadful&#39;, 0.6942194104194641),
 (u&#39;appalling&#39;, 0.6887971758842468),
 (u&#39;lousy&#39;, 0.6646767854690552),
 (u&#39;horrid&#39;, 0.6554058194160461),
 (u&#39;horrendous&#39;, 0.6533403992652893),
 (u&#39;amateurish&#39;, 0.6079087853431702)]
</code></pre><h3 id="u4F7F_u7528Word2vec_u7279_u5F81"><a href="#u4F7F_u7528Word2vec_u7279_u5F81" class="headerlink" title="ä½¿ç”¨Word2vecç‰¹å¾"></a>ä½¿ç”¨Word2vecç‰¹å¾</h3><pre><code class="python">def makeFeatureVec(words, model, num_features):
    &#39;&#39;&#39;
    å¯¹æ®µè½ä¸­çš„æ‰€æœ‰è¯å‘é‡è¿›è¡Œå–å¹³å‡æ“ä½œ
    &#39;&#39;&#39;
    featureVec = np.zeros((num_features,), dtype=&quot;float32&quot;)
    nwords = 0.

    # Index2wordåŒ…å«äº†è¯è¡¨ä¸­çš„æ‰€æœ‰è¯ï¼Œä¸ºäº†æ£€ç´¢é€Ÿåº¦ï¼Œä¿å­˜åˆ°setä¸­
    index2word_set = set(model.index2word)
    for word in words:
        if word in index2word_set:
            nwords = nwords + 1.
            featureVec = np.add(featureVec, model[word])

    # å–å¹³å‡
    featureVec = np.divide(featureVec, nwords)
    return featureVec


def getAvgFeatureVecs(reviews, model, num_features):
    &#39;&#39;&#39;
    ç»™å®šä¸€ä¸ªæ–‡æœ¬åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æœ¬ç”±ä¸€ä¸ªè¯åˆ—è¡¨ç»„æˆï¼Œè¿”å›æ¯ä¸ªæ–‡æœ¬çš„è¯å‘é‡å¹³å‡å€¼
    &#39;&#39;&#39;
    counter = 0.

    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype=&quot;float32&quot;)

    for review in reviews:
       if counter % 5000. == 0.:
           print(&quot;Review %d of %d&quot; % (counter, len(reviews)))

       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \
           num_features)

       counter = counter + 1.
    return reviewFeatureVecs
</code></pre>
<pre><code class="python">%time trainDataVecs = getAvgFeatureVecs( train_data, model, num_features )
</code></pre>
<pre><code>Review 0 of 25000
Review 5000 of 25000
Review 10000 of 25000
Review 15000 of 25000
Review 20000 of 25000
CPU times: user 1min 49s, sys: 1.9 s, total: 1min 51s
Wall time: 1min 54s
</code></pre><pre><code class="python">%time testDataVecs = getAvgFeatureVecs(test_data, model, num_features)
</code></pre>
<pre><code>Review 0 of 25000
Review 5000 of 25000
Review 10000 of 25000
Review 15000 of 25000
Review 20000 of 25000
CPU times: user 1min 44s, sys: 1.56 s, total: 1min 46s
Wall time: 1min 48s
</code></pre><h3 id="u9AD8_u65AF_u8D1D_u53F6_u65AF+Word2vec_u8BAD_u7EC3"><a href="#u9AD8_u65AF_u8D1D_u53F6_u65AF+Word2vec_u8BAD_u7EC3" class="headerlink" title="é«˜æ–¯è´å¶æ–¯+Word2vecè®­ç»ƒ"></a>é«˜æ–¯è´å¶æ–¯+Word2vecè®­ç»ƒ</h3><pre><code class="python">from sklearn.naive_bayes import GaussianNB as GNB

model_GNB = GNB()
model_GNB.fit(trainDataVecs, label)

from sklearn.cross_validation import cross_val_score
import numpy as np

print &quot;é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†: &quot;, np.mean(cross_val_score(model_GNB, trainDataVecs, label, cv=10, scoring=&#39;roc_auc&#39;))

result = forest.predict( testDataVecs )

output = pd.DataFrame( data={&quot;id&quot;:test[&quot;id&quot;], &quot;sentiment&quot;:result} )
output.to_csv( &quot;gnb_word2vec.csv&quot;, index=False, quoting=3 )
</code></pre>
<pre><code>å¤šé¡¹å¼è´å¶æ–¯åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†:  0.625579296
</code></pre><p>ä»éªŒè¯ç»“æœæ¥çœ‹ï¼Œæ²¡æœ‰è¶…è¿‡åŸºäºTF-IDFå¤šé¡¹å¼è´å¶æ–¯æ¨¡å‹</p>
<h3 id="u968F_u673A_u68EE_u6797+Word2vec_u8BAD_u7EC3"><a href="#u968F_u673A_u68EE_u6797+Word2vec_u8BAD_u7EC3" class="headerlink" title="éšæœºæ£®æ—+Word2vecè®­ç»ƒ"></a>éšæœºæ£®æ—+Word2vecè®­ç»ƒ</h3><pre><code class="python">from sklearn.ensemble import RandomForestClassifier

forest = RandomForestClassifier( n_estimators = 100, n_jobs=2)

print(&quot;Fitting a random forest to labeled training data...&quot;)
%time forest = forest.fit( trainDataVecs, label )
print &quot;éšæœºæ£®æ—åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†: &quot;, np.mean(cross_val_score(forest, trainDataVecs, label, cv=10, scoring=&#39;roc_auc&#39;))

# æµ‹è¯•é›†
result = forest.predict( testDataVecs )

output = pd.DataFrame( data={&quot;id&quot;:test[&quot;id&quot;], &quot;sentiment&quot;:result} )
output.to_csv( &quot;rf_word2vec.csv&quot;, index=False, quoting=3 )
</code></pre>
<pre><code>Fitting a random forest to labeled training data...
CPU times: user 45 s, sys: 460 ms, total: 45.5 s
Wall time: 24.2 s
éšæœºæ£®æ—åˆ†ç±»å™¨10æŠ˜äº¤å‰éªŒè¯å¾—åˆ†:  0.648426368
</code></pre><p>æ”¹ç”¨éšæœºæ£®æ—ä¹‹åï¼Œæ•ˆæœæœ‰æå‡ï¼Œä½†æ˜¯ä¾ç„¶æ²¡æœ‰è¶…è¿‡åŸºäºTF-IDFå¤šé¡¹å¼è´å¶æ–¯æ¨¡å‹</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/16/algo/kaggle/movie_reviews/" data-id="ciusfm448004760jhyx1p9wxb" class="article-share-link">åˆ†äº«åˆ°</a>
      
        <a href="http://www.notehub.cn/2016/08/16/algo/kaggle/movie_reviews/#ds-thread" class="article-comment-link">è¯„è®º</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/3/">&laquo; ä¸Šä¸€é¡µ</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><a class="extend next" rel="next" href="/page/5/">ä¸‹ä¸€é¡µ &raquo;</a>
      </nav>
    </section>
      
        <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">æœ€æ–°æ–‡ç« </h3>
    <div class="widget">
      <ul id="recent-post" class="">
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/10/26/dev/soft_source/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/10/26/dev/soft_source/" class="title">å¸¸ç”¨çš„è½¯ä»¶æº</a></p>
              <p class="item-date"><time datetime="2016-10-26T08:19:56.000Z" itemprop="datePublished">2016-10-26</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/10/15/algo/ml/OnebyOne_Convolution/" class="thumbnail">
  
    <span style="background-image:url(/images/dl/full_padding_no_strides_transposed.gif
)" alt="One by One [ 1 x 1 ] Convolution - counter-intuitively useful" class="thumbnail-image"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
              <p class="item-title"><a href="/2016/10/15/algo/ml/OnebyOne_Convolution/" class="title">One by One [ 1 x 1 ] Convolution - counter-intuitively useful</a></p>
              <p class="item-date"><time datetime="2016-10-14T16:00:00.000Z" itemprop="datePublished">2016-10-15</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/10/11/dev/node_essentail/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/10/11/dev/node_essentail/" class="title">Node/npmå®‰è£…åŸºæœ¬é—®é¢˜</a></p>
              <p class="item-date"><time datetime="2016-10-11T12:19:56.000Z" itemprop="datePublished">2016-10-11</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/10/10/dev/esop/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/10/10/dev/esop/" class="title">Elasticsearch-ç´¢å¼•ä¼˜åŒ–</a></p>
              <p class="item-date"><time datetime="2016-10-10T02:19:56.000Z" itemprop="datePublished">2016-10-10</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/09/18/algo/sklearn/Dummification_vs_encoding/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/machine-learning/">machine learning</a></p>
              <p class="item-title"><a href="/2016/09/18/algo/sklearn/Dummification_vs_encoding/" class="title">XGBoost Categorical Variables - Dummification vs encoding</a></p>
              <p class="item-date"><time datetime="2016-09-17T16:00:00.000Z" itemprop="datePublished">2016-09-18</time></p>
            </div>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">åˆ†ç±»</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hash/">Hash</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Photo/">Photo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SQL/">SQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ads/">ads</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c++</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/dev/">dev</a><span class="category-list-count">34</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/github/">github</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/internet/">internet</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/kaggle/">kaggle</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">24</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/system/">system</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/travel/">travel</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">æ ‡ç­¾äº‘</h3>
    <div class="widget tagcloud">
      <a href="/tags/Apache/" style="font-size: 10px;">Apache</a> <a href="/tags/Bandits/" style="font-size: 12.5px;">Bandits</a> <a href="/tags/Elasticsearch-docker/" style="font-size: 10px;">Elasticsearch, docker</a> <a href="/tags/FlatBuffers/" style="font-size: 10px;">FlatBuffers</a> <a href="/tags/Google/" style="font-size: 10px;">Google</a> <a href="/tags/Granger-causality/" style="font-size: 10px;">Granger causality</a> <a href="/tags/GridSearchCV/" style="font-size: 10px;">GridSearchCV</a> <a href="/tags/HTTPS/" style="font-size: 10px;">HTTPS</a> <a href="/tags/Jquery/" style="font-size: 10px;">Jquery</a> <a href="/tags/MapReduce/" style="font-size: 10px;">MapReduce</a> <a href="/tags/Mock/" style="font-size: 10px;">Mock</a> <a href="/tags/Monument-Vallay/" style="font-size: 10px;">Monument Vallay</a> <a href="/tags/Mysql/" style="font-size: 12.5px;">Mysql</a> <a href="/tags/PPTP-vpn/" style="font-size: 12.5px;">PPTP, vpn</a> <a href="/tags/Photoshop/" style="font-size: 10px;">Photoshop</a> <a href="/tags/Pipeline/" style="font-size: 10px;">Pipeline</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/ad/" style="font-size: 10px;">ad</a> <a href="/tags/apache/" style="font-size: 10px;">apache</a> <a href="/tags/blade/" style="font-size: 10px;">blade</a> <a href="/tags/crontab/" style="font-size: 10px;">crontab</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/elasticsearch/" style="font-size: 12.5px;">elasticsearch</a> <a href="/tags/font/" style="font-size: 10px;">font</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/go/" style="font-size: 17.5px;">go</a> <a href="/tags/hashmap/" style="font-size: 10px;">hashmap</a> <a href="/tags/kaggle/" style="font-size: 20px;">kaggle</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/linux-ldd-ä¾èµ–å…³ç³»/" style="font-size: 10px;">linux, ldd, ä¾èµ–å…³ç³»</a> <a href="/tags/lucene/" style="font-size: 10px;">lucene</a> <a href="/tags/nio/" style="font-size: 10px;">nio</a> <a href="/tags/pagerank/" style="font-size: 10px;">pagerank</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/swift-llvm/" style="font-size: 10px;">swift, llvm</a> <a href="/tags/å‰ç«¯/" style="font-size: 10px;">å‰ç«¯</a> <a href="/tags/å¹¿å‘Š/" style="font-size: 12.5px;">å¹¿å‘Š</a> <a href="/tags/å¼€æºï¼Œè®¸å¯/" style="font-size: 10px;">å¼€æºï¼Œè®¸å¯</a> <a href="/tags/æ¾³é—¨/" style="font-size: 10px;">æ¾³é—¨</a> <a href="/tags/ç›‘æ§ï¼Œzabbix/" style="font-size: 10px;">ç›‘æ§ï¼Œzabbix</a> <a href="/tags/è´å¶æ–¯/" style="font-size: 10px;">è´å¶æ–¯</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">å½’æ¡£</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">åæœˆ 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">ä¹æœˆ 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">å…«æœˆ 2016</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">äº”æœˆ 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">ä¸‰æœˆ 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">äºŒæœˆ 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">ä¸€æœˆ 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">åäºŒæœˆ 2015</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">åä¸€æœˆ 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">åæœˆ 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">ä¹æœˆ 2015</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">å…­æœˆ 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">äº”æœˆ 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">å››æœˆ 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">ä¸‰æœˆ 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">äºŒæœˆ 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">ä¸€æœˆ 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">åäºŒæœˆ 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">åä¸€æœˆ 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">åæœˆ 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">å…­æœˆ 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">åä¸€æœˆ 2013</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
  <div id="toTop" class="fa fa-chevron-up"></div>
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Li Jingpeng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
    </div>
  </div>
</footer>
    

<script type="text/javascript">
  var duoshuoQuery = {short_name:"lijingpeng"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>


<script src="//ajax.css.network/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>