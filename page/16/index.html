<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Frank</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="计算机 网络 互联网">
<meta property="og:type" content="website">
<meta property="og:title" content="Frank">
<meta property="og:url" content="http://www.notehub.cn/page/16/index.html">
<meta property="og:site_name" content="Frank">
<meta property="og:description" content="计算机 网络 互联网">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Frank">
<meta name="twitter:description" content="计算机 网络 互联网">
  
  
    <link rel="icon" href="favicon.png">
  
  <link href='//fonts.css.network/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
  <link href="//fonts.css.network/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  

  
</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="/" id="logo"><i class="logo" style="background-image: url(/css/images/logo.jpg)"></i><span class="site-title">Frank</span></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/.">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      
        <nav id="sub-nav">
          <div class="profile" id="profile-nav">
            <a id="profile-anchor" href="javascript:;"><img class="avatar" src="/css/images/logo.png"><i class="fa fa-caret-down"></i></a>
          </div>
        </nav>
      
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"> </button><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
      </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tr>
        
          <td><a class="main-nav-link" href="/.">Home</a></td>
        
          <td><a class="main-nav-link" href="/archives">Archives</a></td>
        
          <td><a class="main-nav-link" href="/categories">Categories</a></td>
        
          <td><a class="main-nav-link" href="/tags">Tags</a></td>
        
          <td><a class="main-nav-link" href="/about">About</a></td>
        
        <td>
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
        </td>
      </tr>
    </table>
  </div>
</header>

    <div class="outer">
      
        <aside id="profile">
  <div class="inner profile-inner">
    <div class="base-info profile-block">
      <img id="avatar" src="/css/images/logo.png">
      <h2 id="name">Li Jingpeng</h2>
      <!-- <h3 id="title">undefined</h3> -->
      <span id="location"><i class="fa fa-map-marker"></i>Hangzhou, China</span>
      <a id="follow" href="Https://weibo.com/329299516">关注我</a>
    </div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        102
        <span>文章</span>
      </div>
      <div class="article-info-block">
        41
        <span>标签</span>
      </div>
    </div>
    
    <div class="contact-info profile-block">
      <table class="contact-list">
        <tr>
          
          <td><a href="https://github.com/lijingpeng" target="_blank" title="github"><i class="fa fa-github"></i></a></td>
          
          <td><a href="#" target="_blank" title="twitter"><i class="fa fa-twitter"></i></a></td>
          
          <td><a href="#" target="_blank" title="facebook"><i class="fa fa-facebook"></i></a></td>
          
          <td><a href="/me@lijingpeng.org" target="_blank" title="email"><i class="fa fa-email"></i></a></td>
          
          <td><a href="/atom.xml" target="_blank" title="rss"><i class="fa fa-rss"></i></a></td>
          
        </tr>
      </table>
    </div>
    
    
  </div>
</aside>

      
      <section id="main">
      <article id="post-algo/baysian-bandit-application-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/baysian-bandit-application-md/">Bayesian Bandits原理及在互联网广告行业的应用</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/baysian-bandit-application-md/">
      <time datetime="2015-09-03T05:48:13.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="1-_The_Multi-Armed_Bandit_Problem"><a href="#1-_The_Multi-Armed_Bandit_Problem" class="headerlink" title="1. The Multi-Armed Bandit Problem"></a>1. The Multi-Armed Bandit Problem</h2><p>Suppose you are faced with N slot machines (colourfully called multi-armed bandits). Each bandit has an unknown probability of distributing a prize (assume for now the prizes are the same for each bandit, only the probabilities differ). Some bandits are very generous, others not so much. Of course, you don’t know what these probabilities are. By only choosing one bandit per round, our task is devise a strategy to maximize our winnings.</p>
<p>Of course, if we knew the bandit with the largest probability, then always picking this bandit would yield the maximum winnings. So our task can be phrased as “Find the best bandit, and as quickly as possible”.</p>
<p>The task is complicated by the stochastic nature of the bandits. A suboptimal bandit can return many winnings, purely by chance, which would make us believe that it is a very profitable bandit. Similarly, the best bandit can return many duds. Should we keep trying losers then, or give up?</p>
<p>A more troublesome problem is, if we have a found a bandit that returns pretty good results, do we keep drawing from it to maintain our pretty good score, or do we try other bandits in hopes of finding an even-better bandit? This is the exploration vs. exploitation dilemma.</p>
<h2 id="2-_Applications"><a href="#2-_Applications" class="headerlink" title="2. Applications"></a>2. Applications</h2><p>The Multi-Armed Bandit problem at first seems very artificial, something only a mathematician would love, but that is only before we address some applications:</p>
<p>Internet display advertising: companies have a suite of potential ads they can display to visitors, but the company is not sure which ad strategy to follow to maximize sales. This is similar to A/B testing, but has the added advantage of naturally minimizing strategies that do not work (and generalizes to A/B/C/D… strategies)</p>
<ol>
<li>Ecology: animals have a finite amount of energy to expend, and following certain behaviours has uncertain rewards. How does the animal maximize its fitness?</li>
<li>Finance: which stock option gives the highest return, under time-varying return profiles.</li>
<li>Clinical trials: a researcher would like to find the best treatment, out of many possible treatments, while minimizing losses.</li>
</ol>
<p>Many of these questions above are fundamental to the application’s field. It turns out the optimal solution is incredibly difficult, and it took decades for an overall solution to develop. There are also many approximately-optimal solutions which are quite good. The one I wish to discuss is one of the few solutions that can scale incredibly well. The solution is known asBayesian Bandits.</p>
<h2 id="3-_A_Proposed_Solution"><a href="#3-_A_Proposed_Solution" class="headerlink" title="3. A Proposed Solution"></a>3. A Proposed Solution</h2><p>Any proposed strategy is called an online algorithm (not in the internet sense, but in the continuously-being-updated sense), and more specifically a reinforcement learning algorithm. The algorithm starts in an ignorant state, where it knows nothing, and begins to acquire data by testing the system. As it acquires data and results, it learns what the best and worst behaviours are (in this case, it learns which bandit is the best). With this in mind, perhaps we can add an additional application of the Multi-Armed Bandit problem:</p>
<p>Psychology: how does punishment and reward effect our behaviour? How do humans’ learn?<br>The Bayesian solution begins by assuming priors on the probability of winning for each bandit. In our vignette we assumed complete ignorance of the these probabilities. So a very natural prior is the flat prior over 0 to 1. The algorithm proceeds as follows:</p>
<p>For each round,</p>
<ol>
<li>Sample a random variable Xb from the prior of bandit b, for all b.</li>
<li>Select the bandit with largest sample, i.e. select bandit B=argmaxXb.</li>
<li>Observe the result of pulling bandit B, and update your prior on bandit B.</li>
<li>Return to 1.</li>
</ol>
<p>That’s it. Computationally, the algorithm involves sampling from N distributions. Since the initial priors are Beta(α=1,β=1) (a uniform distribution), and the observed result X (a win or loss, encoded 1 and 0 respectfully) is Binomial, the posterior is a Beta(α=1+X,β=1+1−X)(see here for why to is true). </p>
<p>To answer a question from before, this algorithm suggests that we should not discard losers, but we should pick them at a decreasing rate as we gather confidence that there exist better bandits. This follows because there is always a non-zero chance that a loser will achieve the status of B, but the probability of this event decreases as we play more rounds (see figure below). Below is an implementation of the Bayesian Bandits strategy (which can be skipped for the less Pythonic-ly interested).</p>
<pre><code class="python">from pymc import rbeta

rand = np.random.rand

class Bandits(object):
    &quot;&quot;&quot;
    This class represents N bandits machines.

    parameters:
        p_array: a (n,) Numpy array of probabilities &gt;0, &lt;1.

    methods:
        pull( i ): return the results, 0 or 1, of pulling 
                   the ith bandit.
    &quot;&quot;&quot;
    def __init__(self, p_array):
        self.p = p_array
        self.optimal = np.argmax(p_array)

    def pull( self, i ):
        #i is which arm to pull
        return rand() &lt; self.p[i]

    def __len__(self):
        return len(self.p)


class BayesianStrategy( object ):
    &quot;&quot;&quot;
    Implements a online, learning strategy to solve
    the Multi-Armed Bandit problem.

    parameters:
        bandits: a Bandit class with .pull method

    methods:
        sample_bandits(n): sample and train on n pulls.

    attributes:
        N: the cumulative number of samples
        choices: the historical choices as a (N,) array
        bb_score: the historical score as a (N,) array

    &quot;&quot;&quot;

    def __init__(self, bandits):

        self.bandits = bandits
        n_bandits = len( self.bandits )
        self.wins = np.zeros( n_bandits )
        self.trials = np.zeros(n_bandits )
        self.N = 0
        self.choices = []
        self.bb_score = []


    def sample_bandits( self, n=1 ):

        bb_score = np.zeros( n )
        choices = np.zeros( n )

        for k in range(n):
            #sample from the bandits&#39;s priors, and select the largest sample
            choice = np.argmax( rbeta( 1 + self.wins, 1 + self.trials - self.wins) )

            #sample the chosen bandit
            result = self.bandits.pull( choice )

            #update priors and score
            self.wins[ choice ] += result
            self.trials[ choice ] += 1
            bb_score[ k ] = result 
            self.N += 1
            choices[ k ] = choice

        self.bb_score = np.r_[ self.bb_score, bb_score ]
        self.choices = np.r_[ self.choices, choices ]
        return
</code></pre>
<p>Below we present a visualization of the algorithm sequentially learning the solution. In the figure below, the dashed lines represent the true hidden probabilities, which are (0.85, 0.60, 0.75)(this can be extended to many more dimensions, but the figure suffers, so I kept it at 3).</p>
<p><img src="/images/bb/updating2.png" alt=""></p>
<p>Note that we don’t real care how accurate we become about inference of the hidden probabilities — for this problem we are more interested in choosing the best bandit (or more accurately, becoming more confident in choosing the best bandit). For this reason, the distribution of the red bandit is very wide (representing ignorance about what that hidden probability might be) but we are reasonably confident that it is not the best, so the algorithm chooses to ignore it.</p>
<h3 id="u51E0_u7BC7_u4ECB_u7ECDBayesian_Bandits_u7684_u539F_u7406_u7684_u6587_u7AE0_uFF1A"><a href="#u51E0_u7BC7_u4ECB_u7ECDBayesian_Bandits_u7684_u539F_u7406_u7684_u6587_u7AE0_uFF1A" class="headerlink" title="几篇介绍Bayesian Bandits的原理的文章："></a>几篇介绍Bayesian Bandits的原理的文章：</h3><ol>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_analysis_conversion_rates.html</a></li>
<li>在线演示博弈过程： <a href="https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/" target="_blank" rel="external">https://e76d6ebf22ef8d7e079810f3d1f82ba1e5f145d5.googledrive.com/host/0B2GQktu-wcTiWDB2R2t2a2tMUG8/</a></li>
<li><a href="https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html" target="_blank" rel="external">https://www.chrisstucchio.com/blog/2013/bayesian_bandit.html</a></li>
<li><a href="http://camdp.com/blogs/multi-armed-bandits" target="_blank" rel="external">http://camdp.com/blogs/multi-armed-bandits</a></li>
<li>贝叶斯书籍：<a href="https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers" target="_blank" rel="external">https://github.com/lijingpeng/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/" data-id="ciszfj1rw0009j5s8jn39fb5g" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-application-md/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bandits/">Bandits</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/baysian-bandit-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/algo/baysian-bandit-md/">Bayesian Bandits – optimizing click throughs with statistics</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/algo/baysian-bandit-md/">
      <time datetime="2015-09-03T05:36:48.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>Great news! A murder victim has been found. No slow news day today! The story is already written, now a title needs to be selected. The clever reporter who wrote the story has come up with two potential titles – “Murder victim found in adult entertainment venue” and “Headless Body found in Topless Bar”. (The latter title is one I’ve shamelessly stolen from the NY Daily News.) Once upon a time, deciding which title to run was a matter for a news editor to decide. Those days are now over – the geeks now rule the earth. Title selection is now primarily an algorithmic problem, not an editorial one.</p>
<p>One common approach is to display both potential versions of the title on the homepage or news feed, and measure the Click Through Rate (CTR) of each version of the title. At some point, when the measured CTR for one title exceeds that of the other title, you’ll switch to the one with the highest for all users. Algorithms for solving this problem are called bandit algorithms.</p>
<p>In this blog post I’ll describe one of my favorite bandit algorithms, the Bayesian Bandit, and show why it is an excellent method to use for problems which give us more information than typical bandit algorithms.</p>
<p>Unless you are already familiar with Bayesian statistics and beta distributions, I strongly recommend reading the previous blog post. That post provides much introductory material, and I’ll depend on it heavily.</p>
<h2 id="1-_The_problem_to_be_solved_2C_and_the_underlying_model"><a href="#1-_The_problem_to_be_solved_2C_and_the_underlying_model" class="headerlink" title="1. The problem to be solved, and the underlying model"></a>1. The problem to be solved, and the underlying model</h2><hr>
<p>Ultimately the problem we want to solve is the following. Consider an article being published on a website. The author or editor has come up with several possible titles – “Murder victim found in adult entertainment venue”, “Headless Body found in Topless Bar”, etc. We want to choose the title with the best click through rate (CTR). Let us represent each CTR by θi – i.e., θi is the true probability that an individual user will click on the i-th title. As a simplifying assumption, we assume that these rates θi do not change over time. It is important to note that we don’t actually know what θi is – if we did, we could simply choose i for which θi was largest and move on.</p>
<p>The goal of the bandit algorithm is to do the following. To begin with, it should display all possible titles to a random selection of users, and measure which titles are clicked on more frequently. Over time, it will use these observations to infer which articles have the higher CTR. Then, once the estimation of the CTR becomes more precise, it will preferentially display articles with the higher CTR.</p>
<h2 id="2-_The_Bayesian_Approach"><a href="#2-_The_Bayesian_Approach" class="headerlink" title="2. The Bayesian Approach"></a>2. The Bayesian Approach</h2><hr>
<p>In the model described above, we have N possible story titles, each of which has a click through rate θi. Unfortunately we do not know what θi is. As the astute reader can guess from the title, we are following a Bayesian approach, so we will construct a probability distribution which represents our belief about what the actual value of θi is.<br><img src="/images/bb/beliefs_about_theta.png" alt=""><br>In the figure above, we believe that θi is somewhere between 0.1 and 0.7, with values of 0.3-0.4 being considerably more likely than values of 0.1-0.2 or 0.6-0.7. For those who forgot STATS 101, the area under this curve between the points a and b is the probability thta θi lies between a and b. I.e.:<br><img src="/images/bb/11.png" alt=""><br>The basic idea behind Bayesian methods is to update our beliefs based on evidence. As we gather more data by showing different titles to other users and observing click throughs, we can incrementally narrow the width of the probability distribution.</p>
<p>As in all Bayesian inference, we need to choose a prior. The prior is something we believe to be true before we have any evidence – i.e., before we have shown the title to any visitors. This is just a starting point – after enough evidence is gathered, our prior will play a very minimal role in what we actually believe. Choosing a good prior is important both for mathematical simplicity, and because if your prior is accurate, you don’t need as much evidence to get the correct answer.</p>
<p>I’ll follow the approach I described in a previous blog post, and I’ll use a beta distribution as the prior:<br><img src="/images/bb/31.png" alt=""><br>The parameters αi,βi&gt;1 are the prior parameters. One reasonable choice is αi=βi=1, which amounts to the uniform distribution on [0,1]. What this means is that we are assuming that all possible values of θi are equally likely. Depending on the circumstances (which I’ll explain shortly), we might want to choose other possible values.</p>
<h2 id="3-_Updating_our_beliefs"><a href="#3-_Updating_our_beliefs" class="headerlink" title="3. Updating our beliefs"></a>3. Updating our beliefs</h2><p>Now we address the question of using evidence. After showing title i to ni visitors, we have observed that si of them have actually clicked on the title. We now want to compute theposterior distribution, which is to say the distribution that represents our beliefs after we have evidence.</p>
<p>I did a little bit of algebra previously, in which I showed that if the prior is fαi,βi(θi), then the posterior distribution is:<br><img src="/images/bb/21.png" alt=""><br>The key idea here is that to update our probability distribution describing θi, we need only update the parameters of our beta distribution.</p>
<p>So what does this mean in practice? As we run more experiments, our probability distribution on where θi lives becomes sharper:</p>
<p><img src="/images/bb/beta_distribution_evolution.png" alt=""><br>Before we run any experiments, θi could be anything (as represented by the blue line). Once we have run 700 experiments, yielding 175 click throughs, we are reasonably confident that θi lives roughly between 0.2 and 0.3.</p>
<p>What we’ve done so far is figured out how to estimate what our click through rates actually are based on empirical evidence. But that doesn’t actually give us a method of optimizing them yet.</p>
<h2 id="4-_Optimizing_click_throughs"><a href="#4-_Optimizing_click_throughs" class="headerlink" title="4. Optimizing click throughs"></a>4. Optimizing click throughs</h2><p>Now that we have a method of representing our beliefs about CTRs, it is useful to construct an algorithm to identify the best ones. There are many popular choices – I’ve written about the UCB Algorithm before, and I consider it a good choice.</p>
<p>But my new favorite method is a Monte Carlo method which I’ll describe now.</p>
<p>The ultimate goal of the bandit algorithm is to display to the user whichever title has the highest CTR. One method of estimating the CTRs of the articles is to sample the posterior distribution. I.e., suppose we have two possible titles, from which we have drawn n0=200,s0=64and n1=180,n2=40. Then one possible set of samples we might observe is this:</p>
<p><img src="/images/bb/beta_distribution_sampling1.png" alt=""></p>
<p>For title 0, our sample of θ0 has worked out to be 0.35, while our sample of θ1 is only 0.28. Since θ0=0.35&gt;θ1=0.28, we will display title 0 to the user.</p>
<p>However, there was no guarantee that things worked out this way. It was possible, although less likely, that θ1 could come out larger than θ0:<br><img src="/images/bb/beta_distribution_sampling2.png" alt=""><br>In this case, we would have displayed title 1 to the user rather than title 0.</p>
<p>The net result is that for overlapping probability distributions, we will display the title with the larger expected CTR the majority of the time. But occasionally, we will draw from the other distributions simply because it is within the realm of possibility that they are greater.</p>
<p>As we gather more data our probability distributions will become narrower and a clear winner will become apparent. When this occurs, we will almost surely choose the winner:<br><img src="/images/bb/beta_distribution_sampling3.png" alt=""><br>In python, the algorithm looks like this:</p>
<p>The results of this algorithm are exactly what any good bandit algorithm should do. I ran the following simulation, giving the beta bandit two titles – title 0 had a CTR of 0.25, title 1 had a CTR of 0.35. To start with, both titles were displayed to the user with roughly equal probability. Over time, evidence accumulated that title 1 was considerably better than title 0. At this point the algorithm switched to displaying primarily title 1, and the overall CTR of the experiment converged to 0.35 (the optimal CTR).</p>
<p><img src="/images/bb/beta_bandit_results.png" alt=""></p>
<p>Source code to generate this graph is available here. This method is called Thompson Sampling and is a a fairly popular method in Bayesian AI techniques. For the remainder of this post, I’ll call this method the Bayesian Bandit.</p>
<h2 id="5-Incorporating_common_sense"><a href="#5-Incorporating_common_sense" class="headerlink" title="5.Incorporating common sense"></a>5.Incorporating common sense</h2><p>Anyone with common sense is now scoffing at the geekiness embodied in this post. Even before using statistics, it was fairly obvious that “Headless Body found in Topless Bar” was going to beat “Murder victim found in adult entertainment venue”. The former just sounds catchier and any good editor would run with it.</p>
<p>The wonderful thing about Bayesian methods is that we can modify them to take into account our prior knowledge. Suppose we believe editors intuition is a real thing – can we quantify it? Certainly. We can do this with a fairly simple experiment. We require editors to rate a collection of titles as “catchy” or “not catchy”, run them on the site, and then measure the CTR of the “catchy” and “not catchy” samples. Suppose we did such an experiment, and observed the following aggregate results:</p>
<p><img src="/images/bb/empirical_prior.png" alt=""></p>
<p>This isn’t a solid win for the editor – some catchy titles have low CTRs, and some boring titles have good CTRs. But nevertheless, it’s better for a story to have catchy title than not.</p>
<p>What we want to do is incorporate this information into our bandit algorithm. The beauty of a Bayesian method is that it gives you a clear and meaningful place to plug this information in, namely the prior. In contrast, for many other methods (e.g., UCB) it’s somewhat difficult to do this – there is no obvious parameter to tune as a result of our prior empirical data.</p>
<p>The first step is to fit a theoretical distribution to the empirical data. Due to the fact that I chose the “empirical” (i.e., made up) data to be very nice, a beta distribution fits well [1] – specifically beta distributions with (α0,β0)=(9,20) and (α1,β1)=(4,20).<br><img src="/images/bb/theoretical_prior.png" alt=""></p>
<p>Then the only modification needed to the algorithm is to plug these variables into the prior:<br><img src="/images/bb/41.png" alt=""><br>Everything else remains unchanged. In terms of modifications to source code, this is only a very small change to the previous code – an implementation can be found here.</p>
<h2 id="6-_Empirics_of_including_priors"><a href="#6-_Empirics_of_including_priors" class="headerlink" title="6. Empirics of including priors"></a>6. Empirics of including priors</h2><p>To measure the benefits of incorporating priors into the Bayesian bandit, I ran some numerical experiments, the source code of which is available in this github gist. The methodology was the following.</p>
<p>To compare the Bayesian bandit with priors to that without, I drew a pair (θ0,θ1) from the prior distribution given above. For each pair, I then ran the Bayes Bandit with and without priors for this pair theta, for k trials. This is modelling the scenario that we have k page views on our homepage, and we can only leave a story on the homepage for 1 day.</p>
<p>I then repeated the experiment for 1000 different possible days, or equivalently for 1000 different pairs of (θ0,θ1). I then computed the average gain per page view over all trials and all days.</p>
<p>The result is the following. If we get 50 page views/day (i.e., the Bayes Bandit has very little data to use), the prior gives us a big gain. Without prior knowledge, the Bandit achieved a gain of 0.3749 on average, whereas the bandit with prior knowledge achieved a gain of 0.4274. If we run 150 experiments, the Bayes Bandit improves significantly – it achieves a gain of 0.40. If we run 300 experiments, the Bayes Bandit improves to 0.4146, while the bandit with priors improves to 0.4296. If we get 1000 page views/day, the Bayes Bandit improves to 0.4211, while the bandit with priors gains 0.4249.</p>
<p>The net result is the following – incorporating priors into the Bayes Bandit is an excellent way to improve your results when you don’t have a large number data points to use to train the bandit. If you have a lot of data points, you don’t need strong priors (but they still help a little).</p>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7.Conclusion"></a>7.Conclusion</h2><p>Bandit algorithms are a great way of optimizing many factors of your website. There are many good options – I’ve written about UCB before and consider it a great choice. But if you have other information you want to include, consider using the Bayesian Bandit. It’s simple to implement, straightforward to use, and very importantly it’s also straightforward to extend.</p>
<p>It’s also important to note that the theoretical properties of the Bayesian Bandit (namely logarithmic regret) have been proven. So asymptotically, you lose nothing by using it. There are also attempts at constructing a Bayesian UCB algorithm – I don’t currently understand it well enough to comment.</p>
<p>I’ve written other articles related to this post. I have one post comparing bandit algorithms to a/b testing. I also I wrote about measuring a changing conversion rate, which provides an alternate algorithm for computing the posterior distribution if your conversion rate is not constant.</p>
<p>[1] If a single Beta distribution doesn’t fit, one can also use a convex combination of Beta distributions. The math works out just as nicely.</p>
<p>P.S. After I published this blog post, this related article was also pointed out to me, as was this online simulation of the Bayesian bandit.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/" data-id="ciszfj1ru0008j5s83vzkyq1e" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/algo/baysian-bandit-md/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bandits/">Bandits</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-dev/hive-udf-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/dev/hive-udf-md/">Hive UDF开发</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/dev/hive-udf-md/">
      <time datetime="2015-09-03T04:49:45.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>Hive进行UDAF开发，相对要比UDF复杂一些，不过也不是很难。请看一个例子:</p>
<pre><code class="java">package org.hrj.hive.udf;

import org.apache.hadoop.hive.ql.exec.UDAFEvaluator;
import org.apache.hadoop.hive.serde2.io.DoubleWritable;

public class UDAFSum_Sample extends NumericUDAF {
    public static class Evaluator implements UDAFEvaluator {
        private boolean mEmpty;
        private double mSum;
        public Evaluator() {
            super();
            init();
        }

        public void init() {
            mSum = 0;
            mEmpty = true;
        }

        public boolean iterate(DoubleWritable o) {
            if (o != null) {
                mSum += o.get();
                mEmpty = false;
            }
            return true;
        }

        public DoubleWritable terminatePartial() {
            // This is SQL standard - sum of zero items should be null.
            return mEmpty ? null : new DoubleWritable(mSum);
        }

        public boolean merge(DoubleWritable o) {
            if (o != null) {
                mSum += o.get();
                mEmpty = false;
            }
            return true;
        }

        public DoubleWritable terminate() {
            // This is SQL standard - sum of zero items should be null.
            return mEmpty ? null : new DoubleWritable(mSum);
        }
    }
}
</code></pre>
<p>1.将java文件编译成Sum_Sample.jar</p>
<p>2.进入hive</p>
<pre><code class="bash">
hive&gt; add jar Sum_sample.jar;

hive&gt; create temporary function sum_test as &#39;com.hrj.hive.udf.UDAFSum_Sample&#39;;

hive&gt; select sum_test(t.num) from t;

hive&gt; drop temporary function sum_test;

hive&gt; quit;
</code></pre>
<p>关于UDAF开发注意点：</p>
<p>1.需要import org.apache.hadoop.hive.ql.exec.UDAF以及org.apache.hadoop.hive.ql.exec.UDAFEvaluator,这两个包都是必须的</p>
<p>2.函数类需要继承UDAF类，内部类Evaluator实现UDAFEvaluator接口</p>
<p>3.Evaluator需要实现 init、iterate、terminatePartial、merge、terminate这几个函数</p>
<pre><code>1）init函数类似于构造函数，用于UDAF的初始化

2）iterate接收传入的参数，并进行内部的轮转。其返回类型为boolean

3）terminatePartial无参数，其为iterate函数轮转结束后，返回乱转数据，iterate和terminatePartial类似于hadoop的Combiner

4）merge接收terminatePartial的返回结果，进行数据merge操作，其返回类型为boolean

5）terminate返回最终的聚集函数结果
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/dev/hive-udf-md/" data-id="ciszfj1sl000pj5s8ghu5126f" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/dev/hive-udf-md/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <article id="post-opensource/input-font-md" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/03/opensource/input-font-md/">Input mono字体</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/09/03/opensource/input-font-md/">
      <time datetime="2015-09-03T03:20:50.000Z" itemprop="datePublished">2015-09-03</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/dev/">dev</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p>Input Mono字体作为编程字体挺好看的, 该字体对个人非商业用户是免费的, 并且支持自定义.</p>
<p>地址: <a href="http://input.fontbureau.com" target="_blank" rel="external">http://input.fontbureau.com</a></p>
<p><img src="/images/input_mono.png" alt=""></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/09/03/opensource/input-font-md/" data-id="ciszfj1sz000yj5s857g98ehk" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/09/03/opensource/input-font-md/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/font/">font</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/feature_d" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/06/06/algo/feature_d/">机器学习中的数据清洗与特征处理综述</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2015/06/06/algo/feature_d/">
      <time datetime="2015-06-05T16:00:00.000Z" itemprop="datePublished">2015-06-06</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="u7279_u5F81_u5206_u7C7B"><a href="#u7279_u5F81_u5206_u7C7B" class="headerlink" title="特征分类"></a>特征分类</h2><hr>
<p>　　在分析完特征和标注的清洗方法之后，下面来具体介绍下特征的处理方法，先对特征进行分类，对于不同的特征应该有不同的处理方法。根据不同的分类方法，可以将特征分为</p>
<ul>
<li>Low level特征和High level特征。</li>
<li>稳定特征与动态特征。</li>
<li>二值特征、连续特征、枚举特征。</li>
</ul>
<p>　　Low level特征是较低级别的特征，主要是原始特征，不需要或者需要非常少的人工处理和干预，例如文本特征中的词向量特征，图像特征中的像素点，用户id，商品id等。Low level特征一般维度比较高，不能用过于复杂的模型。High level特征是经过较复杂的处理，结合部分业务逻辑或者规则、模型得到的特征，例如人工打分，模型打分等特征，可以用于较复杂的非线性模型。Low level 比较针对性，覆盖面小。长尾样本的预测值主要受high level特征影响。高频样本的预测值主要受low level特征影响。</p>
<p>　　稳定特征是变化频率(更新频率)较少的特征，例如评价平均分，团购单价格等，在较长的时间段内都不会发生变化。动态特征是更新变化比较频繁的特征，有些甚至是实时计算得到的特征，例如距离特征，2小时销量等特征。或者叫做实时特征和非实时特征。针对两类特征的不同可以针对性地设计特征存储和更新方式，例如对于稳定特征，可以建入索引，较长时间更新一次，如果做缓存的话，缓存的时间可以较长。对于动态特征，需要实时计算或者准实时地更新数据，如果做缓存的话，缓存过期时间需要设置的较短。</p>
<p>　　二值特征主要是0/1特征，即特征只取两种值：0或者1，例如用户id特征：目前的id是否是某个特定的id，词向量特征：某个特定的词是否在文章中出现等等。连续值特征是取值为有理数的特征，特征取值个数不定，例如距离特征，特征取值为是0~正无穷。枚举值特征主要是特征有固定个数个可能值，例如今天周几，只有7个可能值：周1，周2，…，周日。在实际的使用中，我们可能对不同类型的特征进行转换，例如将枚举特征或者连续特征处理为二值特征。枚举特征处理为二值特征技巧：将枚举特征映射为多个特征，每个特征对应一个特定枚举值，例如今天周几，可以把它转换成7个二元特征：今天是否是周一，今天是否是周二，…，今天是否是周日。连续值处理为二值特征方法：先将连续值离散化（后面会介绍如何离散化), 再将离散化后的特征切分为N个二元特征，每个特征代表是否在这个区间内。</p>
<h2 id="u7279_u5F81_u5904_u7406_u4E0E_u5206_u6790"><a href="#u7279_u5F81_u5904_u7406_u4E0E_u5206_u6790" class="headerlink" title="特征处理与分析"></a>特征处理与分析</h2><hr>
<p>　　在对特征进行分类后，下面介绍下对特征常用的处理方法。包括1.特征归一化，离散化，缺省值处理。2.特征降维方法。3.特征选择方法等。</p>
<h3 id="u5F52_u4E00_u5316"><a href="#u5F52_u4E00_u5316" class="headerlink" title="归一化"></a>归一化</h3><p>　　不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括：</p>
<ol>
<li>函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。</li>
<li>分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。</li>
<li>排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。</li>
</ol>
<h3 id="u79BB_u6563_u5316"><a href="#u79BB_u6563_u5316" class="headerlink" title="离散化"></a>离散化</h3><p>　　在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，…，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。</p>
<h3 id="u7F3A_u7701_u503C_u5904_u7406"><a href="#u7F3A_u7701_u503C_u5904_u7406" class="headerlink" title="缺省值处理"></a>缺省值处理</h3><p>　　有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等。<br>特征降维</p>
<p>　　在介绍特征降维之前，先介绍下特征升维。在机器学习中，有一个VC维理论。根据VC维理论，VC维越高，打散能力越强，可容许的模型复杂度越高。在低维不可分的数据，映射到高维是可分。可以想想，给你一堆物品，人脑是如何对这些物品进行分类，依然是找出这些物品的一些特征，例如：颜色，形状，大小，触感等等，然后根据这些特征对物品做以归类，这其实就是一个先升维，后划分的过程。比如我们人脑识别香蕉。可能首先我们发现香蕉是黄色的。这是在颜色这个维度的一个切分。但是很多东西都是黄色的啊，例如哈密瓜。那么怎么区分香蕉和哈密瓜呢？我们发现香蕉形状是弯曲的。而哈密瓜是圆形的，那么我们就可以用形状来把香蕉和哈密瓜划分开了，即引入一个新维度：形状，来区分。这就是一个从“颜色”一维特征升维到二维特征的例子。</p>
<p>　　那问题来了，既然升维后模型能力能变强，那么是不是特征维度越高越好呢？为什么要进行特征降维&amp;特征选择？主要是出于如下考虑：</p>
<ol>
<li>特征维数越高，模型越容易过拟合，此时更复杂的模型就不好用。</li>
<li>相互独立的特征维数越高，在模型不变的情况下，在测试集上达到相同的效果表现所需要的训练样本的数目就越大。 </li>
<li>特征数量增加带来的训练、测试以及存储的开销都会增大。</li>
<li>在某些模型中，例如基于距离计算的模型KMeans，KNN等模型，在进行距离计算时，维度过高会影响精度和性能。</li>
<li>可视化分析的需要。在低维的情况下，例如二维，三维，我们可以把数据绘制出来，可视化地看到数据。当维度增高时，就难以绘制出来了。在机器学习中，有一个非常经典的维度灾难的概念。用来描述当空间维度增加时，分析和组织高维空间，因体积指数增加而遇到各种问题场景。例如，100个平均分布的点能把一个单位区间以每个点距离不超过0.01采样；而当维度增加到10后，如果以相邻点距离不超过0.01小方格采样单位超一单位超正方体，则需要10^20 个采样点。</li>
</ol>
<p>　　正是由于高维特征有如上描述的各种各样的问题，所以我们需要进行特征降维和特征选择等工作。特征降维常用的算法有PCA，LDA等。特征降维的目标是将高维空间中的数据集映射到低维空间数据，同时尽可能少地丢失信息，或者降维后的数据点尽可能地容易被区分</p>
<h4 id="PCA_u7B97_u6CD5"><a href="#PCA_u7B97_u6CD5" class="headerlink" title="PCA算法"></a>PCA算法</h4><p>　　通过协方差矩阵的特征值分解能够得到数据的主成分，以二维特征为例，两个特征之间可能存在线性关系（例如运动的时速和秒速度），这样就造成了第二维信息是冗余的。PCA的目标是发现这种特征之间的线性关系，并去除。</p>
<h4 id="LDA_u7B97_u6CD5"><a href="#LDA_u7B97_u6CD5" class="headerlink" title="LDA算法"></a>LDA算法</h4><p>考虑label，降维后的数据点尽可能地容易被区分</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2015/06/06/algo/feature_d/" data-id="ciszfj1ry000aj5s85wd7jvhb" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2015/06/06/algo/feature_d/#ds-thread" class="article-comment-link">评论</a>
      
      
    </footer>
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/15/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="page-number" href="/page/15/">15</a><span class="page-number current">16</span><a class="page-number" href="/page/17/">17</a><a class="page-number" href="/page/18/">18</a><span class="space">&hellip;</span><a class="page-number" href="/page/21/">21</a><a class="extend next" rel="next" href="/page/17/">下一页 &raquo;</a>
      </nav>
    </section>
      
        <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul id="recent-post" class="">
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/09/11/other/public_cdn/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/other/">other</a></p>
              <p class="item-title"><a href="/2016/09/11/other/public_cdn/" class="title">CDNJS 库以及 Google Fonts、Ajax 和 Gravatar 反代</a></p>
              <p class="item-date"><time datetime="2016-09-10T16:00:00.000Z" itemprop="datePublished">2016-09-11</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/09/09/algo/kaggle/gbid/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/kaggle/">kaggle</a></p>
              <p class="item-title"><a href="/2016/09/09/algo/kaggle/gbid/" class="title">kaggle之Grupo Bimbo Inventory Demand</a></p>
              <p class="item-date"><time datetime="2016-09-09T05:48:13.000Z" itemprop="datePublished">2016-09-09</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/09/08/dev/python/pandas_reset_index/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/09/08/dev/python/pandas_reset_index/" class="title">pandas reset_index</a></p>
              <p class="item-date"><time datetime="2016-09-08T02:19:56.000Z" itemprop="datePublished">2016-09-08</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/08/31/dev/python/python_print_chs/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/08/31/dev/python/python_print_chs/" class="title">Python print 中文乱码问题</a></p>
              <p class="item-date"><time datetime="2016-08-31T02:19:56.000Z" itemprop="datePublished">2016-08-31</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/08/26/algo/kaggle/facial_keypoints/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/kaggle/">kaggle</a></p>
              <p class="item-title"><a href="/2016/08/26/algo/kaggle/facial_keypoints/" class="title">kaggle之人脸特征识别</a></p>
              <p class="item-date"><time datetime="2016-08-26T05:48:13.000Z" itemprop="datePublished">2016-08-26</time></p>
            </div>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hash/">Hash</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Photo/">Photo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SQL/">SQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ads/">ads</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c++</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/dev/">dev</a><span class="category-list-count">31</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/github/">github</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/internet/">internet</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/kaggle/">kaggle</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">20</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/system/">system</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/travel/">travel</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Apache/" style="font-size: 10px;">Apache</a> <a href="/tags/Bandits/" style="font-size: 12.5px;">Bandits</a> <a href="/tags/Elasticsearch-docker/" style="font-size: 10px;">Elasticsearch, docker</a> <a href="/tags/FlatBuffers/" style="font-size: 10px;">FlatBuffers</a> <a href="/tags/Google/" style="font-size: 10px;">Google</a> <a href="/tags/Granger-causality/" style="font-size: 10px;">Granger causality</a> <a href="/tags/GridSearchCV/" style="font-size: 10px;">GridSearchCV</a> <a href="/tags/HTTPS/" style="font-size: 10px;">HTTPS</a> <a href="/tags/Jquery/" style="font-size: 10px;">Jquery</a> <a href="/tags/MapReduce/" style="font-size: 10px;">MapReduce</a> <a href="/tags/Mock/" style="font-size: 10px;">Mock</a> <a href="/tags/Monument-Vallay/" style="font-size: 10px;">Monument Vallay</a> <a href="/tags/Mysql/" style="font-size: 12.5px;">Mysql</a> <a href="/tags/PPTP-vpn/" style="font-size: 12.5px;">PPTP, vpn</a> <a href="/tags/Photoshop/" style="font-size: 10px;">Photoshop</a> <a href="/tags/Pipeline/" style="font-size: 10px;">Pipeline</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/ad/" style="font-size: 10px;">ad</a> <a href="/tags/apache/" style="font-size: 10px;">apache</a> <a href="/tags/blade/" style="font-size: 10px;">blade</a> <a href="/tags/crontab/" style="font-size: 10px;">crontab</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/elasticsearch/" style="font-size: 12.5px;">elasticsearch</a> <a href="/tags/font/" style="font-size: 10px;">font</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/go/" style="font-size: 17.5px;">go</a> <a href="/tags/hashmap/" style="font-size: 10px;">hashmap</a> <a href="/tags/kaggle/" style="font-size: 20px;">kaggle</a> <a href="/tags/linux-ldd-依赖关系/" style="font-size: 10px;">linux, ldd, 依赖关系</a> <a href="/tags/lucene/" style="font-size: 10px;">lucene</a> <a href="/tags/nio/" style="font-size: 10px;">nio</a> <a href="/tags/pagerank/" style="font-size: 10px;">pagerank</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/swift-llvm/" style="font-size: 10px;">swift, llvm</a> <a href="/tags/前端/" style="font-size: 10px;">前端</a> <a href="/tags/广告/" style="font-size: 12.5px;">广告</a> <a href="/tags/开源，许可/" style="font-size: 10px;">开源，许可</a> <a href="/tags/澳门/" style="font-size: 10px;">澳门</a> <a href="/tags/监控，zabbix/" style="font-size: 10px;">监控，zabbix</a> <a href="/tags/贝叶斯/" style="font-size: 10px;">贝叶斯</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">三月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">六月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">二月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">十一月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">十月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">六月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">十一月 2013</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
  <div id="toTop" class="fa fa-chevron-up"></div>
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Li Jingpeng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
    </div>
  </div>
</footer>
    

<script type="text/javascript">
  var duoshuoQuery = {short_name:"lijingpeng"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>


<script src="//ajax.css.network/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>