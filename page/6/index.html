<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Frank</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="计算机 网络 互联网">
<meta property="og:type" content="website">
<meta property="og:title" content="Frank">
<meta property="og:url" content="http://www.notehub.cn/page/6/index.html">
<meta property="og:site_name" content="Frank">
<meta property="og:description" content="计算机 网络 互联网">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Frank">
<meta name="twitter:description" content="计算机 网络 互联网">
  
  
    <link rel="icon" href="favicon.png">
  
  <link href='//fonts.css.network/css?family=Open+Sans:400italic,400,600' rel='stylesheet' type='text/css'>
  <link href="//fonts.css.network/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  

  
</head>

<body>
  <div id="container">
    <header id="header">
  <div id="header-main" class="header-inner">
    <div class="outer">
      <a href="/" id="logo"><i class="logo" style="background-image: url(/css/images/logo.jpg)"></i><span class="site-title">Frank</span></a>
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/.">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/categories">Categories</a>
        
          <a class="main-nav-link" href="/tags">Tags</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
      </nav>
      
        <nav id="sub-nav">
          <div class="profile" id="profile-nav">
            <a id="profile-anchor" href="javascript:;"><img class="avatar" src="/css/images/logo.png"><i class="fa fa-caret-down"></i></a>
          </div>
        </nav>
      
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"> </button><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
      </div>
    </div>
  </div>
  <div id="main-nav-mobile" class="header-sub header-inner">
    <table class="menu outer">
      <tr>
        
          <td><a class="main-nav-link" href="/.">Home</a></td>
        
          <td><a class="main-nav-link" href="/archives">Archives</a></td>
        
          <td><a class="main-nav-link" href="/categories">Categories</a></td>
        
          <td><a class="main-nav-link" href="/tags">Tags</a></td>
        
          <td><a class="main-nav-link" href="/about">About</a></td>
        
        <td>
          <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="hidden" name="sitesearch" value="http://www.notehub.cn"></form>
        </td>
      </tr>
    </table>
  </div>
</header>

    <div class="outer">
      
        <aside id="profile">
  <div class="inner profile-inner">
    <div class="base-info profile-block">
      <img id="avatar" src="/css/images/logo.png">
      <h2 id="name">Li Jingpeng</h2>
      <!-- <h3 id="title">undefined</h3> -->
      <span id="location"><i class="fa fa-map-marker"></i>Hangzhou, China</span>
      <a id="follow" href="Https://weibo.com/329299516">关注我</a>
    </div>
    <div class="article-info profile-block">
      <div class="article-info-block">
        118
        <span>文章</span>
      </div>
      <div class="article-info-block">
        42
        <span>标签</span>
      </div>
    </div>
    
    <div class="contact-info profile-block">
      <table class="contact-list">
        <tr>
          
          <td><a href="https://github.com/lijingpeng" target="_blank" title="github"><i class="fa fa-github"></i></a></td>
          
          <td><a href="#" target="_blank" title="twitter"><i class="fa fa-twitter"></i></a></td>
          
          <td><a href="#" target="_blank" title="facebook"><i class="fa fa-facebook"></i></a></td>
          
          <td><a href="/me@lijingpeng.org" target="_blank" title="email"><i class="fa fa-email"></i></a></td>
          
          <td><a href="/atom.xml" target="_blank" title="rss"><i class="fa fa-rss"></i></a></td>
          
        </tr>
      </table>
    </div>
    
    
  </div>
</aside>

      
      <section id="main">
      <article id="post-algo/kaggle/titanic" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/19/algo/kaggle/titanic/">kaggle之Titanic 沉没</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/19/algo/kaggle/titanic/">
      <time datetime="2016-08-19T12:30:13.000Z" itemprop="datePublished">2016-08-19</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="Titanic__u6C89_u6CA1"><a href="#Titanic__u6C89_u6CA1" class="headerlink" title="Titanic 沉没"></a>Titanic 沉没</h2><p><a href="https://github.com/lijingpeng" target="_blank" rel="external">Github地址</a>     </p>
<p>这是一个分类任务，特征包含离散特征和连续特征，数据如下：<a href="https://www.kaggle.com/c/titanic/data" target="_blank" rel="external">Kaggle地址</a>。目标是根据数据特征预测一个人是否能在泰坦尼克的沉没事故中存活下来。接下来解释下数据的格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">survival        目标列，是否存活，1代表存活 (0 = No; 1 = Yes)  </div><div class="line">pclass          乘坐的舱位级别 (1 = 1st; 2 = 2nd; 3 = 3rd)  </div><div class="line">name            姓名</div><div class="line">sex             性别  </div><div class="line">age             年龄  </div><div class="line">sibsp           兄弟姐妹的数量（乘客中）  </div><div class="line">parch           父母的数量（乘客中）  </div><div class="line">ticket          票号  </div><div class="line">fare            票价  </div><div class="line">cabin           客舱  </div><div class="line">embarked        登船的港口  </div><div class="line">                (C = Cherbourg; Q = Queenstown; S = Southampton)</div></pre></td></tr></table></figure>
<h2 id="u8F7D_u5165_u6570_u636E_u5E76_u5206_u6790"><a href="#u8F7D_u5165_u6570_u636E_u5E76_u5206_u6790" class="headerlink" title="载入数据并分析"></a>载入数据并分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> string</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">'train.csv'</span>)</div><div class="line">test = pd.read_csv(<span class="string">'test.csv'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">substrings_in_string</span><span class="params">(big_string, substrings)</span>:</span></div><div class="line">    <span class="keyword">for</span> substring <span class="keyword">in</span> substrings:</div><div class="line">        <span class="keyword">if</span> string.find(big_string, substring) != <span class="number">-1</span>:</div><div class="line">            <span class="keyword">return</span> substring</div><div class="line">    <span class="keyword">return</span> np.nan</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">replace_titles</span><span class="params">(x)</span>:</span></div><div class="line">    title=x[<span class="string">'Title'</span>]</div><div class="line">    <span class="keyword">if</span> title <span class="keyword">in</span> [<span class="string">'Mr'</span>,<span class="string">'Don'</span>, <span class="string">'Major'</span>, <span class="string">'Capt'</span>, <span class="string">'Jonkheer'</span>, <span class="string">'Rev'</span>, <span class="string">'Col'</span>]:</div><div class="line">        <span class="keyword">return</span> <span class="string">'Mr'</span></div><div class="line">    <span class="keyword">elif</span> title <span class="keyword">in</span> [<span class="string">'Master'</span>]:</div><div class="line">        <span class="keyword">return</span> <span class="string">'Master'</span></div><div class="line">    <span class="keyword">elif</span> title <span class="keyword">in</span> [<span class="string">'Countess'</span>, <span class="string">'Mme'</span>,<span class="string">'Mrs'</span>]:</div><div class="line">        <span class="keyword">return</span> <span class="string">'Mrs'</span></div><div class="line">    <span class="keyword">elif</span> title <span class="keyword">in</span> [<span class="string">'Mlle'</span>, <span class="string">'Ms'</span>,<span class="string">'Miss'</span>]:</div><div class="line">        <span class="keyword">return</span> <span class="string">'Miss'</span></div><div class="line">    <span class="keyword">elif</span> title ==<span class="string">'Dr'</span>:</div><div class="line">        <span class="keyword">if</span> x[<span class="string">'Sex'</span>]==<span class="string">'Male'</span>:</div><div class="line">            <span class="keyword">return</span> <span class="string">'Mr'</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="string">'Mrs'</span></div><div class="line">    <span class="keyword">elif</span> title ==<span class="string">''</span>:</div><div class="line">        <span class="keyword">if</span> x[<span class="string">'Sex'</span>]==<span class="string">'Male'</span>:</div><div class="line">            <span class="keyword">return</span> <span class="string">'Master'</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> <span class="string">'Miss'</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> title</div><div class="line"></div><div class="line">title_list = [<span class="string">'Mrs'</span>, <span class="string">'Mr'</span>, <span class="string">'Master'</span>, <span class="string">'Miss'</span>, <span class="string">'Major'</span>, <span class="string">'Rev'</span>,</div><div class="line">                <span class="string">'Dr'</span>, <span class="string">'Ms'</span>, <span class="string">'Mlle'</span>,<span class="string">'Col'</span>, <span class="string">'Capt'</span>, <span class="string">'Mme'</span>, <span class="string">'Countess'</span>,</div><div class="line">                <span class="string">'Don'</span>, <span class="string">'Jonkheer'</span>]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">label = train[<span class="string">'Survived'</span>] <span class="comment"># 目标列</span></div></pre></td></tr></table></figure>
<h3 id="Pclass_u3001Sex_u3001Embarked_u79BB_u6563_u7279_u5F81_u6570_u636E_u9884_u89C8"><a href="#Pclass_u3001Sex_u3001Embarked_u79BB_u6563_u7279_u5F81_u6570_u636E_u9884_u89C8" class="headerlink" title="Pclass、Sex、Embarked离散特征数据预览"></a>Pclass、Sex、Embarked离散特征数据预览</h3><p>除此之外Name、Ticket、Cabin也是离散特征，我们暂时不用这几个特征，直观上来讲，叫什么名字跟在事故中是否存活好像没有太大的联系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 接下来我们对每个特征进行一下分析：</span></div><div class="line">train.groupby([<span class="string">'Pclass'</span>])[<span class="string">'PassengerId'</span>].count().plot(kind=<span class="string">'bar'</span>)</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x102bef590&gt;
</code></pre><p><img src="output_6_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.groupby([<span class="string">'SibSp'</span>])[<span class="string">'PassengerId'</span>].count().plot(kind=<span class="string">'bar'</span>)</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x106c41a10&gt;
</code></pre><p><img src="output_7_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.groupby([<span class="string">'Parch'</span>])[<span class="string">'PassengerId'</span>].count().plot(kind=<span class="string">'bar'</span>)</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x106d7b090&gt;
</code></pre><p><img src="output_8_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.groupby([<span class="string">'Embarked'</span>])[<span class="string">'PassengerId'</span>].count().plot(kind=<span class="string">'bar'</span>)</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x106eca590&gt;
</code></pre><p><img src="output_9_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.groupby([<span class="string">'Sex'</span>])[<span class="string">'PassengerId'</span>].count().plot(kind=<span class="string">'bar'</span>)</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes.AxesSubplot at 0x106ff83d0&gt;
</code></pre><p><img src="output_10_1.png" alt="png"></p>
<h3 id="u8FDE_u7EED_u7279_u5F81_u5904_u7406"><a href="#u8FDE_u7EED_u7279_u5F81_u5904_u7406" class="headerlink" title="连续特征处理"></a>连续特征处理</h3><p>Age、Fare是连续特征，观察数据分布查看是否有缺失值和异常值，我们看到Age中存在缺失值，我们考虑使用均值来填充缺失值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'检测是否有缺失值：'</span></div><div class="line"><span class="keyword">print</span> train[train[<span class="string">'Age'</span>].isnull()][<span class="string">'Age'</span>].head()</div><div class="line"><span class="keyword">print</span> train[train[<span class="string">'Fare'</span>].isnull()][<span class="string">'Fare'</span>].head()</div><div class="line"><span class="keyword">print</span> train[train[<span class="string">'SibSp'</span>].isnull()][<span class="string">'SibSp'</span>].head()</div><div class="line"><span class="keyword">print</span> train[train[<span class="string">'Parch'</span>].isnull()][<span class="string">'Parch'</span>].head()</div><div class="line">train[<span class="string">'Age'</span>] = train[<span class="string">'Age'</span>].fillna(train[<span class="string">'Age'</span>].mean())</div><div class="line"><span class="keyword">print</span> <span class="string">'填充之后再检测：'</span></div><div class="line"><span class="keyword">print</span> train[train[<span class="string">'Age'</span>].isnull()][<span class="string">'Age'</span>].head()</div><div class="line"><span class="keyword">print</span> train[train[<span class="string">'Fare'</span>].isnull()][<span class="string">'Fare'</span>].head()</div></pre></td></tr></table></figure>
<pre><code>检测是否有缺失值：
5    NaN
17   NaN
19   NaN
26   NaN
28   NaN
Name: Age, dtype: float64
Series([], Name: Fare, dtype: float64)
Series([], Name: SibSp, dtype: int64)
Series([], Name: Parch, dtype: int64)
填充之后再检测：
Series([], Name: Age, dtype: float64)
Series([], Name: Fare, dtype: float64)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'检测测试集是否有缺失值：'</span></div><div class="line"><span class="keyword">print</span> test[test[<span class="string">'Age'</span>].isnull()][<span class="string">'Age'</span>].head()</div><div class="line"><span class="keyword">print</span> test[test[<span class="string">'Fare'</span>].isnull()][<span class="string">'Fare'</span>].head()</div><div class="line"><span class="keyword">print</span> test[test[<span class="string">'SibSp'</span>].isnull()][<span class="string">'SibSp'</span>].head()</div><div class="line"><span class="keyword">print</span> test[test[<span class="string">'Parch'</span>].isnull()][<span class="string">'Parch'</span>].head()</div><div class="line">test[<span class="string">'Age'</span>] = test[<span class="string">'Age'</span>].fillna(test[<span class="string">'Age'</span>].mean())</div><div class="line">test[<span class="string">'Fare'</span>] = test[<span class="string">'Fare'</span>].fillna(test[<span class="string">'Fare'</span>].mean())</div><div class="line"><span class="keyword">print</span> <span class="string">'填充之后再检测：'</span></div><div class="line"><span class="keyword">print</span> test[test[<span class="string">'Age'</span>].isnull()][<span class="string">'Age'</span>].head()</div><div class="line"><span class="keyword">print</span> test[test[<span class="string">'Fare'</span>].isnull()][<span class="string">'Fare'</span>].head()</div></pre></td></tr></table></figure>
<pre><code>检测测试集是否有缺失值：
10   NaN
22   NaN
29   NaN
33   NaN
36   NaN
Name: Age, dtype: float64
152   NaN
Name: Fare, dtype: float64
Series([], Name: SibSp, dtype: int64)
Series([], Name: Parch, dtype: int64)
填充之后再检测：
Series([], Name: Age, dtype: float64)
Series([], Name: Fare, dtype: float64)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 处理Title特征</span></div><div class="line">train[<span class="string">'Title'</span>] = train[<span class="string">'Name'</span>].map(<span class="keyword">lambda</span> x: substrings_in_string(x, title_list))</div><div class="line">test[<span class="string">'Title'</span>] = test[<span class="string">'Name'</span>].map(<span class="keyword">lambda</span> x: substrings_in_string(x, title_list))</div><div class="line"></div><div class="line">train[<span class="string">'Title'</span>] = train.apply(replace_titles, axis=<span class="number">1</span>)</div><div class="line">test[<span class="string">'Title'</span>] = test.apply(replace_titles, axis=<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># family特征</span></div><div class="line">train[<span class="string">'Family_Size'</span>] = train[<span class="string">'SibSp'</span>] + train[<span class="string">'Parch'</span>]</div><div class="line">train[<span class="string">'Family'</span>] = train[<span class="string">'SibSp'</span>] * train[<span class="string">'Parch'</span>]</div><div class="line">test[<span class="string">'Family_Size'</span>] = test[<span class="string">'SibSp'</span>] + test[<span class="string">'Parch'</span>]</div><div class="line">test[<span class="string">'Family'</span>] = test[<span class="string">'SibSp'</span>] * test[<span class="string">'Parch'</span>]</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">train[<span class="string">'AgeFill'</span>] = train[<span class="string">'Age'</span>]</div><div class="line">mean_ages = np.zeros(<span class="number">4</span>)</div><div class="line">mean_ages[<span class="number">0</span>] = np.average(train[train[<span class="string">'Title'</span>] == <span class="string">'Miss'</span>][<span class="string">'Age'</span>].dropna())</div><div class="line">mean_ages[<span class="number">1</span>] = np.average(train[train[<span class="string">'Title'</span>] == <span class="string">'Mrs'</span>][<span class="string">'Age'</span>].dropna())</div><div class="line">mean_ages[<span class="number">2</span>] = np.average(train[train[<span class="string">'Title'</span>] == <span class="string">'Mr'</span>][<span class="string">'Age'</span>].dropna())</div><div class="line">mean_ages[<span class="number">3</span>] = np.average(train[train[<span class="string">'Title'</span>] == <span class="string">'Master'</span>][<span class="string">'Age'</span>].dropna())</div><div class="line">train.loc[ (train.Age.isnull()) &amp; (train.Title == <span class="string">'Miss'</span>) ,<span class="string">'AgeFill'</span>] = mean_ages[<span class="number">0</span>]</div><div class="line">train.loc[ (train.Age.isnull()) &amp; (train.Title == <span class="string">'Mrs'</span>) ,<span class="string">'AgeFill'</span>] = mean_ages[<span class="number">1</span>]</div><div class="line">train.loc[ (train.Age.isnull()) &amp; (train.Title == <span class="string">'Mr'</span>) ,<span class="string">'AgeFill'</span>] = mean_ages[<span class="number">2</span>]</div><div class="line">train.loc[ (train.Age.isnull()) &amp; (train.Title == <span class="string">'Master'</span>) ,<span class="string">'AgeFill'</span>] = mean_ages[<span class="number">3</span>]</div><div class="line"></div><div class="line">train[<span class="string">'AgeCat'</span>] = train[<span class="string">'AgeFill'</span>]</div><div class="line">train.loc[ (train.AgeFill&lt;=<span class="number">10</span>), <span class="string">'AgeCat'</span>] = <span class="string">'child'</span></div><div class="line">train.loc[ (train.AgeFill&gt;<span class="number">60</span>), <span class="string">'AgeCat'</span>] = <span class="string">'aged'</span></div><div class="line">train.loc[ (train.AgeFill&gt;<span class="number">10</span>) &amp; (train.AgeFill &lt;=<span class="number">30</span>) ,<span class="string">'AgeCat'</span>] = <span class="string">'adult'</span></div><div class="line">train.loc[ (train.AgeFill&gt;<span class="number">30</span>) &amp; (train.AgeFill &lt;=<span class="number">60</span>) ,<span class="string">'AgeCat'</span>] = <span class="string">'senior'</span></div><div class="line"></div><div class="line">train[<span class="string">'Fare_Per_Person'</span>] = train[<span class="string">'Fare'</span>] / (train[<span class="string">'Family_Size'</span>] + <span class="number">1</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">test[<span class="string">'AgeFill'</span>] = test[<span class="string">'Age'</span>]</div><div class="line">mean_ages = np.zeros(<span class="number">4</span>)</div><div class="line">mean_ages[<span class="number">0</span>] = np.average(test[test[<span class="string">'Title'</span>] == <span class="string">'Miss'</span>][<span class="string">'Age'</span>].dropna())</div><div class="line">mean_ages[<span class="number">1</span>] = np.average(test[test[<span class="string">'Title'</span>] == <span class="string">'Mrs'</span>][<span class="string">'Age'</span>].dropna())</div><div class="line">mean_ages[<span class="number">2</span>] = np.average(test[test[<span class="string">'Title'</span>] == <span class="string">'Mr'</span>][<span class="string">'Age'</span>].dropna())</div><div class="line">mean_ages[<span class="number">3</span>] = np.average(test[test[<span class="string">'Title'</span>] == <span class="string">'Master'</span>][<span class="string">'Age'</span>].dropna())</div><div class="line">test.loc[ (test.Age.isnull()) &amp; (test.Title == <span class="string">'Miss'</span>) ,<span class="string">'AgeFill'</span>] = mean_ages[<span class="number">0</span>]</div><div class="line">test.loc[ (test.Age.isnull()) &amp; (test.Title == <span class="string">'Mrs'</span>) ,<span class="string">'AgeFill'</span>] = mean_ages[<span class="number">1</span>]</div><div class="line">test.loc[ (test.Age.isnull()) &amp; (test.Title == <span class="string">'Mr'</span>) ,<span class="string">'AgeFill'</span>] = mean_ages[<span class="number">2</span>]</div><div class="line">test.loc[ (test.Age.isnull()) &amp; (test.Title == <span class="string">'Master'</span>) ,<span class="string">'AgeFill'</span>] = mean_ages[<span class="number">3</span>]</div><div class="line"></div><div class="line">test[<span class="string">'AgeCat'</span>] = test[<span class="string">'AgeFill'</span>]</div><div class="line">test.loc[ (test.AgeFill&lt;=<span class="number">10</span>), <span class="string">'AgeCat'</span>] = <span class="string">'child'</span></div><div class="line">test.loc[ (test.AgeFill&gt;<span class="number">60</span>), <span class="string">'AgeCat'</span>] = <span class="string">'aged'</span></div><div class="line">test.loc[ (test.AgeFill&gt;<span class="number">10</span>) &amp; (test.AgeFill &lt;=<span class="number">30</span>) ,<span class="string">'AgeCat'</span>] = <span class="string">'adult'</span></div><div class="line">test.loc[ (test.AgeFill&gt;<span class="number">30</span>) &amp; (test.AgeFill &lt;=<span class="number">60</span>) ,<span class="string">'AgeCat'</span>] = <span class="string">'senior'</span></div><div class="line"></div><div class="line">test[<span class="string">'Fare_Per_Person'</span>] = test[<span class="string">'Fare'</span>] / (test[<span class="string">'Family_Size'</span>] + <span class="number">1</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">train.Embarked = train.Embarked.fillna(<span class="string">'S'</span>)</div><div class="line">test.Embarked = test.Embarked.fillna(<span class="string">'S'</span>)</div><div class="line"></div><div class="line">train.loc[ train.Cabin.isnull() == <span class="keyword">True</span>, <span class="string">'Cabin'</span>] = <span class="number">0.2</span></div><div class="line">train.loc[ train.Cabin.isnull() == <span class="keyword">False</span>, <span class="string">'Cabin'</span>] = <span class="number">1</span></div><div class="line"></div><div class="line">test.loc[ test.Cabin.isnull() == <span class="keyword">True</span>, <span class="string">'Cabin'</span>] = <span class="number">0.2</span></div><div class="line">test.loc[ test.Cabin.isnull() == <span class="keyword">False</span>, <span class="string">'Cabin'</span>] = <span class="number">1</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Age times class</span></div><div class="line">train[<span class="string">'AgeClass'</span>] = train[<span class="string">'AgeFill'</span>] * train[<span class="string">'Pclass'</span>]</div><div class="line">train[<span class="string">'ClassFare'</span>] = train[<span class="string">'Pclass'</span>] * train[<span class="string">'Fare_Per_Person'</span>]</div><div class="line"></div><div class="line">train[<span class="string">'HighLow'</span>] = train[<span class="string">'Pclass'</span>]</div><div class="line">train.loc[ (train.Fare_Per_Person &lt; <span class="number">8</span>) ,<span class="string">'HighLow'</span>] = <span class="string">'Low'</span></div><div class="line">train.loc[ (train.Fare_Per_Person &gt;= <span class="number">8</span>) ,<span class="string">'HighLow'</span>] = <span class="string">'High'</span></div><div class="line"></div><div class="line"><span class="comment">#Age times class</span></div><div class="line">test[<span class="string">'AgeClass'</span>] = test[<span class="string">'AgeFill'</span>] * test[<span class="string">'Pclass'</span>]</div><div class="line">test[<span class="string">'ClassFare'</span>] = test[<span class="string">'Pclass'</span>] * test[<span class="string">'Fare_Per_Person'</span>]</div><div class="line"></div><div class="line">test[<span class="string">'HighLow'</span>] = test[<span class="string">'Pclass'</span>]</div><div class="line">test.loc[ (test.Fare_Per_Person &lt; <span class="number">8</span>) ,<span class="string">'HighLow'</span>] = <span class="string">'Low'</span></div><div class="line">test.loc[ (test.Fare_Per_Person &gt;= <span class="number">8</span>) ,<span class="string">'HighLow'</span>] = <span class="string">'High'</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> train.head(<span class="number">1</span>)</div><div class="line"><span class="comment"># print test.head()</span></div></pre></td></tr></table></figure>
<pre><code>   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \
0            1         0       3  Braund, Mr. Owen Harris  male  22.0      1   

   Parch     Ticket  Fare   ...    Embarked Title Family_Size  Family  \
0      0  A/5 21171  7.25   ...           S    Mr           1       0   

   AgeFill  AgeCat Fare_Per_Person  AgeClass  ClassFare  HighLow  
0     22.0   adult           3.625      66.0     10.875      Low  

[1 rows x 21 columns]
</code></pre><h2 id="u7279_u5F81_u5DE5_u7A0B"><a href="#u7279_u5F81_u5DE5_u7A0B" class="headerlink" title="特征工程"></a>特征工程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 处理训练集</span></div><div class="line">Pclass = pd.get_dummies(train.Pclass)</div><div class="line">Sex = pd.get_dummies(train.Sex)</div><div class="line">Embarked = pd.get_dummies(train.Embarked)</div><div class="line">Title = pd.get_dummies(train.Title)</div><div class="line">AgeCat = pd.get_dummies(train.AgeCat)</div><div class="line">HighLow = pd.get_dummies(train.HighLow)</div><div class="line">train_data = pd.concat([Pclass, Sex, Embarked, Title, AgeCat, HighLow], axis=<span class="number">1</span>)</div><div class="line">train_data[<span class="string">'Age'</span>] = train[<span class="string">'Age'</span>]</div><div class="line">train_data[<span class="string">'Fare'</span>] = train[<span class="string">'Fare'</span>]</div><div class="line">train_data[<span class="string">'SibSp'</span>] = train[<span class="string">'SibSp'</span>]</div><div class="line">train_data[<span class="string">'Parch'</span>] = train[<span class="string">'Parch'</span>]</div><div class="line">train_data[<span class="string">'Family_Size'</span>] = train[<span class="string">'Family_Size'</span>]</div><div class="line">train_data[<span class="string">'Family'</span>] = train[<span class="string">'Family'</span>]</div><div class="line">train_data[<span class="string">'AgeFill'</span>] = train[<span class="string">'AgeFill'</span>]</div><div class="line">train_data[<span class="string">'Fare_Per_Person'</span>] = train[<span class="string">'Fare_Per_Person'</span>]</div><div class="line">train_data[<span class="string">'Cabin'</span>] = train[<span class="string">'Cabin'</span>]</div><div class="line">train_data[<span class="string">'AgeClass'</span>] = train[<span class="string">'AgeClass'</span>]</div><div class="line">train_data[<span class="string">'ClassFare'</span>] = train[<span class="string">'ClassFare'</span>]</div><div class="line"></div><div class="line">cols = [<span class="string">'Age'</span>, <span class="string">'Fare'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Family_Size'</span>, <span class="string">'Family'</span>, <span class="string">'AgeFill'</span>, <span class="string">'Fare_Per_Person'</span>, <span class="string">'AgeClass'</span>, <span class="string">'ClassFare'</span>]</div><div class="line">train_data[cols] = train_data[cols].apply(<span class="keyword">lambda</span> x: (x - np.mean(x)) / (np.max(x) - np.min(x)))</div><div class="line"><span class="keyword">print</span> train_data.head()</div><div class="line"></div><div class="line"><span class="comment"># 处理测试集</span></div><div class="line">Pclass = pd.get_dummies(test.Pclass)</div><div class="line">Sex = pd.get_dummies(test.Sex)</div><div class="line">Embarked = pd.get_dummies(test.Embarked)</div><div class="line">Title = pd.get_dummies(test.Title)</div><div class="line">AgeCat = pd.get_dummies(test.AgeCat)</div><div class="line">HighLow = pd.get_dummies(test.HighLow)</div><div class="line">test_data = pd.concat([Pclass, Sex, Embarked, Title, AgeCat, HighLow], axis=<span class="number">1</span>)</div><div class="line">test_data[<span class="string">'Age'</span>] = test[<span class="string">'Age'</span>]</div><div class="line">test_data[<span class="string">'Fare'</span>] = test[<span class="string">'Fare'</span>]</div><div class="line">test_data[<span class="string">'SibSp'</span>] = test[<span class="string">'SibSp'</span>]</div><div class="line">test_data[<span class="string">'Parch'</span>] = test[<span class="string">'Parch'</span>]</div><div class="line">test_data[<span class="string">'Family_Size'</span>] = test[<span class="string">'Family_Size'</span>]</div><div class="line">test_data[<span class="string">'Family'</span>] = test[<span class="string">'Family'</span>]</div><div class="line">test_data[<span class="string">'AgeFill'</span>] = test[<span class="string">'AgeFill'</span>]</div><div class="line">test_data[<span class="string">'Fare_Per_Person'</span>] = test[<span class="string">'Fare_Per_Person'</span>]</div><div class="line">test_data[<span class="string">'Cabin'</span>] = test[<span class="string">'Cabin'</span>]</div><div class="line">test_data[<span class="string">'AgeClass'</span>] = test[<span class="string">'AgeClass'</span>]</div><div class="line">test_data[<span class="string">'ClassFare'</span>] = test[<span class="string">'ClassFare'</span>]</div><div class="line"></div><div class="line">test_data[cols] = test_data[cols].apply(<span class="keyword">lambda</span> x: (x - np.mean(x)) / (np.max(x) - np.min(x)))</div><div class="line"><span class="keyword">print</span> test_data.head()</div></pre></td></tr></table></figure>
<pre><code>     1    2    3  female  male    C    Q    S  Master  Miss    ...      \
0  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0    ...       
1  1.0  0.0  0.0     1.0   0.0  1.0  0.0  0.0     0.0   0.0    ...       
2  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0     0.0   1.0    ...       
3  1.0  0.0  0.0     1.0   0.0  0.0  0.0  1.0     0.0   0.0    ...       
4  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0    ...       

       Fare     SibSp     Parch  Family_Size    Family   AgeFill  \
0 -0.048707  0.059624 -0.063599      0.00954 -0.035494 -0.096747   
1  0.076277  0.059624 -0.063599      0.00954 -0.035494  0.104309   
2 -0.047390 -0.065376 -0.063599     -0.09046 -0.035494 -0.046483   
3  0.040786  0.059624 -0.063599      0.00954 -0.035494  0.066611   
4 -0.047146 -0.065376 -0.063599     -0.09046 -0.035494  0.066611   

   Fare_Per_Person  Cabin  AgeClass  ClassFare  
0        -0.031799      1  0.004673  -0.040180  
1         0.030694      1 -0.121978   0.008161  
2        -0.023406      1  0.058952  -0.015001  
3         0.012948      1 -0.135547  -0.009584  
4        -0.023162      1  0.181080  -0.014269  

[5 rows x 29 columns]
     1    2    3  female  male    C    Q    S  Master  Miss    ...      \
0  0.0  0.0  1.0     0.0   1.0  0.0  1.0  0.0     0.0   0.0    ...       
1  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0     0.0   0.0    ...       
2  0.0  1.0  0.0     0.0   1.0  0.0  1.0  0.0     0.0   0.0    ...       
3  0.0  0.0  1.0     0.0   1.0  0.0  0.0  1.0     0.0   0.0    ...       
4  0.0  0.0  1.0     1.0   0.0  0.0  0.0  1.0     0.0   0.0    ...       

       Fare     SibSp     Parch  Family_Size    Family   AgeFill  \
0 -0.054258 -0.055921 -0.043594    -0.083971 -0.027811  0.055749   
1 -0.055877  0.069079 -0.043594     0.016029 -0.027811  0.220591   
2 -0.050631 -0.055921 -0.043594    -0.083971 -0.027811  0.418402   
3 -0.052632 -0.055921 -0.043594    -0.083971 -0.027811 -0.043157   
4 -0.045556  0.069079  0.067517     0.116029  0.034689 -0.109094   

   Fare_Per_Person  Cabin  AgeClass  ClassFare  
0        -0.053389      1  0.218758  -0.037167  
1        -0.069889      1  0.425952  -0.086667  
2        -0.046307      1  0.332024  -0.052842  
3        -0.050213      1  0.094442  -0.027639  
4        -0.067618      1  0.011564  -0.079855  

[5 rows x 29 columns]
</code></pre><h2 id="u6A21_u578B_u8BAD_u7EC3"><a href="#u6A21_u578B_u8BAD_u7EC3" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression <span class="keyword">as</span> LR</div><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> cross_val_score</div><div class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB <span class="keyword">as</span> GNB</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div></pre></td></tr></table></figure>
<h3 id="u903B_u8F91_u56DE_u5F52"><a href="#u903B_u8F91_u56DE_u5F52" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">model_lr = LR(penalty = <span class="string">'l2'</span>, dual = <span class="keyword">True</span>, random_state = <span class="number">0</span>)</div><div class="line">model_lr.fit(train_data, label)</div><div class="line"><span class="keyword">print</span> <span class="string">"逻辑回归10折交叉验证得分: "</span>, np.mean(cross_val_score(model_lr, train_data, label, cv=<span class="number">10</span>, scoring=<span class="string">'roc_auc'</span>))</div><div class="line"></div><div class="line">result = model_lr.predict( test_data )</div><div class="line">output = pd.DataFrame( data=&#123;<span class="string">"PassengerId"</span>:test[<span class="string">"PassengerId"</span>], <span class="string">"Survived"</span>:result&#125; )</div><div class="line">output.to_csv( <span class="string">"lr.csv"</span>, index=<span class="keyword">False</span>, quoting=<span class="number">3</span> )</div></pre></td></tr></table></figure>
<pre><code>逻辑回归10折交叉验证得分:  0.871878335172
</code></pre><h4 id="u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-78469"><a href="#u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-78469" class="headerlink" title="提交kaggle后准确率：0.78469"></a>提交kaggle后准确率：0.78469</h4><h3 id="u9AD8_u65AF_u8D1D_u53F6_u65AF"><a href="#u9AD8_u65AF_u8D1D_u53F6_u65AF" class="headerlink" title="高斯贝叶斯"></a>高斯贝叶斯</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">model_GNB = GNB()</div><div class="line">model_GNB.fit(train_data, label)</div><div class="line"><span class="keyword">print</span> <span class="string">"高斯贝叶斯分类器10折交叉验证得分: "</span>, np.mean(cross_val_score(model_GNB, train_data, label, cv=<span class="number">10</span>, scoring=<span class="string">'roc_auc'</span>))</div><div class="line"></div><div class="line">result = model_GNB.predict( test_data )</div><div class="line">output = pd.DataFrame( data=&#123;<span class="string">"PassengerId"</span>:test[<span class="string">"PassengerId"</span>], <span class="string">"Survived"</span>:result&#125; )</div><div class="line">output.to_csv( <span class="string">"gnb.csv"</span>, index=<span class="keyword">False</span>, quoting=<span class="number">3</span> )</div></pre></td></tr></table></figure>
<pre><code>高斯贝叶斯分类器10折交叉验证得分:  0.857323798206
</code></pre><h4 id="u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-74163"><a href="#u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-74163" class="headerlink" title="提交kaggle后准确率：0.74163"></a>提交kaggle后准确率：0.74163</h4><h3 id="u968F_u673A_u68EE_u6797"><a href="#u968F_u673A_u68EE_u6797" class="headerlink" title="随机森林"></a>随机森林</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">forest = RandomForestClassifier( n_estimators=<span class="number">500</span>, criterion=<span class="string">'entropy'</span>, max_depth=<span class="number">5</span>, min_samples_split=<span class="number">1</span>,</div><div class="line">  min_samples_leaf=<span class="number">1</span>, max_features=<span class="string">'auto'</span>, bootstrap=<span class="keyword">False</span>, oob_score=<span class="keyword">False</span>, n_jobs=<span class="number">4</span>,</div><div class="line">  verbose=<span class="number">0</span>)</div><div class="line"></div><div class="line">%time forest = forest.fit( train_data, label )</div><div class="line"><span class="keyword">print</span> <span class="string">"随机森林分类器10折交叉验证得分: "</span>, np.mean(cross_val_score(forest, train_data, label, cv=<span class="number">10</span>, scoring=<span class="string">'roc_auc'</span>))</div><div class="line"></div><div class="line">result = forest.predict( test_data )</div><div class="line">output = pd.DataFrame( data=&#123;<span class="string">"PassengerId"</span>:test[<span class="string">"PassengerId"</span>], <span class="string">"Survived"</span>:result&#125; )</div><div class="line">output.to_csv( <span class="string">"rf.csv"</span>, index=<span class="keyword">False</span>, quoting=<span class="number">3</span> )</div></pre></td></tr></table></figure>
<pre><code>CPU times: user 1.34 s, sys: 208 ms, total: 1.55 s
Wall time: 1.17 s
随机森林分类器10折交叉验证得分:  0.870820473644
</code></pre><h4 id="u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-76555"><a href="#u63D0_u4EA4kaggle_u540E_u51C6_u786E_u7387_uFF1A0-76555" class="headerlink" title="提交kaggle后准确率：0.76555"></a>提交kaggle后准确率：0.76555</h4><hr>
<h2 id="u5BFB_u627E_u6700_u4F73_u53C2_u6570"><a href="#u5BFB_u627E_u6700_u4F73_u53C2_u6570" class="headerlink" title="寻找最佳参数"></a>寻找最佳参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</div><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split,StratifiedShuffleSplit,StratifiedKFold</div><div class="line">param_grid = dict( )</div><div class="line"></div><div class="line">pipeline=Pipeline([ (<span class="string">'clf'</span>, forest) ])</div><div class="line">grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=<span class="number">3</span>, scoring=<span class="string">'accuracy'</span>,</div><div class="line">cv=StratifiedShuffleSplit(label, n_iter=<span class="number">10</span>, test_size=<span class="number">0.2</span>, train_size=<span class="keyword">None</span>)).fit(train_data, label)</div><div class="line"></div><div class="line">print(<span class="string">"Best score: %0.3f"</span> % grid_search.best_score_)</div></pre></td></tr></table></figure>
<pre><code>Fitting 10 folds for each of 1 candidates, totalling 10 fits
[CV]  ................................................................
[CV] ....................................... , score=0.849162 -   1.7s
[CV]  ................................................................
[CV] ....................................... , score=0.843575 -   1.5s
[CV]  ................................................................
[CV] ....................................... , score=0.804469 -   1.4s
[CV]  ................................................................
[CV] ....................................... , score=0.804469 -   1.9s
[CV]  ................................................................
[CV] ....................................... , score=0.871508 -   2.1s
[CV]  ................................................................
[CV] ....................................... , score=0.865922 -   1.9s
[CV]  ................................................................
[CV] ....................................... , score=0.854749 -   1.8s
[CV]  ................................................................
[CV] ....................................... , score=0.860335 -   1.7s
[CV]  ................................................................
[CV] ....................................... , score=0.843575 -   1.6s
[CV]  ................................................................
[CV] ....................................... , score=0.826816 -   1.5s


[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   17.1s finished


Best score: 0.842
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/19/algo/kaggle/titanic/" data-id="cj3uvlzqu004lbms9sc3fndlf" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/08/19/algo/kaggle/titanic/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/kaggle/sequence" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/19/algo/kaggle/sequence/">kaggle之数字序列预测</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/19/algo/kaggle/sequence/">
      <time datetime="2016-08-19T05:48:13.000Z" itemprop="datePublished">2016-08-19</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="u6570_u5B57_u5E8F_u5217_u9884_u6D4B"><a href="#u6570_u5B57_u5E8F_u5217_u9884_u6D4B" class="headerlink" title="数字序列预测"></a>数字序列预测</h2><p><a href="https://github.com/lijingpeng/kaggle/tree/master/competitions/Sequence" target="_blank" rel="external">Github地址</a><br><a href="https://www.kaggle.com/c/integer-sequence-learning" target="_blank" rel="external">Kaggle地址</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> string</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">'train.csv'</span>)</div><div class="line">test = pd.read_csv(<span class="string">'test.csv'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">last = test.Sequence.apply(<span class="keyword">lambda</span> x: pd.Series(x.split(<span class="string">','</span>))).mode(axis=<span class="number">1</span>).fillna(<span class="number">0</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">submission = pd.DataFrame(&#123;<span class="string">'Id'</span>: test[<span class="string">'Id'</span>], <span class="string">'Last'</span>: last[<span class="number">0</span>]&#125;)</div><div class="line">submission.to_csv(<span class="string">'mode.csv'</span>, index=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<p>提交Kaggle之后是0.05680</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/19/algo/kaggle/sequence/" data-id="cj3uvlzqp004cbms9u3w832zd" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/08/19/algo/kaggle/sequence/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/kaggle/movie_reviews" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/16/algo/kaggle/movie_reviews/">kaggle之电影文本情感分类</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/16/algo/kaggle/movie_reviews/">
      <time datetime="2016-08-16T05:48:13.000Z" itemprop="datePublished">2016-08-16</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <h2 id="u7535_u5F71_u6587_u672C_u60C5_u611F_u5206_u7C7B"><a href="#u7535_u5F71_u6587_u672C_u60C5_u611F_u5206_u7C7B" class="headerlink" title="电影文本情感分类"></a>电影文本情感分类</h2><p><a href="https://github.com/lijingpeng/kaggle/tree/master/competitions/Bag_of_Words" target="_blank" rel="external">Github地址</a><br><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/" target="_blank" rel="external">Kaggle地址</a></p>
<p>这个任务主要是对电影评论文本进行情感分类，主要分为正面评论和负面评论，所以是一个二分类问题，二分类模型我们可以选取一些常见的模型比如贝叶斯、逻辑回归等，这里挑战之一是文本内容的向量化，因此，我们首先尝试基于TF-IDF的向量化方法，然后尝试word2vec。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">review_to_wordlist</span><span class="params">(review)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">    把IMDB的评论转成词序列</div><div class="line">    参考：http://blog.csdn.net/longxinchen_ml/article/details/50629613</div><div class="line">    '''</div><div class="line">    <span class="comment"># 去掉HTML标签，拿到内容</span></div><div class="line">    review_text = BeautifulSoup(review, <span class="string">"html.parser"</span>).get_text()</div><div class="line">    <span class="comment"># 用正则表达式取出符合规范的部分</span></div><div class="line">    review_text = re.sub(<span class="string">"[^a-zA-Z]"</span>,<span class="string">" "</span>, review_text)</div><div class="line">    <span class="comment"># 小写化所有的词，并转成词list</span></div><div class="line">    words = review_text.lower().split()</div><div class="line">    <span class="comment"># 返回words</span></div><div class="line">    <span class="keyword">return</span> words</div></pre></td></tr></table></figure>
<h2 id="u8F7D_u5165_u6570_u636E_u96C6"><a href="#u8F7D_u5165_u6570_u636E_u96C6" class="headerlink" title="载入数据集"></a>载入数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 载入数据集</span></div><div class="line">train = pd.read_csv(<span class="string">'/Users/frank/Documents/workspace/kaggle/dataset/Bag_of_Words_Meets_Bags_of_Popcorn/labeledTrainData.tsv'</span>, header=<span class="number">0</span>, delimiter=<span class="string">"\t"</span>, quoting=<span class="number">3</span>)</div><div class="line">test = pd.read_csv(<span class="string">'/Users/frank/Documents/workspace/kaggle/dataset/Bag_of_Words_Meets_Bags_of_Popcorn/testData.tsv'</span>, header=<span class="number">0</span>, delimiter=<span class="string">"\t"</span>, quoting=<span class="number">3</span>)</div><div class="line"><span class="keyword">print</span> train.head()</div><div class="line"><span class="keyword">print</span> test.head()</div></pre></td></tr></table></figure>
<pre><code>         id  sentiment                                             review
0  &quot;5814_8&quot;          1  &quot;With all this stuff going down at the moment ...
1  &quot;2381_9&quot;          1  &quot;\&quot;The Classic War of the Worlds\&quot; by Timothy ...
2  &quot;7759_3&quot;          0  &quot;The film starts with a manager (Nicholas Bell...
3  &quot;3630_4&quot;          0  &quot;It must be assumed that those who praised thi...
4  &quot;9495_8&quot;          1  &quot;Superbly trashy and wondrously unpretentious ...
           id                                             review
0  &quot;12311_10&quot;  &quot;Naturally in a film who&apos;s main themes are of ...
1    &quot;8348_2&quot;  &quot;This movie is a disaster within a disaster fi...
2    &quot;5828_4&quot;  &quot;All in all, this is a movie for kids. We saw ...
3    &quot;7186_2&quot;  &quot;Afraid of the Dark left me with the impressio...
4   &quot;12128_7&quot;  &quot;A very accurate depiction of small time mob l...
</code></pre><h2 id="u9884_u5904_u7406_u6570_u636E"><a href="#u9884_u5904_u7406_u6570_u636E" class="headerlink" title="预处理数据"></a>预处理数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 预处理数据</span></div><div class="line">label = train[<span class="string">'sentiment'</span>]</div><div class="line">train_data = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(train[<span class="string">'review'</span>])):</div><div class="line">    train_data.append(<span class="string">' '</span>.join(review_to_wordlist(train[<span class="string">'review'</span>][i])))</div><div class="line">test_data = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(test[<span class="string">'review'</span>])):</div><div class="line">    test_data.append(<span class="string">' '</span>.join(review_to_wordlist(test[<span class="string">'review'</span>][i])))</div><div class="line"></div><div class="line"><span class="comment"># 预览数据</span></div><div class="line"><span class="keyword">print</span> train_data[<span class="number">0</span>], <span class="string">'\n'</span></div><div class="line"><span class="keyword">print</span> test_data[<span class="number">0</span>]</div></pre></td></tr></table></figure>
<pre><code>with all this stuff going down at the moment with mj i ve started listening to his music watching the odd documentary here and there watched the wiz and watched moonwalker again maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent moonwalker is part biography part feature film which i remember going to see at the cinema when it was originally released some of it has subtle messages about mj s feeling towards the press and also the obvious message of drugs are bad m kay visually impressive but of course this is all about michael jackson so unless you remotely like mj in anyway then you are going to hate this and find it boring some may call mj an egotist for consenting to the making of this movie but mj and most of his fans would say that he made it for the fans which if true is really nice of him the actual feature film bit when it finally starts is only on for minutes or so excluding the smooth criminal sequence and joe pesci is convincing as a psychopathic all powerful drug lord why he wants mj dead so bad is beyond me because mj overheard his plans nah joe pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno maybe he just hates mj s music lots of cool things in this like mj turning into a car and a robot and the whole speed demon sequence also the director must have had the patience of a saint when it came to filming the kiddy bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene bottom line this movie is for people who like mj on one level or another which i think is most people if not then stay away it does try and give off a wholesome message and ironically mj s bestest buddy in this movie is a girl michael jackson is truly one of the most talented people ever to grace this planet but is he guilty well with all the attention i ve gave this subject hmmm well i don t know because people can be different behind closed doors i know this for a fact he is either an extremely nice but stupid guy or one of the most sickest liars i hope he is not the latter

naturally in a film who s main themes are of mortality nostalgia and loss of innocence it is perhaps not surprising that it is rated more highly by older viewers than younger ones however there is a craftsmanship and completeness to the film which anyone can enjoy the pace is steady and constant the characters full and engaging the relationships and interactions natural showing that you do not need floods of tears to show emotion screams to show fear shouting to show dispute or violence to show anger naturally joyce s short story lends the film a ready made structure as perfect as a polished diamond but the small changes huston makes such as the inclusion of the poem fit in neatly it is truly a masterpiece of tact subtlety and overwhelming beauty
</code></pre><h2 id="u7279_u5F81_u5904_u7406"><a href="#u7279_u5F81_u5904_u7406" class="headerlink" title="特征处理"></a>特征处理</h2><p>直接丢给计算机这些词文本，计算机是无法计算的，因此我们需要把文本转换为向量，有几种常见的文本向量处理方法，比如：</p>
<ol>
<li>单词计数  </li>
<li>TF-IDF向量  </li>
<li>Word2vec向量<br>我们先使用TF-IDF来试一下。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer <span class="keyword">as</span> TFIDF</div><div class="line"><span class="comment"># 参考：http://blog.csdn.net/longxinchen_ml/article/details/50629613</span></div><div class="line">tfidf = TFIDF(min_df=<span class="number">2</span>, <span class="comment"># 最小支持度为2</span></div><div class="line">           max_features=<span class="keyword">None</span>,</div><div class="line">           strip_accents=<span class="string">'unicode'</span>,</div><div class="line">           analyzer=<span class="string">'word'</span>,</div><div class="line">           token_pattern=<span class="string">r'\w&#123;1,&#125;'</span>,</div><div class="line">           ngram_range=(<span class="number">1</span>, <span class="number">3</span>),  <span class="comment"># 二元文法模型</span></div><div class="line">           use_idf=<span class="number">1</span>,</div><div class="line">           smooth_idf=<span class="number">1</span>,</div><div class="line">           sublinear_tf=<span class="number">1</span>,</div><div class="line">           stop_words = <span class="string">'english'</span>) <span class="comment"># 去掉英文停用词</span></div><div class="line"></div><div class="line"><span class="comment"># 合并训练和测试集以便进行TFIDF向量化操作</span></div><div class="line">data_all = train_data + test_data</div><div class="line">len_train = len(train_data)</div><div class="line"></div><div class="line">tfidf.fit(data_all)</div><div class="line">data_all = tfidf.transform(data_all)</div><div class="line"><span class="comment"># 恢复成训练集和测试集部分</span></div><div class="line">train_x = data_all[:len_train]</div><div class="line">test_x = data_all[len_train:]</div><div class="line"><span class="keyword">print</span> <span class="string">'TF-IDF处理结束.'</span></div></pre></td></tr></table></figure>
<pre><code>TF-IDF处理结束.
</code></pre><h2 id="u6734_u7D20_u8D1D_u53F6_u65AF_u8BAD_u7EC3"><a href="#u6734_u7D20_u8D1D_u53F6_u65AF_u8BAD_u7EC3" class="headerlink" title="朴素贝叶斯训练"></a>朴素贝叶斯训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB <span class="keyword">as</span> MNB</div><div class="line"></div><div class="line">model_NB = MNB()</div><div class="line">model_NB.fit(train_x, label)</div><div class="line">MNB(alpha=<span class="number">1.0</span>, class_prior=<span class="keyword">None</span>, fit_prior=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> cross_val_score</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"多项式贝叶斯分类器10折交叉验证得分: "</span>, np.mean(cross_val_score(model_NB, train_x, label, cv=<span class="number">10</span>, scoring=<span class="string">'roc_auc'</span>))</div></pre></td></tr></table></figure>
<pre><code>多项式贝叶斯分类器10折交叉验证得分:  0.94983968
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">test_predicted = np.array(model_NB.predict(test_x))</div><div class="line"><span class="keyword">print</span> <span class="string">'保存结果...'</span></div><div class="line">nb_output = pd.DataFrame(data=test_predicted, columns=[<span class="string">'sentiment'</span>])</div><div class="line">nb_output[<span class="string">'id'</span>] = test[<span class="string">'id'</span>]</div><div class="line">nb_output = nb_output[[<span class="string">'id'</span>, <span class="string">'sentiment'</span>]]</div><div class="line">nb_output.to_csv(<span class="string">'nb_output.csv'</span>, index=<span class="keyword">False</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">'结束.'</span></div></pre></td></tr></table></figure>
<pre><code>保存结果...
结束.
</code></pre><ol>
<li>提交最终的结果到kaggle，AUC为：0.85728，排名300左右，50%的水平  </li>
<li>ngram_range = 3, 三元文法，AUC为0.85924</li>
</ol>
<h2 id="u903B_u8F91_u56DE_u5F52"><a href="#u903B_u8F91_u56DE_u5F52" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression <span class="keyword">as</span> LR</div><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line"></div><div class="line"><span class="comment"># 设定grid search的参数</span></div><div class="line">grid_values = &#123;<span class="string">'C'</span>:[<span class="number">30</span>]&#125;  </div><div class="line"><span class="comment"># 设定打分为roc_auc</span></div><div class="line">model_LR = GridSearchCV(LR(penalty = <span class="string">'L2'</span>, dual = <span class="keyword">True</span>, random_state = <span class="number">0</span>), grid_values, scoring = <span class="string">'roc_auc'</span>, cv = <span class="number">20</span>)</div><div class="line">model_LR.fit(train_x, label)</div><div class="line"><span class="comment"># 20折交叉验证</span></div><div class="line">GridSearchCV(cv=<span class="number">20</span>, estimator=LR(C=<span class="number">1.0</span>, class_weight=<span class="keyword">None</span>, dual=<span class="keyword">True</span>,</div><div class="line">             fit_intercept=<span class="keyword">True</span>, intercept_scaling=<span class="number">1</span>, penalty=<span class="string">'L2'</span>, random_state=<span class="number">0</span>, tol=<span class="number">0.0001</span>),</div><div class="line">        fit_params=&#123;&#125;, iid=<span class="keyword">True</span>, n_jobs=<span class="number">1</span>,</div><div class="line">        param_grid=&#123;<span class="string">'C'</span>: [<span class="number">30</span>]&#125;, pre_dispatch=<span class="string">'2*n_jobs'</span>, refit=<span class="keyword">True</span>,</div><div class="line">        scoring=<span class="string">'roc_auc'</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment">#输出结果</span></div><div class="line"><span class="keyword">print</span> model_LR.grid_scores_</div></pre></td></tr></table></figure>
<pre><code>[mean: 0.96497, std: 0.00476, params: {&apos;C&apos;: 30}]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">test_predicted = np.array(model_LR.predict(test_x))</div><div class="line"><span class="keyword">print</span> <span class="string">'保存结果...'</span></div><div class="line">lr_output = pd.DataFrame(data=test_predicted, columns=[<span class="string">'sentiment'</span>])</div><div class="line">lr_output[<span class="string">'id'</span>] = test[<span class="string">'id'</span>]</div><div class="line">lr_output = lr_output[[<span class="string">'id'</span>, <span class="string">'sentiment'</span>]]</div><div class="line">lr_output.to_csv(<span class="string">'lr_output.csv'</span>, index=<span class="keyword">False</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">'结束.'</span></div></pre></td></tr></table></figure>
<pre><code>保存结果...
结束.
</code></pre><ol>
<li>提交最终的结果到kaggle，AUC为：0.88956，排名260左右，比之前贝叶斯模型有所提高   </li>
<li>三元文法，AUC为0.89076</li>
</ol>
<h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>神经网络语言模型L = SUM[log(p(w|contect(w))]，即在w的上下文下计算当前词w的概率，由公式可以看到，我们的核心是计算p(w|contect(w)， Word2vec给出了构造这个概率的一个方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> gensim</div><div class="line"><span class="keyword">import</span> nltk</div><div class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</div><div class="line"></div><div class="line">tokenizer = nltk.data.load(<span class="string">'tokenizers/punkt/english.pickle'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">review_to_wordlist</span><span class="params">( review, remove_stopwords=False )</span>:</span></div><div class="line">    review_text = BeautifulSoup(review, <span class="string">"html.parser"</span>).get_text()</div><div class="line">    review_text = re.sub(<span class="string">"[^a-zA-Z]"</span>,<span class="string">" "</span>, review_text)</div><div class="line"></div><div class="line">    words = review_text.lower().split()</div><div class="line"></div><div class="line">    <span class="keyword">if</span> remove_stopwords:</div><div class="line">        stops = set(stopwords.words(<span class="string">"english"</span>))</div><div class="line">        words = [w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> <span class="keyword">not</span> w <span class="keyword">in</span> stops]</div><div class="line"></div><div class="line">    <span class="keyword">return</span>(words)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">review_to_sentences</span><span class="params">( review, tokenizer, remove_stopwords=False )</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">    将评论段落转换为句子，返回句子列表，每个句子由一堆词组成</div><div class="line">    '''</div><div class="line">    raw_sentences = tokenizer.tokenize(review.strip().decode(<span class="string">'utf8'</span>))</div><div class="line"></div><div class="line">    sentences = []</div><div class="line">    <span class="keyword">for</span> raw_sentence <span class="keyword">in</span> raw_sentences:</div><div class="line">        <span class="keyword">if</span> len(raw_sentence) &gt; <span class="number">0</span>:</div><div class="line">            <span class="comment"># 获取句子中的词列表</span></div><div class="line">            sentences.append( review_to_wordlist( raw_sentence, remove_stopwords ))</div><div class="line">    <span class="keyword">return</span> sentences</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sentences = []</div><div class="line"><span class="keyword">for</span> i, review <span class="keyword">in</span> enumerate(train[<span class="string">"review"</span>]):</div><div class="line">    sentences += review_to_sentences(review, tokenizer)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">unlabeled_train = pd.read_csv(<span class="string">"/Users/frank/Documents/workspace/kaggle/dataset/Bag_of_Words_Meets_Bags_of_Popcorn/unlabeledTrainData.tsv"</span>, header=<span class="number">0</span>, delimiter=<span class="string">"\t"</span>, quoting=<span class="number">3</span> )</div><div class="line"><span class="keyword">for</span> review <span class="keyword">in</span> unlabeled_train[<span class="string">"review"</span>]:</div><div class="line">    sentences += review_to_sentences(review, tokenizer)</div><div class="line"><span class="keyword">print</span> <span class="string">'预处理unlabeled_train data...'</span></div><div class="line"><span class="keyword">print</span> len(train_data)</div><div class="line"><span class="keyword">print</span> len(sentences)</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">预处理unlabeled_train data...</div><div class="line">25000</div><div class="line">795538</div></pre></td></tr></table></figure>
<h3 id="u6784_u5EFAword2vec_u6A21_u578B"><a href="#u6784_u5EFAword2vec_u6A21_u578B" class="headerlink" title="构建word2vec模型"></a>构建word2vec模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</div><div class="line"><span class="comment"># 模型参数</span></div><div class="line">num_features = <span class="number">300</span>    <span class="comment"># Word vector dimensionality                      </span></div><div class="line">min_word_count = <span class="number">40</span>   <span class="comment"># Minimum word count                        </span></div><div class="line">num_workers = <span class="number">4</span>       <span class="comment"># Number of threads to run in parallel</span></div><div class="line">context = <span class="number">10</span>          <span class="comment"># Context window size                                                                                    </span></div><div class="line">downsampling = <span class="number">1e-3</span>   <span class="comment"># Downsample setting for frequent words</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">%%time</div><div class="line"><span class="comment"># 训练模型</span></div><div class="line">print(<span class="string">"训练模型中..."</span>)</div><div class="line">model = Word2Vec(sentences, workers=num_workers, \</div><div class="line">            size=num_features, min_count = min_word_count, \</div><div class="line">            window = context, sample = downsampling)</div></pre></td></tr></table></figure>
<pre><code>训练模型中...
CPU times: user 6min 16s, sys: 8.34 s, total: 6min 24s
Wall time: 2min 27s
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'保存模型...'</span></div><div class="line">model.init_sims(replace=<span class="keyword">True</span>)</div><div class="line">model_name = <span class="string">"300features_40minwords_10context"</span></div><div class="line">model.save(model_name)</div></pre></td></tr></table></figure>
<pre><code>保存模型...
</code></pre><h3 id="u9884_u89C8_u6A21_u578B"><a href="#u9884_u89C8_u6A21_u578B" class="headerlink" title="预览模型"></a>预览模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.doesnt_match(<span class="string">"man woman child kitchen"</span>.split())</div></pre></td></tr></table></figure>
<pre><code>&apos;kitchen&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.doesnt_match(<span class="string">"france england germany berlin"</span>.split())</div></pre></td></tr></table></figure>
<pre><code>&apos;berlin&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.doesnt_match(<span class="string">"paris berlin london austria"</span>.split())</div></pre></td></tr></table></figure>
<pre><code>&apos;london&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.most_similar(<span class="string">"man"</span>)</div></pre></td></tr></table></figure>
<pre><code>[(u&apos;woman&apos;, 0.6246455907821655),
 (u&apos;lady&apos;, 0.6008599400520325),
 (u&apos;lad&apos;, 0.5698915719985962),
 (u&apos;businessman&apos;, 0.5431989431381226),
 (u&apos;chap&apos;, 0.53116375207901),
 (u&apos;monk&apos;, 0.5250570774078369),
 (u&apos;men&apos;, 0.5177899599075317),
 (u&apos;guy&apos;, 0.517480731010437),
 (u&apos;farmer&apos;, 0.5114585757255554),
 (u&apos;person&apos;, 0.5109285116195679)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.most_similar(<span class="string">"queen"</span>)</div></pre></td></tr></table></figure>
<pre><code>[(u&apos;princess&apos;, 0.6759523153305054),
 (u&apos;bride&apos;, 0.6207793951034546),
 (u&apos;belle&apos;, 0.6001157760620117),
 (u&apos;shearer&apos;, 0.5995810031890869),
 (u&apos;stepmother&apos;, 0.596365749835968),
 (u&apos;victoria&apos;, 0.5917614698410034),
 (u&apos;dame&apos;, 0.589063286781311),
 (u&apos;latifah&apos;, 0.5790275931358337),
 (u&apos;countess&apos;, 0.5776904821395874),
 (u&apos;widow&apos;, 0.5727116465568542)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.most_similar(<span class="string">"awful"</span>)</div></pre></td></tr></table></figure>
<pre><code>[(u&apos;terrible&apos;, 0.7642339468002319),
 (u&apos;atrocious&apos;, 0.7405279874801636),
 (u&apos;horrible&apos;, 0.7376815676689148),
 (u&apos;abysmal&apos;, 0.7010303139686584),
 (u&apos;dreadful&apos;, 0.6942194104194641),
 (u&apos;appalling&apos;, 0.6887971758842468),
 (u&apos;lousy&apos;, 0.6646767854690552),
 (u&apos;horrid&apos;, 0.6554058194160461),
 (u&apos;horrendous&apos;, 0.6533403992652893),
 (u&apos;amateurish&apos;, 0.6079087853431702)]
</code></pre><h3 id="u4F7F_u7528Word2vec_u7279_u5F81"><a href="#u4F7F_u7528Word2vec_u7279_u5F81" class="headerlink" title="使用Word2vec特征"></a>使用Word2vec特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeFeatureVec</span><span class="params">(words, model, num_features)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">    对段落中的所有词向量进行取平均操作</div><div class="line">    '''</div><div class="line">    featureVec = np.zeros((num_features,), dtype=<span class="string">"float32"</span>)</div><div class="line">    nwords = <span class="number">0.</span></div><div class="line"></div><div class="line">    <span class="comment"># Index2word包含了词表中的所有词，为了检索速度，保存到set中</span></div><div class="line">    index2word_set = set(model.index2word)</div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</div><div class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> index2word_set:</div><div class="line">            nwords = nwords + <span class="number">1.</span></div><div class="line">            featureVec = np.add(featureVec, model[word])</div><div class="line"></div><div class="line">    <span class="comment"># 取平均</span></div><div class="line">    featureVec = np.divide(featureVec, nwords)</div><div class="line">    <span class="keyword">return</span> featureVec</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAvgFeatureVecs</span><span class="params">(reviews, model, num_features)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">    给定一个文本列表，每个文本由一个词列表组成，返回每个文本的词向量平均值</div><div class="line">    '''</div><div class="line">    counter = <span class="number">0.</span></div><div class="line"></div><div class="line">    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype=<span class="string">"float32"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> review <span class="keyword">in</span> reviews:</div><div class="line">       <span class="keyword">if</span> counter % <span class="number">5000.</span> == <span class="number">0.</span>:</div><div class="line">           print(<span class="string">"Review %d of %d"</span> % (counter, len(reviews)))</div><div class="line"></div><div class="line">       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \</div><div class="line">           num_features)</div><div class="line"></div><div class="line">       counter = counter + <span class="number">1.</span></div><div class="line">    <span class="keyword">return</span> reviewFeatureVecs</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">%time trainDataVecs = getAvgFeatureVecs( train_data, model, num_features )</div></pre></td></tr></table></figure>
<pre><code>Review 0 of 25000
Review 5000 of 25000
Review 10000 of 25000
Review 15000 of 25000
Review 20000 of 25000
CPU times: user 1min 49s, sys: 1.9 s, total: 1min 51s
Wall time: 1min 54s
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">%time testDataVecs = getAvgFeatureVecs(test_data, model, num_features)</div></pre></td></tr></table></figure>
<pre><code>Review 0 of 25000
Review 5000 of 25000
Review 10000 of 25000
Review 15000 of 25000
Review 20000 of 25000
CPU times: user 1min 44s, sys: 1.56 s, total: 1min 46s
Wall time: 1min 48s
</code></pre><h3 id="u9AD8_u65AF_u8D1D_u53F6_u65AF+Word2vec_u8BAD_u7EC3"><a href="#u9AD8_u65AF_u8D1D_u53F6_u65AF+Word2vec_u8BAD_u7EC3" class="headerlink" title="高斯贝叶斯+Word2vec训练"></a>高斯贝叶斯+Word2vec训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB <span class="keyword">as</span> GNB</div><div class="line"></div><div class="line">model_GNB = GNB()</div><div class="line">model_GNB.fit(trainDataVecs, label)</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> cross_val_score</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"高斯贝叶斯分类器10折交叉验证得分: "</span>, np.mean(cross_val_score(model_GNB, trainDataVecs, label, cv=<span class="number">10</span>, scoring=<span class="string">'roc_auc'</span>))</div><div class="line"></div><div class="line">result = forest.predict( testDataVecs )</div><div class="line"></div><div class="line">output = pd.DataFrame( data=&#123;<span class="string">"id"</span>:test[<span class="string">"id"</span>], <span class="string">"sentiment"</span>:result&#125; )</div><div class="line">output.to_csv( <span class="string">"gnb_word2vec.csv"</span>, index=<span class="keyword">False</span>, quoting=<span class="number">3</span> )</div></pre></td></tr></table></figure>
<pre><code>多项式贝叶斯分类器10折交叉验证得分:  0.625579296
</code></pre><p>从验证结果来看，没有超过基于TF-IDF多项式贝叶斯模型</p>
<h3 id="u968F_u673A_u68EE_u6797+Word2vec_u8BAD_u7EC3"><a href="#u968F_u673A_u68EE_u6797+Word2vec_u8BAD_u7EC3" class="headerlink" title="随机森林+Word2vec训练"></a>随机森林+Word2vec训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"></div><div class="line">forest = RandomForestClassifier( n_estimators = <span class="number">100</span>, n_jobs=<span class="number">2</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Fitting a random forest to labeled training data..."</span>)</div><div class="line">%time forest = forest.fit( trainDataVecs, label )</div><div class="line"><span class="keyword">print</span> <span class="string">"随机森林分类器10折交叉验证得分: "</span>, np.mean(cross_val_score(forest, trainDataVecs, label, cv=<span class="number">10</span>, scoring=<span class="string">'roc_auc'</span>))</div><div class="line"></div><div class="line"><span class="comment"># 测试集</span></div><div class="line">result = forest.predict( testDataVecs )</div><div class="line"></div><div class="line">output = pd.DataFrame( data=&#123;<span class="string">"id"</span>:test[<span class="string">"id"</span>], <span class="string">"sentiment"</span>:result&#125; )</div><div class="line">output.to_csv( <span class="string">"rf_word2vec.csv"</span>, index=<span class="keyword">False</span>, quoting=<span class="number">3</span> )</div></pre></td></tr></table></figure>
<pre><code>Fitting a random forest to labeled training data...
CPU times: user 45 s, sys: 460 ms, total: 45.5 s
Wall time: 24.2 s
随机森林分类器10折交叉验证得分:  0.648426368
</code></pre><p>改用随机森林之后，效果有提升，但是依然没有超过基于TF-IDF多项式贝叶斯模型</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/16/algo/kaggle/movie_reviews/" data-id="cj3uvlzqt004ibms9dgc2sn04" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/08/16/algo/kaggle/movie_reviews/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/kaggle/digit" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/15/algo/kaggle/digit/">kaggle之手写体识别</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/15/algo/kaggle/digit/">
      <time datetime="2016-08-15T05:48:13.000Z" itemprop="datePublished">2016-08-15</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p><a href="https://www.kaggle.com/c/digit-recognizer/" target="_blank" rel="external">kaggle地址</a>  </p>
<h2 id="u6570_u636E_u9884_u89C8"><a href="#u6570_u636E_u9884_u89C8" class="headerlink" title="数据预览"></a>数据预览</h2><p>首先载入数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">train = pd.read_csv(<span class="string">'/Users/frank/Documents/workspace/kaggle/dataset/digit_recognizer/train.csv'</span>)</div><div class="line">test = pd.read_csv(<span class="string">'/Users/frank/Documents/workspace/kaggle/dataset/digit_recognizer/test.csv'</span>)</div><div class="line"><span class="keyword">print</span> train.head()</div><div class="line"><span class="keyword">print</span> test.head()</div></pre></td></tr></table></figure>
<pre><code>   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \
0      1       0       0       0       0       0       0       0       0   
1      0       0       0       0       0       0       0       0       0   
2      1       0       0       0       0       0       0       0       0   
3      4       0       0       0       0       0       0       0       0   
4      0       0       0       0       0       0       0       0       0   

   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \
0       0    ...            0         0         0         0         0   
1       0    ...            0         0         0         0         0   
2       0    ...            0         0         0         0         0   
3       0    ...            0         0         0         0         0   
4       0    ...            0         0         0         0         0   

   pixel779  pixel780  pixel781  pixel782  pixel783  
0         0         0         0         0         0  
1         0         0         0         0         0  
2         0         0         0         0         0  
3         0         0         0         0         0  
4         0         0         0         0         0  

[5 rows x 785 columns]
   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \
0       0       0       0       0       0       0       0       0       0   
1       0       0       0       0       0       0       0       0       0   
2       0       0       0       0       0       0       0       0       0   
3       0       0       0       0       0       0       0       0       0   
4       0       0       0       0       0       0       0       0       0   

   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \
0       0    ...            0         0         0         0         0   
1       0    ...            0         0         0         0         0   
2       0    ...            0         0         0         0         0   
3       0    ...            0         0         0         0         0   
4       0    ...            0         0         0         0         0   

   pixel779  pixel780  pixel781  pixel782  pixel783  
0         0         0         0         0         0  
1         0         0         0         0         0  
2         0         0         0         0         0  
3         0         0         0         0         0  
4         0         0         0         0         0  

[5 rows x 784 columns]
</code></pre><p>分离训练数据和标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">train_data = train.values[:,<span class="number">1</span>:]</div><div class="line">label = train.ix[:,<span class="number">0</span>]</div><div class="line">test_data = test.values</div></pre></td></tr></table></figure>
<p>使用PCA来降维：<a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" target="_blank" rel="external">PCA文档</a><br>使用SVM来训练：<a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" target="_blank" rel="external">SVM文档</a></p>
<h2 id="u964D_u7EF4"><a href="#u964D_u7EF4" class="headerlink" title="降维"></a>降维</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</div><div class="line">pca = PCA(n_components=<span class="number">0.8</span>, whiten=<span class="keyword">True</span>)</div><div class="line"><span class="comment"># pca.fit(train_data)</span></div><div class="line">train_data = pca.fit_transform(train_data)</div><div class="line"><span class="comment"># pca.fit(test_data)</span></div><div class="line">test_data = pca.transform(test_data)</div></pre></td></tr></table></figure>
<h2 id="SVM_u8BAD_u7EC3"><a href="#SVM_u8BAD_u7EC3" class="headerlink" title="SVM训练"></a>SVM训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">'使用SVM进行训练...'</span>)</div><div class="line">svc = SVC(kernel=<span class="string">'rbf'</span>,C=<span class="number">2</span>)</div><div class="line">svc.fit(train_data, label)</div><div class="line">print(<span class="string">'训练结束.'</span>)</div></pre></td></tr></table></figure>
<pre><code>使用SVM进行训练...
训练结束.
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">'对测试集进行预测...'</span>)</div><div class="line">predict = svc.predict(test_data)</div><div class="line">print(<span class="string">'预测结束.'</span>)</div></pre></td></tr></table></figure>
<pre><code>对测试集进行预测...
预测结束.
</code></pre><p>保存结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">pd.DataFrame(</div><div class="line">    &#123;<span class="string">"ImageId"</span>: range(<span class="number">1</span>, len(predict) + <span class="number">1</span>), <span class="string">"Label"</span>: predict&#125;</div><div class="line">).to_csv(<span class="string">'output.csv'</span>, index=<span class="keyword">False</span>, header=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">'done.'</span></div></pre></td></tr></table></figure>
<pre><code>done.
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/15/algo/kaggle/digit/" data-id="cj3uvlzqn0049bms90sqn7ax4" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/08/15/algo/kaggle/digit/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <article id="post-algo/kaggle/cf_crime" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/08/12/algo/kaggle/cf_crime/">kaggle之旧金山犯罪预测</a>
    </h1>
  

        <div class="article-meta">
          
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2016/08/12/algo/kaggle/cf_crime/">
      <time datetime="2016-08-12T05:48:13.000Z" itemprop="datePublished">2016-08-12</time>
    </a>
  </div>


          
  <div class="article-category">
  	<i class="fa fa-folder"></i>
    <a class="article-category-link" href="/categories/kaggle/">kaggle</a>
  </div>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
                
        <p><a href="https://www.kaggle.com/c/sf-crime" target="_blank" rel="external">kaggle地址</a><br><a href="https://github.com/lijingpeng/kaggle" target="_blank" rel="external">github地址</a></p>
<h2 id="u6570_u636E_u6982_u89C8"><a href="#u6570_u636E_u6982_u89C8" class="headerlink" title="数据概览"></a>数据概览</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># 载入数据</span></div><div class="line">train = pd.read_csv(<span class="string">'~/kaggle/dataset/San_Francisco_Crime_Classification/train.csv'</span>, parse_dates = [<span class="string">'Dates'</span>])</div><div class="line">test = pd.read_csv(<span class="string">'~/kaggle/dataset/San_Francisco_Crime_Classification/test.csv'</span>, parse_dates = [<span class="string">'Dates'</span>])</div></pre></td></tr></table></figure>
<p>预览训练集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> train.head(<span class="number">10</span>)</div></pre></td></tr></table></figure>
<pre><code>                Dates        Category                        Descript  \
0 2015-05-13 23:53:00        WARRANTS                  WARRANT ARREST   
1 2015-05-13 23:53:00  OTHER OFFENSES        TRAFFIC VIOLATION ARREST   
2 2015-05-13 23:33:00  OTHER OFFENSES        TRAFFIC VIOLATION ARREST   
3 2015-05-13 23:30:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   
4 2015-05-13 23:30:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   
5 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM UNLOCKED AUTO   
6 2015-05-13 23:30:00   VEHICLE THEFT               STOLEN AUTOMOBILE   
7 2015-05-13 23:30:00   VEHICLE THEFT               STOLEN AUTOMOBILE   
8 2015-05-13 23:00:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   
9 2015-05-13 23:00:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   

   DayOfWeek PdDistrict      Resolution                        Address  \
0  Wednesday   NORTHERN  ARREST, BOOKED             OAK ST / LAGUNA ST   
1  Wednesday   NORTHERN  ARREST, BOOKED             OAK ST / LAGUNA ST   
2  Wednesday   NORTHERN  ARREST, BOOKED      VANNESS AV / GREENWICH ST   
3  Wednesday   NORTHERN            NONE       1500 Block of LOMBARD ST   
4  Wednesday       PARK            NONE      100 Block of BRODERICK ST   
5  Wednesday  INGLESIDE            NONE            0 Block of TEDDY AV   
6  Wednesday  INGLESIDE            NONE            AVALON AV / PERU AV   
7  Wednesday    BAYVIEW            NONE       KIRKWOOD AV / DONAHUE ST   
8  Wednesday   RICHMOND            NONE           600 Block of 47TH AV   
9  Wednesday    CENTRAL            NONE  JEFFERSON ST / LEAVENWORTH ST   

            X          Y  
0 -122.425892  37.774599  
1 -122.425892  37.774599  
2 -122.424363  37.800414  
3 -122.426995  37.800873  
4 -122.438738  37.771541  
5 -122.403252  37.713431  
6 -122.423327  37.725138  
7 -122.371274  37.727564  
8 -122.508194  37.776601  
9 -122.419088  37.807802  
</code></pre><p>预览测试集合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> test.head(<span class="number">10</span>)</div></pre></td></tr></table></figure>
<pre><code>   Id               Dates DayOfWeek PdDistrict                   Address  \
0   0 2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   
1   1 2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   
2   2 2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   
3   3 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   
4   4 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   
5   5 2015-05-10 23:40:00    Sunday    TARAVAL     BROAD ST / CAPITOL AV   
6   6 2015-05-10 23:30:00    Sunday  INGLESIDE   100 Block of CHENERY ST   
7   7 2015-05-10 23:30:00    Sunday  INGLESIDE     200 Block of BANKS ST   
8   8 2015-05-10 23:10:00    Sunday    MISSION     2900 Block of 16TH ST   
9   9 2015-05-10 23:10:00    Sunday    CENTRAL      TAYLOR ST / GREEN ST   

            X          Y  
0 -122.399588  37.735051  
1 -122.391523  37.732432  
2 -122.426002  37.792212  
3 -122.437394  37.721412  
4 -122.437394  37.721412  
5 -122.459024  37.713172  
6 -122.425616  37.739351  
7 -122.412652  37.739750  
8 -122.418700  37.765165  
9 -122.413935  37.798886  
</code></pre><p>我们看到训练集和测试集都有Dates、DayOfWeek、PdDistrict三个特征，我们先从这三个特征入手。训练集中的Category是我们的预测目标，我们先对其进行编码，这里用到sklearn的LabelEncoder()，示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line">label = preprocessing.LabelEncoder()</div><div class="line">label.fit([<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">6</span>])</div><div class="line"><span class="keyword">print</span> label.transform([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>])</div></pre></td></tr></table></figure>
<pre><code>[0 0 1 2]
</code></pre><p>接下来我们对类别进行编码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">crime = label.fit_transform(train.Category)</div></pre></td></tr></table></figure>
<p>对于离散化的特征，有一种常用的特征处理方式是二值化处理，pandas中有get_dummies()函数，函数示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pd.get_dummies(pd.Series(list(<span class="string">'abca'</span>)))</div></pre></td></tr></table></figure>
<div><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>a</th><br>      <th>b</th><br>      <th>c</th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>0</th><br>      <td>1.0</td><br>      <td>0.0</td><br>      <td>0.0</td><br>    </tr><br>    <tr><br>      <th>1</th><br>      <td>0.0</td><br>      <td>1.0</td><br>      <td>0.0</td><br>    </tr><br>    <tr><br>      <th>2</th><br>      <td>0.0</td><br>      <td>0.0</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>3</th><br>      <td>1.0</td><br>      <td>0.0</td><br>      <td>0.0</td><br>    </tr><br>  </tbody><br></table><br></div>



<p>接下来对Dates、DayOfWeek、PdDistrict三个特征进行二值化处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">days = pd.get_dummies(train.DayOfWeek)</div><div class="line">district = pd.get_dummies(train.PdDistrict)</div><div class="line">hour = pd.get_dummies(train.Dates.dt.hour)</div></pre></td></tr></table></figure>
<p>接下来重新组合训练集，并把类别附加上：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">train_data = pd.concat([days, district, hour], axis=<span class="number">1</span>)</div><div class="line">train_data[<span class="string">'crime'</span>] = crime</div></pre></td></tr></table></figure>
<p>针对测试集做同样的处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">days = pd.get_dummies(test.DayOfWeek)</div><div class="line">district = pd.get_dummies(test.PdDistrict)</div><div class="line">hour = pd.get_dummies(test.Dates.dt.hour)</div><div class="line">test_data = pd.concat([days, district, hour], axis=<span class="number">1</span>)</div></pre></td></tr></table></figure>
<p>预览新的训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> train_data.head(<span class="number">10</span>)</div><div class="line"><span class="keyword">print</span> test_data.head(<span class="number">10</span>)</div></pre></td></tr></table></figure>
<pre><code>   Friday  Monday  Saturday  Sunday  Thursday  Tuesday  Wednesday  BAYVIEW  \
0     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   
1     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   
2     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   
3     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   
4     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   
5     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   
6     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   
7     0.0     0.0       0.0     0.0       0.0      0.0        1.0      1.0   
8     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   
9     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   

   CENTRAL  INGLESIDE  ...     15   16   17   18   19   20   21   22   23  \
0      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
1      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
2      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
3      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
4      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
5      0.0        1.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
6      0.0        1.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
7      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
8      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   
9      1.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   

   crime  
0     37  
1     21  
2     21  
3     16  
4     16  
5     16  
6     36  
7     36  
8     16  
9     16  

[10 rows x 42 columns]
   Friday  Monday  Saturday  Sunday  Thursday  Tuesday  Wednesday  BAYVIEW  \
0     0.0     0.0       0.0     1.0       0.0      0.0        0.0      1.0   
1     0.0     0.0       0.0     1.0       0.0      0.0        0.0      1.0   
2     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   
3     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   
4     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   
5     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   
6     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   
7     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   
8     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   
9     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   

   CENTRAL  INGLESIDE ...    14   15   16   17   18   19   20   21   22   23  
0      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
1      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
2      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
3      0.0        1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
4      0.0        1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
5      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
6      0.0        1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
7      0.0        1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
8      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  
9      1.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  

[10 rows x 41 columns]
</code></pre><p>分割训练集和验证集(70%训练,30%验证)准备建模：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</div><div class="line">training, validation = train_test_split(train_data, train_size=<span class="number">0.6</span>)</div></pre></td></tr></table></figure>
<h2 id="u8D1D_u53F6_u65AF_u8BAD_u7EC3"><a href="#u8D1D_u53F6_u65AF_u8BAD_u7EC3" class="headerlink" title="贝叶斯训练"></a>贝叶斯训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> log_loss</div><div class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> BernoulliNB</div><div class="line"></div><div class="line">model = BernoulliNB()</div><div class="line">feature_list = training.columns.tolist()</div><div class="line">feature_list = feature_list[:len(feature_list) - <span class="number">1</span>]</div><div class="line"><span class="keyword">print</span> <span class="string">'选取的特征列：'</span>, feature_list</div><div class="line">model.fit(training[feature_list], training[<span class="string">'crime'</span>])</div><div class="line"></div><div class="line">predicted = np.array(model.predict_proba(validation[feature_list]))</div><div class="line"><span class="keyword">print</span> <span class="string">"朴素贝叶斯log损失为 %f"</span> % (log_loss(validation[<span class="string">'crime'</span>], predicted))</div></pre></td></tr></table></figure>
<pre><code>选取的特征列： [&apos;Friday&apos;, &apos;Monday&apos;, &apos;Saturday&apos;, &apos;Sunday&apos;, &apos;Thursday&apos;, &apos;Tuesday&apos;, &apos;Wednesday&apos;, &apos;BAYVIEW&apos;, &apos;CENTRAL&apos;, &apos;INGLESIDE&apos;, &apos;MISSION&apos;, &apos;NORTHERN&apos;, &apos;PARK&apos;, &apos;RICHMOND&apos;, &apos;SOUTHERN&apos;, &apos;TARAVAL&apos;, &apos;TENDERLOIN&apos;, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
朴素贝叶斯log损失为 2.581561
</code></pre><h2 id="u903B_u8F91_u56DE_u5F52"><a href="#u903B_u8F91_u56DE_u5F52" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</div><div class="line">model = LogisticRegression(C=<span class="number">0.1</span>)</div><div class="line">model.fit(training[feature_list], training[<span class="string">'crime'</span>])</div><div class="line"></div><div class="line">predicted = np.array(model.predict_proba(validation[feature_list]))</div><div class="line"><span class="keyword">print</span> <span class="string">"逻辑回归log损失为 %f"</span> %(log_loss(validation[<span class="string">'crime'</span>], predicted))</div></pre></td></tr></table></figure>
<pre><code>逻辑回归log损失为 2.580102
</code></pre><p>在测试集上运行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">test_predicted = np.array(model.predict_proba(test_data[feature_list]))</div></pre></td></tr></table></figure>
<p>保存结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">col_names = np.sort(train[<span class="string">'Category'</span>].unique())</div><div class="line"><span class="keyword">print</span> col_names</div><div class="line">result = pd.DataFrame(data=test_predicted, columns=col_names)</div><div class="line">result[<span class="string">'Id'</span>] = test[<span class="string">'Id'</span>].astype(int)</div><div class="line">result.to_csv(<span class="string">'output.csv'</span>, index=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<pre><code>[&apos;ARSON&apos; &apos;ASSAULT&apos; &apos;BAD CHECKS&apos; &apos;BRIBERY&apos; &apos;BURGLARY&apos; &apos;DISORDERLY CONDUCT&apos;
 &apos;DRIVING UNDER THE INFLUENCE&apos; &apos;DRUG/NARCOTIC&apos; &apos;DRUNKENNESS&apos; &apos;EMBEZZLEMENT&apos;
 &apos;EXTORTION&apos; &apos;FAMILY OFFENSES&apos; &apos;FORGERY/COUNTERFEITING&apos; &apos;FRAUD&apos; &apos;GAMBLING&apos;
 &apos;KIDNAPPING&apos; &apos;LARCENY/THEFT&apos; &apos;LIQUOR LAWS&apos; &apos;LOITERING&apos; &apos;MISSING PERSON&apos;
 &apos;NON-CRIMINAL&apos; &apos;OTHER OFFENSES&apos; &apos;PORNOGRAPHY/OBSCENE MAT&apos; &apos;PROSTITUTION&apos;
 &apos;RECOVERED VEHICLE&apos; &apos;ROBBERY&apos; &apos;RUNAWAY&apos; &apos;SECONDARY CODES&apos;
 &apos;SEX OFFENSES FORCIBLE&apos; &apos;SEX OFFENSES NON FORCIBLE&apos; &apos;STOLEN PROPERTY&apos;
 &apos;SUICIDE&apos; &apos;SUSPICIOUS OCC&apos; &apos;TREA&apos; &apos;TRESPASS&apos; &apos;VANDALISM&apos; &apos;VEHICLE THEFT&apos;
 &apos;WARRANTS&apos; &apos;WEAPON LAWS&apos;]
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.notehub.cn/2016/08/12/algo/kaggle/cf_crime/" data-id="cj3uvlzqg003xbms94qxc9muj" class="article-share-link">分享到</a>
      
        <a href="http://www.notehub.cn/2016/08/12/algo/kaggle/cf_crime/#ds-thread" class="article-comment-link">评论</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>



    
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/page/5/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/7/">下一页 &raquo;</a>
      </nav>
    
</section>
      
        <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul id="recent-post" class="">
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2017/06/12/dev/collect/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2017/06/12/dev/collect/" class="title">收集</a></p>
              <p class="item-date"><time datetime="2017-06-12T06:19:56.000Z" itemprop="datePublished">2017-06-12</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2017/06/12/dev/web/ajax_upload/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/web/">web</a></p>
              <p class="item-title"><a href="/2017/06/12/dev/web/ajax_upload/" class="title">Ajax 文件上传</a></p>
              <p class="item-date"><time datetime="2017-06-12T05:19:56.000Z" itemprop="datePublished">2017-06-12</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/12/21/dev/go/go_file/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/12/21/dev/go/go_file/" class="title">Go文件操作大全</a></p>
              <p class="item-date"><time datetime="2016-12-21T07:19:56.000Z" itemprop="datePublished">2016-12-21</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/12/16/dev/encode/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/12/16/dev/encode/" class="title">Excel导入CSV文件中文乱码</a></p>
              <p class="item-date"><time datetime="2016-12-16T02:19:56.000Z" itemprop="datePublished">2016-12-16</time></p>
            </div>
          </li>
        
          <li>
            
            <div class="item-thumbnail">
              <a href="/2016/12/16/dev/python/python_extra/" class="thumbnail">
  
    <span class="thumbnail-image thumbnail-none"></span>
  
</a>
            </div>
            
            <div class="item-inner">
              <p class="item-category"><a class="article-category-link" href="/categories/dev/">dev</a></p>
              <p class="item-title"><a href="/2016/12/16/dev/python/python_extra/" class="title">Python snippets</a></p>
              <p class="item-date"><time datetime="2016-12-16T02:19:56.000Z" itemprop="datePublished">2016-12-16</time></p>
            </div>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hash/">Hash</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Photo/">Photo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SQL/">SQL</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ads/">ads</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c++</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/dev/">dev</a><span class="category-list-count">39</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/github/">github</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/internet/">internet</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/kaggle/">kaggle</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/system/">system</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/travel/">travel</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">5</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">十二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">十一月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">十月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">五月 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">三月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">二月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">六月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">五月 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">四月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">三月 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">二月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">一月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/11/">十一月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">十月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">六月 2014</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">十一月 2013</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Apache/" style="font-size: 10px;">Apache</a> <a href="/tags/Bandits/" style="font-size: 12.5px;">Bandits</a> <a href="/tags/Elasticsearch-docker/" style="font-size: 10px;">Elasticsearch, docker</a> <a href="/tags/FlatBuffers/" style="font-size: 10px;">FlatBuffers</a> <a href="/tags/Google/" style="font-size: 10px;">Google</a> <a href="/tags/Granger-causality/" style="font-size: 10px;">Granger causality</a> <a href="/tags/GridSearchCV/" style="font-size: 10px;">GridSearchCV</a> <a href="/tags/HTTPS/" style="font-size: 10px;">HTTPS</a> <a href="/tags/Jquery/" style="font-size: 10px;">Jquery</a> <a href="/tags/MapReduce/" style="font-size: 10px;">MapReduce</a> <a href="/tags/Mock/" style="font-size: 10px;">Mock</a> <a href="/tags/Monument-Vallay/" style="font-size: 10px;">Monument Vallay</a> <a href="/tags/Mysql/" style="font-size: 12.5px;">Mysql</a> <a href="/tags/PPTP-vpn/" style="font-size: 12.5px;">PPTP, vpn</a> <a href="/tags/Photoshop/" style="font-size: 10px;">Photoshop</a> <a href="/tags/Pipeline/" style="font-size: 10px;">Pipeline</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/ad/" style="font-size: 10px;">ad</a> <a href="/tags/apache/" style="font-size: 10px;">apache</a> <a href="/tags/blade/" style="font-size: 10px;">blade</a> <a href="/tags/crontab/" style="font-size: 10px;">crontab</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/elasticsearch/" style="font-size: 12.5px;">elasticsearch</a> <a href="/tags/font/" style="font-size: 10px;">font</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/go/" style="font-size: 17.5px;">go</a> <a href="/tags/hashmap/" style="font-size: 10px;">hashmap</a> <a href="/tags/kaggle/" style="font-size: 20px;">kaggle</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/linux-ldd-依赖关系/" style="font-size: 10px;">linux, ldd, 依赖关系</a> <a href="/tags/lucene/" style="font-size: 10px;">lucene</a> <a href="/tags/nio/" style="font-size: 10px;">nio</a> <a href="/tags/pagerank/" style="font-size: 10px;">pagerank</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/swift-llvm/" style="font-size: 10px;">swift, llvm</a> <a href="/tags/前端/" style="font-size: 10px;">前端</a> <a href="/tags/广告/" style="font-size: 12.5px;">广告</a> <a href="/tags/开源，许可/" style="font-size: 10px;">开源，许可</a> <a href="/tags/澳门/" style="font-size: 10px;">澳门</a> <a href="/tags/监控，zabbix/" style="font-size: 10px;">监控，zabbix</a> <a href="/tags/贝叶斯/" style="font-size: 10px;">贝叶斯</a>
    </div>
  </div>

  
  <div id="toTop" class="fa fa-chevron-up"></div>
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Li Jingpeng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
    </div>
  </div>
</footer>
    

<script type="text/javascript">
  var duoshuoQuery = {short_name:"lijingpeng"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>


<script src="//ajax.css.network/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>